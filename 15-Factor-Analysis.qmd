# 因素分析 {#sec-Factor-Aanalysis}

```{r}
#| include: FALSE
source("header.R")
```

> **譯者註** 20240129完成jamovi示範之外的編修。


<!---Previous chapters have covered statistical tests for differences between two or more groups. However, sometimes when conducting research, we may wish to examine how multiple variables *co-vary*. That is, how they are related to each other and whether the patterns of relatedness suggest anything interesting and meaningful. For example, we are often interested in exploring whether there are any underlying unobserved latent factors that are represented by the observed, directly measured, variables in our dataset. In statistics, latent factors are initially hidden variables that are not directly observed but are rather inferred (through statistical analysis) from other variables that are observed (directly measured).

In this chapter we will consider a number of different Factor Analysis and related techniques, starting with [Exploratory Factor Analysis] (EFA). EFA is a statistical technique for identifying underlying latent factors in a data set. Then we will cover [Principal Component Analysis] (PCA) which is a data reduction technique which, strictly speaking, does not identify underlying latent factors. Instead, PCA simply produces a linear combination of observed variables. Following this, the section on [Confirmatory Factor Analysis] (CFA) shows that, unlike EFA, with CFA you start with an idea - a model - of how the variables in your data are related to each other. You then test your model against the observed data and assess how good a fit the model is. A more sophisticated version of CFA is the so-called [Multi-Trait Multi-Method CFA] approach in which both latent factor and method variance are included in the model. This is useful when there are different methodological approaches used for measurement and therefore method variance is an important consideration. Finally, we will cover a related analysis: [Internal consistency reliability analysis] tests how consistently a scale measures a psychological construct. --->

前幾個單元介紹的統計檢定方法主要是處理兩個或多個研究組之間的差異，不過有時候的研究目的是檢定多個變項的*共變*。也就是探討變項之間的關係,以及有關聯的變項所構成的模式是否有趣和有意義的東西。例如,研究者經常有興趣探索是否存在任何潛在的未觀察到的因素,這些因素是從直接測量的可觀察變項資料而揭露的。潛在因素的統計學定義是一開始為隱藏變項,不是直接觀察的,而是經由其他直接觀察或測量的變項推斷出來。

這個單元將介紹幾種因素分析和相關技術,首先是[探索性因素分析] (EFA)。EFA是一種統計技術,用於識別潛藏在資料裡的潛在因素。然後是[主成分分析](PCA),這是一種縮減資料變項的方法,嚴格來說,這種方法無法識別潛藏的潛在因素,僅用來建構觀察變項的線性組合。接著是[驗證性因素分析](CFA),CFA與EFA不同之處是，前者從一個想法開始檢定資料中的變項之間的關係，所謂想法通常是一個模型。然後根據觀察到的資料檢驗模型,並評估模型的適配程度。CFA有一個種較複雜的版本–[多種特質多項相關驗證性因素分析],包括檢定模型內的潛在因素和方法之間的變異。這種方法有用的原因是當研究者使用不同測量方法，那麼方法之間的變異就是一個重要的因素。最後要介紹的是[內部一致性信度分析]，這種相關分析是測試一種量表所評估之心理結構一致性。

## 探索性因素分析 

<!---**Exploratory Factor Analysis (EFA)** is a statistical technique for revealing any hidden latent factors that can be inferred from our observed data. This technique calculates to what extent a set of measured variables, for example $V1, V2, V3, V4$, and $V5$, can be represented as measures of an underlying latent factor. This latent factor cannot be measured through just one observed variable but instead is manifested in the relationships it causes in a set of observed variables.

In @fig-fig15-1 each observed variable $V$ is 'caused' to some extent by the underlying latent factor ($F$), depicted by the coefficients $b_1$ to $b_5$ (also called factor loadings). Each observed variable also has an associated error term, e1 to e5. Each error term is the variance in the associated observed variable, $V_i$ , that is unexplained by the underlying latent factor.

Latent factor underlying the relationship between several observed variables--->

**探索性因素分析(EFA)**是一種可以從觀察資料推斷出任何隱藏的潛在因素的統計技術，這種方法的原理是計算一組測量變項(例如$V_1、V_2、V_3、V_4$ 和 $V_5$)在多大程度上可以構成潛在因素的測量尺度。這種潛在因素不能只用一個觀察變項來測量,而是體現於受影響的一組觀察變項構成的關係網路。

以 @fig-fig15-1 來說，每個觀察變項 $V_i$ 都在一定程度上受到潛在因素($F$)的影響，影響力用係數 $b_1$ 到 $b_5$(也稱為因子負荷)表示。每個觀察變項$V_i$都有一個誤差項,也就是$e_1$ 到 $e_5$，代表與潛在因素無關的資料料誤差。  


```{r}
#| label: fig-fig15-1
#| fig-cap: 隱藏於數個觀察變項之間的潛在因素  
knitr::include_graphics("images/fig15-1.png")
```


<!---In Psychology, latent factors represent psychological phenomena or constructs that are difficult to directly observe or measure. For example, personality, or intelligence, or thinking style. In the example in @fig-fig15-1 we may have asked people five specific questions about their behaviour or attitudes, and from that we are able to get a picture about a personality construct called, for example, extraversion. A different set of specific questions may give us a picture about an individual's introversion, or their conscientiousness.

Here's another example: we may not be able to directly measure statistics anxiety, but we can measure whether statistics anxiety is high or low with a set of questions in a questionnaire. For example, "$Q1$: Doing the assignment for a statistics course", "$Q2$: Trying to understand the statistics described in a journal article", and "$Q3$: Asking the lecturer for help in understanding something from the course", etc., each rated from low anxiety to high anxiety. People with high statistics anxiety will tend to give similarly high responses on these observed variables because of their high statistics anxiety. Likewise, people with low statistics anxiety will give similar low responses to these variables because of their low statistics anxiety.

In exploratory factor analysis (EFA), we are essentially exploring the correlations between observed variables to uncover any interesting, important underlying (latent) factors that are identified when observed variables co-vary. We can use statistical software to estimate any latent factors and to identify which of our variables have a high loading[^factor-analysis-1] (e.g. loading > 0.5) on each factor, suggesting they are a useful measure, or indicator, of the latent factor. Part of this process includes a step called rotation, which to be honest is a pretty weird idea but luckily we don't have to worry about understanding it; we just need to know that it is helpful because it makes the pattern of loadings on different factors much clearer. As such, rotation helps with seeing more clearly which variables are linked substantively to each factor. We also need to decide how many factors are reasonable given our data, and helpful in this regard is something called Eigen values. We'll come back to this in a moment, after we have covered some of the main assumptions of EFA.

[^factor-analysis-1]: Quite helpfully, factor loadings can be interpreted like standardized regression coefficients --->

心理學的潛在因素通常是難以直接觀察或測量的心理現象或構造，像是個性,智力或思考模式。以 @fig-fig15-1 來說，觀察變項可以是五個請參與者回答的行為或態度之具體問題,影響五個問題的潛在因素可能是一種被學者稱為外向性的性格，另一組問題則可能受到內向性或責任感等潛在因素的影響。

這裡還有另一個範例:有一個測量統計焦慮的問卷，雖然統計焦慮無法直接測量，不過問卷中的每個問題能測量因統計課作業引發的一部分焦慮感。例如,“$Q1$:完成統計課程中的作業”,“$Q2$:試圖理解期刊文章中描述的統計”,和“$Q3$:向講師請教課程中不理解之處的幫助”等等，填答者從低焦慮到高焦慮給每題一個評分。若填答者有明顯的統計焦慮，每一題會傾向給較高的評分；反之，如果填答者沒有太明顯的統計焦慮，每一題會傾向給較低的評分。

探索性因素分析的本質是探索變項之間的相關性，從變項之間的共變關係識別任何有趣和重要的潛在因素。使用統計軟體可以評估任何潛在因素,以及與受潛在因素影響的每個變項的因素負荷量[^factor-analysis-1]。例如因素負荷量 > 0.5的變項，很可能是測量潛在因素的有效指標。計算因素負荷量的過程之一稱為**轉軸法(rotation)**，這是一個目前不好懂的名詞，好在目前讀者不需要理解這個過程，只要知道轉軸能清理不同因素對同一組變項的因素負荷量。經過轉軸法的處理，能清楚地看到哪些變項與每個潛在因素有實質的關聯性。此外，還要決定需要多少因素才能合理解釋資料，這就需要計算**特徵值**(Eigen value)。介紹[探索性因素分析的執行條件]之後，我們再回來討論這些名詞。

[^factor-analysis-1]: 因素負荷量的解讀方式如同標準化迴歸係數。

### 探索性因素分析的執行條件

<!--- There are a couple of assumptions that need to be checked as part of the analysis. The first assumption is **sphericity**, which essentially checks that the variables in your dataset are correlated with each other to the extent that they can potentially be summarised with a smaller set of factors. Bartlett's test for sphericity checks whether the observed correlation matrix diverges significantly from a zero (or null) correlation matrix. So, if Bartlett's test is significant ($p < .05$), this indicates that the observed correlation matrix is significantly divergent from the null, and is therefore suitable for EFA.

The second assumption is **sampling adequacy** and is checked using the Kaiser-MeyerOlkin (KMO) Measure of Sampling Adequacy (MSA). The KMO index is a measure of the proportion of variance among observed variables that might be common variance. Using partial correlations, it checks for factors that load just two items. We seldom, if ever, want EFA producing a lot of factors loading just two items each. KMO is about sampling adequacy because partial correlations are typically seen with inadequate samples. If the KMO index is high ($\approx 1$), the EFA is efficient whereas if KMO is low ($\approx 0$), the EFA is not relevant. KMO values smaller than $0.5$ indicates that EFA is not suitable and a KMO value of $0.6$ should be present before EFA is considered suitable. Values between $0.5$ and $0.7$ are considered adequate, values between $0.7$ and $0.9$ are good and values between $0.9$ and $1.0$ are excellent. --->


需要檢查的第一個執行條件是**球形性*,這是檢查資料變項之間的相關性,相關的變項越多就可以用越少潛在因素解釋。巴特利球形檢驗是用來檢驗變項的相關矩陣，是否顯著不同於零相關矩陣。如果巴特利檢驗結果有達到顯著($p < .05$),表示反應變項之間有關聯性，可使用探索性因素分析。  

第二個要檢查的執行條件是**樣本適足性**,這是使用Kaiser-Meyer-Olkin樣本適足量數(簡稱KMO)做為評估指標。KMO樣本適足量數代表觀察變項之間的共變佔總變異量的比例。
因為通常報告呈現的潛在因素，很少納入只能解釋兩個變項的因素，因為這代表樣本不足。如果存在只影響兩個變項的因素，可計算部分相關係數。如果 KMO 量數偏高($ \approx 1$),可認定因素分析結果有效;如果 KMO 量數偏低($ \approx 0$),則因素分析結果找到的潛在因素與變項不相關。 KMO 量數小於 $0.5$ 表示因素分析結果不適用,KMO 值為 $0.6$ 時才會認定因素分析結果是低度適用。 $0.5$ 和 $0.7$ 之間的值被認為是中度適用,$0.7$ 和 $0.9$ 之間的值是高度適用,$0.9$ 和 $1.0$ 之間的值是非常適用。



### 探索性因素分析的用途

<!---If the EFA has provided a good solution (i.e. factor model), then we need to decide what to do with our shiny new factors. Researchers often use EFA during psychometric scale development. They will develop a pool of questionnaire items that they think relate to one or more psychological constructs, use EFA to see which items "go together" as latent factors, and then they will assess whether some items should be removed because they don't usefully or distinctly measure one of the latent factors.

In line with this approach, another consequence of EFA is to combine the variables that load onto distinct factors into a factor score, sometimes known as a scale score. There are two options for combining variables into a scale score:

- Create a new variable with a score weighted by the factor loadings for each item that contributes to the factor.
- Create a new variable based on each item that contributes to the factor, but weighting them equally.

In the first option each item's contribution to the combined score depends on how strongly it relates to the factor. In the second option we typically just average across all the items that contribute substantively to a factor to create the combined scale score variable. Which to choose is a matter of preference, though a disadvantage with the first option is that loadings can vary quite a bit from sample to sample, and in behavioural and health sciences we are often interested in developing and using composite questionnaire scale scores across different studies and different samples. In which case it is reasonable to use a composite measure that is based on the substantive items contributing equally rather than weighting by sample specific loadings from a different sample. In any case, understanding a combined variable measure as an average of items is simpler and more intuitive than using a sample specific optimally-weighted combination.

A more advanced statistical technique, one which is beyond the scope of this book, undertakes regression modelling where latent factors are used in prediction models of other latent factors. This is called "structural equation modelling" and there are specific software programmes and R packages dedicated to this approach. But let's not get ahead of ourselves; what we should really focus on now is how to do an EFA in jamovi. --->

如果因素分析結果確立了適用的因素模型,接著需要決定如何處理結果顯現的新因素。EFA通常用來開發心理測量量表，研究人員會先建立與單一與多種心理特質有關的問卷題庫，收集次料後 EFA 檢視哪些題目是"聚斂於"一種潛在因素,然後評估是否應刪除沒有清楚測出任何一個潛在因素的某些題目。

EFA的另一種用途是將因素負荷量高的變項合併為因素分數,有時可稱為量表分數。有兩種方法能將合併的變項資料轉為量表分數 :

- 創建新變項代表要計分的因素，合併為一份量表的變項分數按照因素負荷量加權調整。 

- 創建新變項代表要計分的因素，合併為一份量表的變項分數均權調整。

第一種方法的每個變項對合併分數的貢獻取決於與因素的關係強度。第二種方法就是拿所有受到同一因素實質影響的變項，取變項平均值做為合併的量表分數。何種方法較好沒有參考標準，只是第一種方法的缺點是因素負荷量會隨樣本檢源改變。行為和健康科學的研究人員經常會開發和使用於不同研究場景，或不同對象的綜合問卷。這種問卷的量表分數適合用第二種方法較合理，因為是基於等量貢獻的實質變項，而不是使用來自不同來源的特定樣本的負荷量加權。其實在任何研究問題，用變項平均值當成合併變項的測量較簡單，而且比較直觀。  

還有一種使用迴歸式建立因素模型的進階方法，這是使用潛在因素預測其他潛在因素。這種方法就是“結構方式模型”(structural equation modelling)，已經有專門的軟體和R套件能執行這種方法。不過讀者還不必急著去學，現在先學好如何用 jamovi 執行 EFA。


### 使用jamovi完成探索性因素分析

<!--- First, we need some data. Twenty-five personality self-report items (see @fig-fig15-2) taken from the <a href="http://ipip.ori.org" target="_blank">International Personality Item Pool</a> were included as part of the Synthetic Aperture Personality Assessment (SAPA) web-based personality assessment (SAPA: <a href="http://sapa-project.org"
target="_blank">http://sapa-project.org</a>) project. The 25 items are organized by five putative factors: Agreeableness, Conscientiousness, Extraversion, Neuroticism, and Openness.

The item data were collected using a 6-point response scale:

1.  Very Inaccurate
2.  Moderately Inaccurate
3.  Slightly Inaccurate
4.  Slightly Accurate
5.  Moderately Accurate
6.  Very Accurate.

A sample of $N=250$ responses is contained in the dataset *bfi_sample.csv* . As researchers, we are interested in exploring the data to see whether there are some underlying latent factors that are measured reasonably well by the $25$ observed variables in the *bfi_sample.csv*  data file. Open up the dataset and check that the $25$ variables are coded as continuous variables (technically they are ordinal though for EFA in jamovi it mostly doesn't matter, except if you decide to calculate weighted factor scores in which case continuous variables are needed). To perform EFA in jamovi:

Twenty-five observed variable items organised by five putative personality factors in the dataset bfi\_sample.csv
--->

在此使用取自 <a href="http://ipip.ori.org" target="_blank">國際性格量表題庫</a>的25項人格自我報告題目(請見 @fig-fig15-2 )， 組合的網路性格問卷–合成孔徑性格量表(SAPA:<a href="http://sapa-project.org" target="_blank">http://sapa-project.org</a>)其中一部分資料做為範例。25個題目假設受五個因素影響:親和性(Agreeableness)、盡責性(Conscientiousness)、外向性(Extraversion)、神經質(Neuroticism)和開放性(Openness)。  

每個題目都是6點量表紀錄參與者的反應資料:  

1.非常不準確  

2.中度不準確  

3.輕度不準確  

4.輕度準確  

5.中度準確  

6.非常準確。  

資料檔案*bfi\_sample.csv*包括$N=250$份參與者樣本(lsj檔案庫Personality Questionnaire)。研究人員有興趣的，是看看檔案中的$25$個觀察變項，有那些能合理測量的潛在因素。請先開啟這份檔案檢查這$25$個變項是否以連續變項編碼？(至少要用次序變項編碼，雖然jamovi的EFA模組可以處理。若是要用因素負荷加權計算因素分數，就需要先轉換為連續變項)。接著執行jamovi的EFA模組：  


```{r}
#| label: fig-fig15-2
#| fig-cap: 資料檔案bfi\_sample.csv的25個假設可測量五大性格因素的題目
knitr::include_graphics("images/fig15-2.png")
```

<!---
- Select Factor - Exploratory Factor Analysis from the main jamovi button bar to open the EFA analysis window (@fig-fig15-3).

- Select the 25 personality questions and transfer them into the 'Variables' box.

- Check appropriate options, including 'Assumption Checks', but also Rotation 'Method', 'Number of Factors' to extract, and 'Additional Output' options. See @fig-fig15-3 for suggested options for this illustrative EFA, and please note that the Rotation 'Method' and 'Number of Factors' extracted is typically adjusted by the researcher during the analysis to find the best result, as described below.

The jamovi EFA analysis window

jamovi EFA assumption checks for the personality questionnaire data

--->


- 從主要jamovi按鈕欄中選擇“因素”- “探索性因素分析”以打開EFA分析窗口(@fig-fig15-3)。

- 選擇25個人格問題并將其轉移到“變項”框中。  

- 檢查適當的選項,包括“預設檢查”,但也選擇旋轉“方法”、要提取的“因子數量”和“其他輸出”選項。有關此示例EFA的建議選項,請參閱@fig-fig15-3,并請注意,如下所述,通常研究人員會在分析過程中調整旋轉“方法”和提取的“因子數量”以找到最佳結果。   


```{r}
#| label: fig-fig15-3
#| classes: .enlarge-image
#| fig-cap: jamovi EFA分析窗口  
knitr::include_graphics("images/fig15-3.png")
```

```{r}
#| label: fig-fig15-4
#| classes: .enlarge-image
#| fig-cap: jamovi人格問卷資料的EFA預設檢查
knitr::include_graphics("images/fig15-4.png")
```

<!--- First, check the assumptions (@fig-fig15-4). You can see that (1) Bartlett's test of sphericity is significant, so this assumption is satisfied; and (2) the KMO measure of sampling adequacy (MSA) is $0.81$ overall, suggesting good sampling adequacy. No problems here then!

The next thing to check is how many factors to use (or "extract" from the data). Three different approaches are available:

- One convention is to choose all components with Eigen values greater than 12 . This would give us four factors with our data (try it and see).

- Examination of the scree plot, as in @fig-fig15-5, lets you identify the "point of inflection". This is the point at which the slope of the scree curve clearly levels off, below the "elbow". This would give us five factors with our data. Interpreting scree plots is a bit of an art: in @fig-fig15-5 there is a noticeable step from $5$ to $6$ factors, but in other scree plots you look at it will not be so clear cut.

- Using a parallel analysis technique, the obtained Eigen values are compared to those that would be obtained from random data. The number of factors extracted is the number with Eigen values greater than what would be found with random data.

Scree plot of the personality data in jamovi EFA, showing a noticeable inflection and levelling off after point 5 (the 'elbow') --->


首先,檢查預設條件(@fig-fig15-4)。您可以看到(1)巴特利球形性檢驗顯著,所以滿足這個預設條件;和(2)抽樣適度性測度(MSA)的總體KMO測度為$0.81$,這表明了很好的抽樣適度性。這裡沒有問題!  

下一件要檢查的事情是使用多少因素(或從資料中“提取”多少因素)。有三種不同的方法:   

- 一個公約是選擇所有特徵值大於1的組件2。這會給我們四個因素(嘗試一下)。   

- 如@fig-fig15-5所示,檢查斜率圖可以幫助您識別“拐點”。這是斜率曲線明顯趨於平緩的點,在“肘部”以下。这會给我们的数据五个因素。解釋斜率圖有點藝術性:在@fig-fig15-5中,從$5$個到$6$個因素有一個明顯的跨度,但是在您查看的其他斜率圖中,情況並不會那么清晰。   

- 使用平行分析技術,獲得的特徵值與從隨機資料獲得的特徵值進行比較。 提取的因素數量是特徵值大於隨機資料中找到的值的數量。   



```{r}
#| label: fig-fig15-5
#| fig-cap: 在jamovi EFA 中顯示人格資料的斜率圖,顯示在點5(“肘部”)后明顯拐點和趨於平緩   
knitr::include_graphics("images/fig15-5.png")
```

<!--- The third approach is a good one according to @Fabrigar1999, although in practice researchers tend to look at all three and then make a judgement about the number of factors that are most easily or helpfully interpreted. This can be understood as the "meaningfulness criterion", and researchers will typically examine, in addition to the solution from one of the approaches above, solutions with one or two more or fewer factors. They then adopt the solution which makes the most sense to them.

At the same time, we should also consider the best way to rotate the final solution. There are two main approaches to rotation: orthogonal (e.g. 'varimax') rotation forces the selected factors to be uncorrelated, whereas oblique (e.g. 'oblimin') rotation allows the selected factors to be correlated. Dimensions of interest to psychologists and behavioural scientists are not often dimensions we would expect to be orthogonal, so oblique solutions are arguably more sensible[^factor-analysis-2]

[^factor-analysis-2]: Oblique rotations provide two factor matrices, one called a structure matrix and one called a pattern matrix. In jamovi just the pattern matrix is shown in the results as this is typically the most useful for interpretation, though some experts suggest that both can be helpful. In a structure matrix coefficients show the relationship between the variable and the factors whilst ignoring the relationship of that factor with all the other factors (i.e. a zero-order correlation). Pattern matrix coefficients show the unique contribution of a factor to a variable whilst controlling for the effects of other factors on that variable (akin to standardized partial regression coefficient). Under orthogonal rotation, structure and pattern coefficients are the same.

Factor summary statistics and correlations for a five factor solution in jamovi EFA--->


根據 @Fabrigar1999 的說法,第三種方法很好,儘管在實踐中,研究人員傾向於查看所有三個方法,然后根據最容易或最有幫助解釋的因素數量來進行判斷。這可以理解為“意義標准”,研究人員通常除了檢查上述方法之一的解决方案外,还會檢查具有一個或兩個更多或更少因素的解决方案。 然后他們采用對他們最有意义的解决方案。

與此同時,我們還應考慮最佳旋轉最終解决方案的最佳方法。旋轉有兩種主要方法:正交(例如“varimax”)旋轉強制所選因素不相關,Whereas斜交(例如“oblimin”)旋轉允許所選因素相關。心理學家和行為科學家感興趣的維度通常並非我們希望正交的維度,因此斜交解決方案可以說更加合理[^factor-analysis-2]  

[^factor-analysis-2]: 斜交旋轉提供了兩個因子矩陣,一個稱為結構矩陣,一個稱為模式矩陣。 在jamovi中,結果中只顯示模式矩陣,因為這通常對解釋最有用,儘管一些專家建議两者都很有幫助。 在結構矩陣中,係數顯示變項與因素之間的關係,同時忽略該因素與所有其他因素的關係(即零階相關)。 模式矩陣係數顯示因素對變項的獨特貢獻,同時控制該變項上其他因素的影響(類似於標准化偏迴歸係數)。 在正交旋轉下,結構和模式係數是相同的。  


```{r}
#| label: fig-fig15-6
#| classes: .enlarge-image
#| fig-cap: jamovi EFA 中五因素解的因素摘要統計量和相關量 
knitr::include_graphics("images/fig15-6.png")
```

<!--- Practically, if in an oblique rotation the factors are found to be substantially correlated (positive or negative, and > 0.3), as in @fig-fig15-6 where a correlation between two of the extracted factors is 0.31, then this would confirm our intuition to prefer oblique rotation. If the factors are, in fact, correlated, then an oblique rotation will produce a better estimate of the true factors and a better simple structure than will an orthogonal rotation. And, if the oblique rotation indicates that the factors have close to zero correlations between one another, then the researcher can go ahead and conduct an orthogonal rotation (which should then give about the same solution as the oblique rotation).

On checking the correlation between the extracted factors at least one correlation was greater than 0.3 (@fig-fig15-6), so an oblique ('oblimin') rotation of the five extracted factors is preferred. We can also see in @fig-fig15-6 that the proportion of overall variance in the data that is accounted for by the five factors is 46%. Factor one accounts for around 10% of the variance, factors two to four around 9% each, and factor five just over 7%. This isn't great; it would have been better if the overall solution accounted for a more substantive proportion of the variance in our data.

Be aware that in every EFA you could potentially have the same number of factors as observed variables, but every additional factor you include will add a smaller amount of explained variance. If the first few factors explain a good amount of the variance in the original 25 variables, then those factors are clearly a useful, simpler substitute for the 25 variables. You can drop the rest without losing too much of the original variability. But if it takes 18 factors (for example) to explain most of the variance in those 25 variables, you might as well just use the original 25.

@fig-fig15-7 shows the factor loadings. That is, how the 25 different personality items load onto each of the five selected factors. We have hidden loadings less than $0.3$ (set in the options shown in @fig-fig15-3.

For Factors $1, 2, 3$ and $4$ the pattern of factor loadings closely matches the putative factors specified in @fig-fig15-2. Phew! And factor $5$ is pretty close, with four of the five observed variables that putatively measure "openness" loading pretty well onto the factor. Variable $04$ doesn't quite seem to fit though, as the factor solution in @fig-fig15-7 suggests that it loads onto factor $4$ (albeit with a relatively low loading) but not substantively onto factor $5$.

The other thing to note is that those variables that were denoted as "R: reverse coding" in @fig-fig15-2 are those that have negative factor loadings. Take a look at the items A1 ("Am indifferent to the feelings of others") and A2 ("Inquire about others' well-being"). We can see that a high score on $A1$ indicates low Agreeableness, whereas a high score on $A2$ (and all the other "A" variables for that matter) indicates high Agreeableness. Therefore A1 will be negatively correlated with the other "A" variables, and this is why it has a negative factor loading, as shown in @fig-fig15-7.

Factor loadings for a five factor solution in jamovi EFA
--->

從實踐的角度來看,如果在斜交旋轉中發現因素之間存在顯著相關(正相關或負相關,並且大於0.3),如@fig-fig15-6所示,其中提取的兩個因素之間的相關為0.31,那麼這將證實我們更喜歡斜交旋轉的直覺。如果這些因素確實相關,那麼斜交旋轉將產生比正交旋轉更好的真實因素估計和更好的簡單結構。而且,如果斜交旋轉表明各因素之間的相關接近零,那麼研究人員可以繼續進行正交旋轉(這時應給出與斜交旋轉大致相同的解決方案)。

在檢查提取因素之間的相關時,至少有一個相關大於0.3(@fig-fig15-6),因此更喜歡提取的五個因素的斜交(“oblimin”)旋轉。我們還可以在@fig-fig15-6中看到,五個因素解釋的資料總變異數的比例為46%。第一因素解釋了大約10%的變異,第二至第四因素解釋了大約9%的變異,第五因素解釋了略多於7%的變異。這並不是很好;如果整體解釋我們資料中的更多變異那會更好。 

請注意,在每個EFA中,您可以潛在地具有與觀察變項數量相同的因素,但是您包含的每個附加因素都會增加更小量的解釋變異數量。如果前几个因素解释了原始25 个變項中的大量方差,那麼這些因素顯然是25 个變項的一個有用、更简单的替代品。您可以放心刪除其餘部分,而不會失去太多原始變異性。但是如果需要18個因素(例如)來解釋這25個變項中的大部分變異數,那麼您不如直接使用原始的25個變項。

@fig-fig15-7顯示了因子負荷。也就是說,25個不同的人格項目如何在五個選定的因素上加載。我們隱藏了小於0.3的負荷(設置在@fig-fig15-3中顯示的選項中)。  

對於因素$1、2、3$和$4$,因子負荷的模式與@fig-fig15-2中指定的假定因素緊密匹配。太好了!第5個因素也相當接近,五個被認為測量“開放性”的觀察變項中有四個在該因素上載入得相當好。但是,變項$04$似乎並不太適合,因為@fig-fig15-7中的因子解决方案表明它載入到因素$4$上(儘管載荷相對較低),但沒有實質上載入到因素$5$上。  

需要注意的另一件事情是,在@fig-fig15-2中標記為“R:反向編碼”的那些變項是那些具有負因子負荷的變項。查看項目A1(“漠不關心他人的感受”)和A2(“詢問他人的幸福”)。我們可以看到,$A1$的高分表示親和力較低,Whereas $A2$(和所有其他“A”變項)的高分表示親和力較高。因此,A1將與其他“A”變項負相關,這就是為什麼它在@fig-fig15-7中具有負因子負荷。


```{r}
#| label: fig-fig15-7
#| classes: .enlarge-image
#| fig-cap: jamovi EFA中的五因素解的因子負荷量
knitr::include_graphics("images/fig15-7.png")
```

<!--- We can also see in @fig-fig15-7 the "uniqueness" of each variable. Uniqueness is the proportion of variance that is 'unique' to the variable and not explained by the factors[^factor-analysis-3]. For example, 72% of the variance in 'A1' is not explained by the factors in the five factor solution. In contrast, 'N1' has relatively low variance not accounted for by the factor solution (35%). Note that the greater the 'uniqueness', the lower the relevance or contribution of the variable in the factor model.

[^factor-analysis-3]: Sometimes reported in factor analysis is "communality" which is the amount of variance in a variable that is accounted for by the factor solution. Uniqueness is equal to (1 $\sim$ communality)

To be honest, it's unusual to get such a neat solution in EFA. It's typically quite a bit more messy than this, and often interpreting the meaning of the factors is more challenging. It's not often that you have such a clearly delineated item pool. More often you will have a whole heap of observed variables that you think may be indicators of a few underlying latent factors, but you don't have such a strong sense of which variables are going to go where!

So, we seem to have a pretty good five factor solution, albeit accounting for a relatively low overall proportion of the observed variance. Let's assume we are happy with this solution and want to use our factors in further analysis. The straightforward option is to calculate an overall (average) score for each factor by adding together the score for each variable that loads substantively onto the factor and then dividing by the number of variables (in other words create a 'mean score' for each person across the items for each scale. For each person in our dataset that entails, for example for the Agreeableness factor, adding together $A1 + A2 + A3 + A4 + A5$, and then dividing by 5. [^factor-analysis-4] In essence, the factor score we have calculated is based on equally weighted scores from each of the included variables/itmes. We can do this in jamovi in two steps:

[^factor-analysis-4]: remembering to first reverse score some variables if necessary

- Recode A1 into "A1R" by reverse scoring the values in the variable (i.e. $6 = 1$; $5 = 2$; $4 = 3$; $3 = 4$; $2 = 5$; $1 = 6$) using the jamovi transform variable command (see @fig-fig15-8).

- Compute a new variable, called "Agreeableness', by calculating the mean of A1R, A2, A3, A4 and A5. Do this using the jamovi compute new variable command (see @fig-fig15-9).  

Recode variable using the jamovi Transform command

Compute new scale score variable using the jamovi Computed variable command
--->

我們也可以在 @fig-fig15-7 中看到每個變項的“獨特性”。獨特性是指變項中“獨特”的變異比例,而不是被因子所描述的 [^factor-analysis-3]。例如,“A1”中有 72% 的變異沒有被五因子解中的因子描述。相反,“N1”的無法被因子解描述的變異相對較低(35%)。請注意,“獨特性”越高,該變項在因子模式中的相關性或貢獻越低。  

[^factor-analysis-3]: 在因子分析中有時會報告“公因性”,這是變項中能夠被因子解描述的變異量。獨特性等於 (1 $\sim$ 公因性)

說實話,在探索性因子分析中得到這樣整潔的解決方案並不尋常。結果通常會混亂得多,而解析因子的意義也更具挑戰性。很少會有這樣清晰劃分的變項池。您會有大量的反應變項,您認為它們可能是少數潛在因子的指標,但是您並不如此強烈地知道哪些變項將會到哪裡!  

所以,我們似乎有一個相當好的五因子解,儘管它描述了相對較低的整體變異比例。假設我們對這個解決方案滿意,並希望在進一步分析中使用因子。直接的選擇是計算每個因子的整體平均分數。例如,對於資料集中的每個人的親和力因子,這涉及添加 $A1 + A2 + A3 + A4 + A5$,然後除以 5 [^factor-analysis-4]。我們計算的因子得分是基於每個包含變項的等權得分。我們可以通過兩個步驟在 jamovi 中執行:

[^factor-analysis-4]: 必要時先進行某些變項的反向計分  

- 使用 jamovi 將 A1 重新編碼為 “A1R”,方法是反向評分變項中的值。

- 使用 jamovi 計算新變項 “親和力”,方法是計算 A1R、A2、A3、A4 和 A5 的平均值。


```{r}
#| label: fig-fig15-8
#| classes: .enlarge-image
#| fig-cap: 使用 jamovi 的變項轉換命令重編碼變項
knitr::include_graphics("images/fig15-8.png")
```

```{r}
#| label: fig-fig15-9
#| classes: .enlarge-image
#| fig-cap: 使用 jamovi 的計算新變項命令計算新的量表分數變項
knitr::include_graphics("images/fig15-9.png")
```

<!--- Another option is to create an **optimally-weighted** factor score index. To do this, save the factor scores to the data set, using the 'Save' - 'Factor scores' checkbox. Once you have done this you will see that five new variables (columns) have been added to the data, one for each factor extracted. See @fig-fig15-10 and @fig-fig15-11.

jamovi option for factor scores for the five factor solution, using the 'Bartlett' optimal weighting method

Data sheet view showing the five newly created factor score variables
--->

另一個選擇是創建一個**最佳加權**的因子分數指數。要做到這一點,使用“保存” - “因子分數”複選框將因子分數保存到資料集。一旦您這樣做,您將看到已經向資料添加了5個新變項(列),每個提取的因子一列。請參見@fig-fig15-10和@fig-fig15-11。


```{r}
#| label: fig-fig15-10
#| classes: .enlarge-image
#| fig-cap: 使用“Bartlett”最佳加權方法的五因子解的因子分數選項的jamovi
knitr::include_graphics("images/fig15-10.png")
```

```{r}
#| label: fig-fig15-11
#| classes: .enlarge-image
#| fig-cap: 顯示五個新創建的因子分數變項的資料表視圖
knitr::include_graphics("images/fig15-11.png")
```

<!--- Now you can go ahead and undertake further analyses, using either the mean score based factor scales (e.g. as in @fig-fig15-9) or using the optimally-weighted factor scores calculated by jamovi. Your choice! For example, one thing you might like to do is see whether there are any gender differences in each of our personality scales. We did this for the Agreeableness score that we calculated using the mean score approach, and although the t test plot (@fig-fig15-12) showed that males were less agreeable than females, this was not a significant difference (Mann-Whitney $U = 5768$, $p = .075$). 


Comparing differences in Agreeableness factor-based scores between males and females
--->


現在,您可以繼續開展進一步的分析,使用基於平均分數的因子量表(例如@fig-fig15-9中的量表)或使用jamovi計算的最佳加權因子分數。由您選擇!例如,您可能想做的一件事是查看這些人格特徵中的每一項在性別上的差異。我們對計算的親和力分數使用平均分法進行了t檢驗圖(@fig-fig15-12),結果顯示男性的親和力低於女性,但這個差異並不顯著(Mann-Whitney U = 5768,p = .075)。


```{r}
#| label: fig-fig15-12
#| classes: .enlarge-image
#| fig-cap: 比較男性和女性之間基於親和力因子的分數差異
knitr::include_graphics("images/fig15-12.png")
```

### 探索性因素分析的報告須知

<!--- Hopefully, so far we have given you some sense of EFA and how to undertake EFA in jamovi. So, once you have completed your EFA, how do you write it up? There is not a formal standard way to write up an EFA, and examples tend to vary by discipline and researcher. That said, there are some fairly standard pieces of information to include in your write-up:

1.  What are the theoretical underpinnings for the area you are studying, and specifically for the constructs that you are interested in uncovering through EFA.

2.  A description of the sample (e.g. demographic information, sample size, sampling method).

3.  A description of the type of data used (e.g., nominal, continuous) and descriptive statistics.

4.  Describe how you went about testing the assumptions for EFA. Details regarding sphericity checks and measures of sampling adequacy should be reported.

5.  Explain what FA extraction method (e.g. 'Minimum residuals' or 'Maximum likelihood') was used.

6.  Explain the criteria and process used for deciding how many factors were extracted in the final solution, and which items were selected. Clearly explain the rationale for key decisions during the EFA process.

7.  Explain what rotation methods were attempted, the reasons why, and the results.

8.  Final factor loadings should be reported in the results, in a table. This table should also report the uniqueness (or communality) for each variable (in the final column). Factor loadings should be reported with descriptive labels in addition to item numbers. Correlations between the factors should also be included, either at the bottom of this table, in a separate table.

9.  Meaningful names for the extracted factors should be provided. You may like to use previously selected factor names, but on examining the actual items and factors you may think a different name is more appropriate --->


希望讀者現在已經了解如何使用jamovi 執行探索性因素分析。 接下來,完成探索性因素分析後,報告要如何撰寫呢?其實並沒有標準的探索性因素分析報告格式，不同領域或學術社群各有習慣的範例。在此只介紹因素分析報告應包含的資訊：

1. 你目前的研究所遵循的理論基礎,特別是透過探索性因素分析而發現的理論建構。  

2. 描述樣本資訊(例如人口統計訊息、樣本量、取樣方法)。  

3. 描述資料類型(例如名義變項、連續變項)以及描述統計資訊。  

4. 描述執行探索性因素分析的條件。 尤其是球形假設檢定以及樣本適足性檢定的詳細資訊。

5. 描述提取潛在因素的方法(例如“最小殘差法”或“最大似然法”)。  

6. 描述決定因素數目以及題目的標準和過程。建議清楚說明探索性因素分析過程每個決定的理由。

7. 描述所使用的轉軸方法、原因以及結果。  

8. 整理最後算出的因素負荷量於報告的表格中。 表格內容的最後一列應報告每個變項的獨特性(或公因性)。 除了項目編號,因素負荷量還要附上描述性標籤。 因素之間的相關係數也應呈現於表格內,無論是在總表格的底部或單獨製表。

9. 為決定提取的潛在因素取個有意義的名稱。 可以是預先選定的名稱,檢視有效的題目與最後提取的因素後,可以更換為更合適的名稱。


## 主成分分析

<!--- In the previous section we saw that EFA works to identify underlying latent factors. And, as we saw, in one scenario the smaller number of latent factors can be used in further statistical analysis using some sort of combined factor scores.

In this way EFA is being used as a "data reduction" technique. Another type of data reduction technique, sometimes seen as part of the EFA family, is **principal component analysis (PCA)** . However, PCA does not identify underlying latent factors. Instead it creates a linear composite score from a larger set of measured variables.

PCA simply produces a mathematical transformation to the original data with no assumptions about how the variables co-vary. The aim of PCA is to calculate a few linear combinations (components) of the original variables that can be used to summarize the observed data set without losing much information. However, if identification of underlying structure is a goal of the analysis, then EFA is to be preferred. And, as we saw, EFA produces factor scores that can be used for data reduction purposes just like principal component scores [@Fabrigar1999].

PCA has been popular in Psychology for a number of reasons, and therefore it's worth mentioning, although nowadays EFA is just as easy to do given the power of desktop computers and can be less susceptible to bias than PCA, especially with a small number of factors and variables. Much of the procedure is similar to EFA, so although there are some conceptual differences, practically the steps are the same, and with large samples and a sufficient number of factors and variables, the results from PCA and EFA should be fairly similar.

To undertake PCA in jamovi, all you need to do is select 'Factor' - 'Principal Component Analysis' from the main jamovi button bar to open the PCA analysis window. Then you can follow the same steps from [EFA in jamovi] above. --->


[探索性因素分析]一節示範如何決定影響題目變項的潛在因素。範例也說明在某些情況，有較少的因素的變項結構，有利使用綜合的因素分數做進一步的統計分析中。

這種方法被稱為“資料降維”，除了探索性因素分析，研究者也可以用**主成分分析(principal component analysis, PCA)**做“資料降維”。不過，PCA並是不用來辨識潛在因素,而是從更大的測量變項集合建立線性綜合分數。

PCA只是產生原始資料的數學轉換,並不限制變項之間必須存在共變。目的是計算原始變項的幾種可能線性組合,這些組件可以用來總結收集的資料,且幾乎不丟失任何資訊。然而,如果分析的目的是辨識潛在的變項結構,那麼應該使用探索性因素分析。正如[探索性因素分析]的範例,此方法產生的因素分數與主成分分析一樣可以達到資料降維 [@Fabrigar1999]。

因為過去使用計算機並不容易，上個世紀的心理學研究很流行使用PCA，所以在此介紹一下。如今各型電腦的計算能力越來越強大，使得研究者完成探索性因素分析時間成本大幅降低,而且與PCA相比,特別是在因素和變項數量較少的情況,探索性因素分析更能避免誤差。PCA的大部分程序與探索性因素分析相似,所以儘管執行條件有一些差異,但是實際操作步驟是相同的,並且對於足夠大的樣本以及充分數量的因素和變項,PCA和EFA的結果應該差不多。  


要使用jamovi執行PCA,只要從主界面按鈕欄選擇“因子” - “主成分分析”以打開PCA分析視窗。 然後,您可以遵循[使用jamovi完成探索性因素分析]的示範步驟，就能完成PCA。


## 驗證性因素分析

<!---So, our attempt to identify underlying latent factors using EFA with carefully selected questions from the personality item pool seemed to be pretty successful. The next step in our quest to develop a useful measure of personality is to check the latent factors we identified in the original EFA with a different sample. We want to see if the factors hold up, if we can confirm their existence with different data. This is a more rigorous check, as we will see. And it's called **Confirmatory Factor Analysis (CFA)** as we will, unsurprisingly, be seeking to confirm a pre-specified latent factor structure.[^factor-analysis-8]

[^factor-analysis-8]: As an aside, given that we had a pretty firm idea from our initial "putative" factors, we could just have gone straight to CFA and skipped the EFA step. Whether you use EFA and then go on to CFA, or go straight to CFA, is a matter of judgement and how confident you are initially that you have the model about right (in terms of number of factors and variables). Earlier on in the development of scales, or the identification of underlying latent constructs, researchers tend to use EFA. Later on, as they get closer to a final scale, or if they want to check an established scale in a new sample, then CFA is a good option.

In CFA, instead of doing an analysis where we see how the data goes together in an exploratory sense, we instead impose a structure, like in @fig-fig15-13, on the data and see how well the data fits our pre-specified structure. In this sense, we are undertaking a confirmatory analysis, to see how well a pre-specified **model** is confirmed by the observed data.

A straightforward confirmatory factor analysis (CFA) of the personality items would therefore specify five latent factors as shown in @fig-fig15-13, each measured by five observed variables. Each variable is a measure of an underlying latent factor. For example, A1 is predicted by the underlying latent factor Agreeableness. And because A1 is not a perfect measure of the Agreeableness factor, there is an error term, $e$, associated with it. In other words, $e$ represents the variance in A1 that is not accounted for by the Agreeableness factor. This is sometimes called **measurement error**.

Initial pre-specification of latent factor structure for the five factor personality scales, for use in CFA. --->

使用精選自<a href="http://ipip.ori.org" target="_blank">國際性格量表題庫</a>的網路問卷資料來確定人類性格的潛在因素似乎相當有效。開發可用的性格測量工具的下一步，是招募不同樣本檢驗從探索性因素分析確定的潛在因素。研究人員想知道能否用另一批資料驗證這些因素,為了進行驗證,研究人員需要一個更嚴格的方法，也就是這一節介紹的**驗證性因素分析(CFA)**。這種因素分析是開發出來確認預先指定的潛在因素結構。 [^factor-analysis-8]  


[^factor-analysis-8]: 此外,若是研究人員對最初“假設”的因素結果相當有信心,可以9跳過EFA而直接進行CFA。要先使用EFA然後進行CFA,還是直接進行CFA,這在很大程度上取決於研究人員最初對模型準確性(就因素和變項數量來源)的判斷和信心。在量表開發的早期階段或確定潛在因素結構的時候,多數研究人員傾向使用EFA。接近完成最終版量表，或者想用新樣本檢查已建立的量表,CFA是一個不錯的選擇。

執行CFA不會用探索性的方式查看資料的整合方式,而是像 @fig-fig15-13 所示先建立一套因素結構，查看資料符合我們預先指定的結構的程度。研究人員使用CFA時的主要目的，是想要查看反應資料對預先指定的**模型**的確認程度。

直接對這些性格題目資料進行確證性因素分析將如 @fig-fig15-13 所示指定五個潛在因素,每個因素各以五個反應變項測量，每個變項被認定是潛在因素的測量尺度之一。例如,題目A1的反應可被潛在因素「親和力」預測，然而因為A1不能完美測量親和力,所以變項的變異還包括一個誤差項$e$。換句話說,$e$代表了A1中無法被親和力因子預測的變異，這個部分又被稱為**測量誤差**。  



```{r}
#| label: fig-fig15-13
#| classes: .enlarge-image
#| fig-cap: 根據預先指定的潛在因素結構，使用確認性因素分析檢驗五大性格特徵量表題目與影響因素。
knitr::include_graphics("images/fig15-13.png")
```

<!--- The next step is to consider whether the latent factors should be allowed to correlate in our model. As mentioned earlier, in the psychological and behavioural sciences constructs are often related to each other, and we also think that some of our personality factors may be correlated with each other. So, in our model, we should allow these latent factors to co-vary, as shown by the double-headed arrows in @fig-fig15-13.

At the same time, we should consider whether there is any good, systematic, reason for some of the error terms to be correlated with each other. One reason for this might be that there is a shared methodological feature for particular sub-sets of the observed variables such that the observed variables might be correlated for methodological rather than substantive latent factor reasons. We'll return to this possibility in a later section but, for now, there are no clear reasons that we can see that would justify correlating some of the error terms with each other

Without any correlated error terms, the model we are testing to see how well it fits with our observed data is just as specified in @fig-fig15-13. Only parameters that are included in the model are expected to be found in the data, so in CFA all other possible parameters (coefficients) are set to zero. So, if these other parameters are not zero (for example there may be a substantial loading from A1 onto the latent factor Extraversion in the observed data, but not in our model) then we may find a poor fit between our model and the observed data.

Right, let's take a look at how we set this CFA analysis up in jamovi. --->


接著要考慮模型裡的潛在因素是否應該有相關性。如同[探索性因素分析]的範例，心理和行為科學的模型經常有彼此相關的因素，心理學家也同意各種性格特徵可能互有關聯。因此五大人格的模型裡，也包括潛在因素之間的共變，如同 @fig-fig15-13 中串連各潛在因素的雙向箭頭。

研究人員同時要考慮某些測量誤差因為任何合理的、有系統性的理由而互有相關。如此設定的一個原因可能是有幾種反應變項之間存在共變的測量誤差,以致反應變項之間的相關可能是出於研究方法造成的系統誤差，而非與潛在變項的關聯性。下一節[多種特質多項相關驗證性因素分析]介紹的進階方法將討論如何處理這種可能性,目前因為沒有任何明確的理由確認某些誤差項彼此相關，因此先不討論。

如果沒有必要檢查誤差項之間的相關,研究人員只要檢測 @fig-fig15-13 所指定的因素結構，與反應資料的匹配程度。由於預期只有模型裡的因素才能由資料變項提取，所以與模型內因素及變項無關的係數都被設置為零，例如,A1的原始資料與潛在因素「外向性」有高負荷量,但在是要驗證的模型假設此係數為零。如果與模型無關的係數不為零，確認性因素分析結果可能會顯示模型與資料之間的匹配程度不高。

接著來看看如何使用jamovi設定確認性因素分析的報行參數。

### 使用jamovi完成驗證性因素分析

<!--- Open up the *bfi_sample2.csv*  file, check that the 25 variables are coded as ordinal (or continuous; it won't make any difference for this analysis). To perform CFA in jamovi:

- Select Factor - Confirmatory Factor Analysis from the main jamovi button bar to open the CFA analysis window (@fig-fig15-14).

- Select the 5 A variables and transfer them into the 'Factors' box and give then the label "Agreeableness".

- Create a new Factor in the 'Factors' box and label it "Conscientiousness". Select the 5 C variables and transfer them into the 'Factors' box under the "Conscientiousness" label.

- Create another new Factor in the 'Factors' box and label it "Extraversion". Select the 5 E variables and transfer them into the 'Factors' box under the "Extraversion" label.

- Create another new Factor in the 'Factors' box and label it "Neuroticism". Select the 5 N variables and transfer them into the 'Factors' box under the "Neuroticism" label.

- Create another new Factor in the 'Factors' box and label it "Openness". Select the 5 O variables and transfer them into the 'Factors' box under the "Openness" label.

- Check other appropriate options, the defaults are ok for this initial work through, though you might want to check the "Path diagram" option under 'Plots' to see jamovi produce a (fairly) similar diagram to our @fig-fig15-13.

The jamovi CFA analysis window.--->

打開 _bfi\_sample2.csv_ 文件,檢查25個變項是否被編碼為順序變項(或連續變項;對於這個分析不會產生任何區別)。要在jamovi中執行確認性因素分析:

- 從主界面按鈕欄中選擇“因子” - “確認性因素分析”以打開確認性因素分析窗口(@fig-fig15-14)。  

- 在“因子”框中選擇5個A變項並將其轉移到“因子”框中,並給予“親和力”的標籤。  

- 在“因子”框中創建一個新的因子並給它貼上“盡責性”的標籤。選擇5個C變項並將其轉移到“盡責性”標籤下的“因子”框中。

- 在“因子”框中再創建一個新的因子並給它貼上“外向性”的標籤。選擇5個E變項並將其轉移到“外向性”標籤下的“因子”框中。  

- 在“因子”框中再創建一個新的因子並給它貼上“神經質”的標籤。選擇5個N變項並將其轉移到“神經質”標籤下的“因子”框中。

- 在“因子”框中再創建一個新的因子並給它貼上“開放性”的標籤。選擇5個O變項並將其轉移到“開放性”標籤下的“因子”框中。  

- 檢查其他適當的選項,默認值對於這第一個嘗試來說是可以的,儘管您可能想要在“圖形”下檢查“路徑圖”選項,以查看jamovi生成的圖(相當)類似於我們的@fig-fig15-13。



```{r}
#| label: fig-fig15-14
#| classes: .enlarge-image
#| fig-cap: jamovi確認性因素分析窗口
knitr::include_graphics("images/fig15-14.png")
```

<!--- Once we have set up the analysis we can turn our attention to the jamovi results window and see what's what. The first thing to look at is **model fit** (@fig-fig15-15) as this tells us how good a fit our model is to the observed data. NB in our model only the pre-specified covariances are estimated, including the factor correlations by default. Everything else is set to zero.

The jamovi CFA Model Fit results for our CFA model. --->

設定好分析後,我們可以將注意力轉到jamovi的結果窗口,看看情況如何。首先要看的是**模型適配度**(@fig-fig15-15),因為這告訴了我們模型與反應資料的匹配程度。請注意,在我們的模型中,只估計了預先指定的協方差,默認包括因子相關。其餘都設置為零。  

  


```{r}
#| label: fig-fig15-15
#| classes: .enlarge-image
#| fig-cap: jamovi CFA模型適配結果
knitr::include_graphics("images/fig15-15.png")
```

<!--- There are several ways of assessing model fit. The first is a chi-square statistic that, if small, indicates that the model is a good fit to the data. However, the chi-squared statistic used for assessing model fit is pretty sensitive to sample size, meaning that with a large sample a good enough fit between the model and the data almost always produces a large and significant ($p$ < .05) chi-square value.

So, we need some other ways of assessing model fit. In jamovi several are provided by default. These are the Comparative Fit Index (CFI), the Tucker Lewis Index (TLI) and the Root Mean Square Error of Approximation (RMSEA) together with the 90% confidence interval for the RMSEA. Some useful rules of thumb are that a satisfactory fit is indicated by CFI > 0.9, TLI > 0.9, and RMSEA of about 0.05 to 0.08. A good fit is CFI > 0.95, TLI > 0.95, and RMSEA and upper CI for RMSEA < 0.05.

So, looking at @fig-fig15-15 we can see that the chi-square value is large and highly significant. Our sample size is not too large, so this possibly indicates a poor fit. The CFI is $0.762$ and the TLI is 0.731, indicating poor fit between the model and the data. The RMSEA is $0.085$ with a $90\%$ confidence interval from $0.077$ to $0.092$, again this does not indicate a good fit.

Pretty disappointing, huh? But perhaps not too surprising given that in the earlier EFA, when we ran with a similar data set (see [Exploratory Factor Analysis] section), only around half of the variance in the data was accounted for by the five factor model.

Let's go on to look at the factor loadings and the factor covariance estimates, shown in @fig-fig15-16 and @fig-fig15-17. The Z-statistic and p-value for each of these parameters indicates they make a reasonable contribution to the model (i.e. they are not zero) so there doesn't appear to be any reason to remove any of the specified variable-factor paths, or factor-factor correlations from the model. Often the standardized estimates are easier to interpret, and these can be specified under the 'Estimates' option. These tables can usefully be incorporated into a written report or scientific article.

The jamovi CFA Factor Loadings table for our CFA model.

The jamovi CFA Factor Covariances table for our CFA model. --->

有幾種方法可以評估模型的適配度。第一個是卡方統計量,如果很小,則表示模型與資料的匹配很好。 然而,用於評估模型適配的卡方統計對樣本大小相當敏感,這意味著對於大樣本而言,模型與資料之間足夠好的匹配幾乎總會產生很大的顯著($p$ < .05)卡方值。  

因此,我們需要其他的模型適配度評估方法。在 jamovi 中預設提供了幾種。這些是比較適配指數(CFI)、塔克-劉易斯指數(TLI)和近似誤差均方根(RMSEA)以及 RMSEA 的 90%置信區間。一些實用的經驗法則是,CFI > 0.9、TLI > 0.9和 RMSEA 約為 0.05 到 0.08 表示滿意的適配。CFI > 0.95、TLI > 0.95和 RMSEA 及 RMSEA 上界 CI < 0.05 表示很好的適配。  

所以,看@fig-fig15-15我們可以看到,卡方值很大並且顯著性很高。我們的樣本量不大,所以這可能表示模型適配較差。CFI為$0.762$,TLI為0.731,表示模型與資料之間的匹配較差。RMSEA為$0.085$,90%置信區間從$0.077$到$0.092$,同樣也沒有顯示很好的適配。  

這個結果相當令人失望,不是嗎?但考慮到在前一節的 EFA 分析中,當我們使用類似的資料集(見 [探索性因素分析])運行時,五因子模型只描述了資料中的大約一半變異,這結果可能也不太令人驚訝。  

讓我們繼續查看@fig-fig15-16和@fig-fig15-17中顯示的因子加載量和因子協方差估計。 每個參數的 Z 統計量和 P 值表明他們對模型做出了合理的貢獻(即它們不為零),所以沒有任何理由從模型中刪除任何指定的變項-因子路徑或因子-因子相關。通常標準化估計值更容易解釋,這些可以在“估計”選項下指定。 這些表可以用fully併入書面報告或科學文章中。  






```{r}
#| label: fig-fig15-16
#| classes: .enlarge-image
#| fig-cap: jamovi CFA因子加載表  
knitr::include_graphics("images/fig15-16.png")
```

```{r}
#| label: fig-fig15-17
#| classes: .enlarge-image
#| fig-cap: jamovi CFA因子協方差表  
knitr::include_graphics("images/fig15-17.png")
```

<!---How could we improve the model? One option is to go back a few stages and think again about the items / measures we are using and how they might be improved or changed. Another option is to make some post hoc tweaks to the model to improve the fit. One way of doing this is to use "modification indices" (@fig-fig15-18), specified as an 'Additional output' option in jamovi.

The jamovi CFA Factor Loadings Modification Indices.--->


我們如何改進模型呢?一個選擇是返回幾個階段並重新考慮我們正在使用的項目/測量以及如何改進或更改它們。另一種選擇是對模型進行一些事後調整以改進適配度。實現這一目的的一種方法是使用“修正指數”(@fig-fig15-18),在 jamovi 中它被指定為“其他輸出”選項。  

```{r}
#| label: fig-fig15-18
#| classes: .enlarge-image
#| fig-cap: jamovi CFA 因子加載修正指數  
knitr::include_graphics("images/fig15-18.png")
```

<!---What we are looking for is the highest modification index (MI) value. We would then judge whether it makes sense to add that additional term into the model, using a *post hoc* rationalisation. For example, we can see in @fig-fig15-18 that the largest MI for the factor loadings that are not already in the model is a value of 28.786 for the loading of N4 ("Often feel blue") onto the latent factor Extraversion. This indicates that if we add this path into the model then the chi-square value will reduce by around the same amount.

But in our model adding this path arguably doesn't really make any theoretical or methodological sense, so it's not a good idea (unless you can come up with a persuasive argument that "Often feel blue" measures both Neuroticism and Extraversion). I can't think of a good reason. But, for the sake of argument, let's pretend it does make some sense and add this path into the model. Go back to the CFA analysis window (see @fig-fig15-14) and add N4 into the Extraversion factor. The results of the CFA will now change (not shown); the chi-square has come down to around 709 (a drop of around 30, roughly similar to the size of the MI) and the other fit indices have also improved, though only a bit. But it's not enough: it's still not a good fitting model.

If you do find yourself adding new parameters to a model using the MI values then always re-check the MI tables after each new addition, as the MIs are refreshed each time.

There is also a Table of Residual Covariance Modification Indices produced by jamovi (@fig-fig15-19). In other words, a table showing which correlated errors, if added to the model, would improve the model fit the most. It's a good idea to look across both MI tables at the same time, spot the largest MI, think about whether the addition of the suggested parameter can be reasonably justified and, if it can, add it to the model. And then you can start again looking for the biggest MI in the re-calculated results.

Residual Covariance Modification Indices produced by jamovi.--->



我們要尋找的是最大修正指數(MI)值。 然後,我們將判斷是否有理由將該附加項添加到模型中,使用事後合理化。 例如,我們可以在@fig-fig15-18中看到,在模型中還沒有的因子加載量中,最大的 MI 值是 N4(“經常感到沮喪”)加載到潛在因子外向性上的值 28.786。 這表明如果我們將此路徑添加到模型中,卡方值將減少差不多相同的量。  

但是在我們的模型中增加這條路徑在理論上或方法論上並不合理,所以這並不是一個好主意(除非您能提出有說服力的論據認為“經常感到沮喪”同時測量神經質和外向性)。 我想不出好的理由。 但是,為了論證的目的,讓我們假裝確實有一定的意義並將此路徑添加到模型中。 返回確認性因素分析窗口(@fig-fig15-14)並將 N4 添加到外向性因子中。 CFA 的結果現在會改變(未顯示); 卡方下降到約 709 左右(下降了約 30,大致與 MI 的大小相當),其他適配指標也有所改善,儘管只是一點點。 但這還不夠:這仍然不是一個很好的匹配模型。  

如果您發現自己正在使用 MI 值向模型中添加新的參數,則每次新增後都應重新檢查 MI 表,因為 MI 會在每次重新計算。  

jamovi 還產生了殘差協方差修正指數表(@fig-fig15-19)。 換句話說,如果將這些相關誤差添加到模型中,那麼這是一個顯示哪些相關誤差可以最大程度改進模型適配的表格。同時查看這兩個 MI 表是一個好主意,找出最大的 MI,考慮是否可以合理證明建議參數的增加,如果可以的話,將其添加到模型中。 然後,您可以在重新計算的結果中再次開始尋找最大的 MI。  



```{r}
#| label: fig-fig15-19
#| out.width: 60%
#| classes: .enlarge-image
#| fig-cap: jamovi 產生的殘差協方差修正指數 
knitr::include_graphics("images/fig15-19.png")
```

<!--- You can keep going this way for as long as you like, adding parameters to the model based on the largest MI, and eventually you will achieve a satisfactory fit. But there will also be a strong possibility that in doing this you will have created a monster! A model that is ugly and deformed and doesn't have any theoretical sense or purity. In other words, be very careful!

So far, we have checked out the factor structure obtained in the EFA using a second sample and CFA. Unfortunately, we didn't find that the factor structure from the EFA was confirmed in the CFA, so it's back to the drawing board as far as the development of this personality scale goes.

Although we could have tweaked the CFA using modification indexes, there really were not any good reasons (that I could think of) for these suggested additional factor loadings or residual covariances to be included. However, sometimes there is a good reason for residuals to be allowed to co-vary (or correlate), and a good example of this is shown in the next section on [Multi-Trait Multi-Method CFA]. Before we do that, let's cover how to report the results of a CFA. --->


您可以盡可能長時間以這種方式繼續操作——根據最大的 MI 將參數添加到模型中,最終您將實現令人滿意的適配效果。 但這樣做的強大可能性是您將創建一個怪物!一個醜陋、畸形的模型,在理論上毫無意義或純粹性。 換句話說,要非常小心!  

到目前為止,我們已經使用第二個樣本和確認性因素分析檢查了在探索性因素分析中獲得的因子結構。 不幸的是,我們發現探索性因素分析中的因子結構在確認性因素分析中沒有被確認,所以就這個人格特徵量表的開發而言,我們又回到了起點。  

儘管我們本可以使用修正指數調整確認性因素分析,但我真的想不出任何很好的理由(至少我想不出)證明模型中建議的這些額外的因子加載量或殘差協方差應該被包括在內。 然而,在某些情況下,允許殘差共變(或相關)是有很好理由的,下一節 [多種特質多項相關驗證性因素分析] 就給出了一個很好的例子。 在進入下一部分之前,讓我們先了解如何報告確認性因素分析的結果。  

### 驗證性因素分析的報告須知

<!---There is not a formal standard way to write up a CFA, and examples tend to vary by discipline and researcher. That said, there are some fairly standard pieces of information to include in your write-up:

1.  A theoretical and empirical justification for the hypothesized model.

2.  A complete description of how the model was specified (e.g. the indicator variables for each latent factor, covariances between latent variables, and any correlations between error terms). A path diagram, like the one in @fig-fig15-13 would be good to include.

3.  A description of the sample (e.g. demographic information, sample size, sampling method).

4.  A description of the type of data used (e.g., nominal, continuous) and descriptive statistics.

5.  Tests of assumptions and estimation method used.

6.  A description of missing data and how the missing data were handled.

7.  The software and version used to fit the model.

8.  Measures, and the criteria used, to judge model fit.

9.  Any alterations made to the original model based on model fit or modification indices.

10. All parameter estimates (i.e., loadings, error variances, latent (co)variances) and their standard errors, probably in a table. --->



確認性因素分析報告沒有正式的標準格試,不同領域或學術社群的報告範例也有所不同。儘管如此,建議報告裡應包括以下幾項:  

1. 描述假設模型的理論和實證依據。   

2. 完整描述模型內的因素關聯性(例如,每個潛在因素的影響變項,潛在變項之間的共變異數，以及任何誤差項之間的相關係數)。以 @fig-fig15-13 這樣的路徑圖呈現在報告是種清楚的報告方法。   

3. 描述樣本資訊(例如人口統計資訊、樣本量、取樣方法)。 

4. 描述資料類型(例如名義變項、連續變項)以及完整的描述統計。   

5. 描述使用條件的檢驗方法，以及關鍵係數的估計方法。   

6. 描述缺失資料的來源以及處理方式。   

7. 測試模型適配度的軟體和版本。   

8. 判斷模型適配度的測量尺度和標準。   

9. 基於模型適配度或修正指數所進行的模型變更。   

10. 以表格整理所有參數估計值(因素負荷量、誤差變異數、潛在變異數或共變數)及其標準誤。

## 多種特質多項相關驗證性因素分析

<!--- In this section we're going to consider how different measurement techniques or questions can be an important source of data variability, known as **method variance**. To do this, we'll use another psychological data set, one that contains data on "attributional style".

The Attributional Style Questionnaire (ASQ) was used [@Hewitt2004] to collect psychological wellbeing data from young people in the United Kingdom and New Zealand. They measured attributional style for negative events, which is how people habitually explain the cause of bad things that happen to them [@Peterson1984]. The attributional style questionnaire (ASQ) measures three aspects of attributional style:

- Internality is the extent to which a person believes that the cause of a bad event is due to his/her own actions.

- Stability refers to the extent to which a person habitually believes the cause of a bad event is stable across time.

- Globality refers to the extent to which a person habitually believes that the cause of a bad event in one area will affect other areas of their lives.

There are six hypothetical scenarios and for each scenario respondents answer a question aimed at (a) internality, (b) stability and (c) globality. So there are $6 \times 3 = 18$ items overall. See @fig-fig15-20 for more details.

The Attributional Style Questionnaire (ASQ) for negative events. --->

這一節介紹的因素分析方法將考慮**方法變異**，也就是來自不同的測量尺度或題目所形成的資料變異。所以這一節的範例採用另一個包含“歸因風格”的資料檔案。  

@Hewitt2004 歸因風格問卷(ASQ)從英國和紐西蘭的年輕人收集心理健康資料，他們測量了負面事件的歸因風格,這是指每個人有自行解釋壞事如何發生的歸因類型[@Peterson1984]。言份問卷測量三種歸因風格:  

- 內隱性(Internality)是他/她相信壞事發生是個人行為造成的程度。  

- 穩定性(Stability)是指他/她習慣地認為隔一段時間就會發生壞事的程度。  

- 全局性(Globality)是指他/她習慣地認為導致一件壞事的原因會影響個人生活各層面的程度。  

問卷設定六種假設情境,對於每種情境,受測者要根據情境設定，回答一組問題,回答是用於測量(a)內隱性,(b)穩定性和(c)全局性。所以要填的問題總共有$6 \times 3 = 18$個。英文版問卷內容請參考 @fig-fig15-20 。  


```{r}
#| label: fig-fig15-20
#| classes: .enlarge-image
#| fig-cap: 負面事件的歸因風格問卷(ASQ)部分題目 
knitr::include_graphics("images/fig15-20.png")
```

<!--- Researchers are interested in checking their data to see whether there are some underlying latent factors that are measured reasonably well by the 18 observed variables in the ASQ.

First, they try EFA with these 18 variables (not shown), but no matter how they extract or rotate, they can't find a good factor solution. Their attempt to identify underlying latent factors in the Attributional Style Questionnaire (ASQ) proved fruitless. If you get results like this then either your theory is wrong (there is no underlying latent factor structure for attributional style, which is possible), the sample is not relevant (which is unlikely given the size and characteristics of this sample of young adults from the United Kingdom and New Zealand), or the analysis was not the right tool for the job. We're going to look at this third possibility.

Remember that there were three dimensions measured in the ASQ: Internality, Stability and Globality, each measured by six questions as shown in @fig-fig15-21.

What if, instead of doing an analysis where we see how the data goes together in an exploratory sense, we instead impose a structure, like in @fig-fig15-21, on the data and see how well the data fits our pre-specified structure. In this sense, we are undertaking a confirmatory analysis, to see how well a pre-specified model is confirmed by the observed data.

A straightforward confirmatory factor analysis (CFA) of the ASQ would therefore specify three latent factors as shown in the columns of @fig-fig15-27, each measured by six observed variables.

Six questions on the ASQ for each of the Internality, Stability and Globality dimensions. --->


研究人員想要分析他們收集的資料,評估ASQ的18個反應變項是否確實測量到有興趣的潛在因素。  

首先,他們使用探索性因素分析,但嘗試各種因素選取或轉軸方法,都找不到一個好的因素結構，因此沒有得到可靠的結論。像這樣的狀況，要麼研究人員的理論是錯誤的(歸因風格可能不是潛在因素),要麼選取到不相關的樣本(樣本規模和特徵可能不是英國和紐西蘭的年輕人),要麼分析方法不是解決這項研究問題的合適工具。在此我們探研第三種可能性。  

我們先將ASQ測量的三種歸因：內隱性、穩定性和全局性，還有各情境的六項題目測量資料的關聯性，以 @fig-fig15-21 的路徑圖呈現。  

如果研究人員不用探索性的分析方法找出資料變項的組合，而是預先設定如同 @fig-fig15-21 的因素及變項結構,那要如何檢驗資料符合這套結構的程度？這樣的分析角度是一種確認性分析,重點是檢視原始資料適配預先指定模型的程度。實際使用ASQ資料執行確證性因素分析，要先確認每位受測者有如同 @fig-fig15-27 所列的18項反應資料，三個因素各有六個測量變項。





```{r}
#| label: fig-fig15-21
#| classes: .enlarge-image
#| fig-cap: ASQ包括的三個潛在因素~內隱性、穩定性和全局性及對應的六道題目編碼
knitr::include_graphics("images/fig15-21.png")
```

<!--- We could depict this as in the diagram in @fig-fig15-22, which shows that each variable is a measure of an underlying latent factor. For example INT1 is predicted by the underlying latent factor Internality. And because INT1 is not a perfect measure of the Internality factor, there is an error term, e1, associated with it. In other words, e1 represents the variance in INT1 that is not accounted for by the Internality factor. This is sometimes called "measurement error".

Initial pre-specification of latent factor structure for the ASQ. --->

每個變項與潛在因素可以描繪成 @fig-fig15-22 的路徑圖。例如,INT1受到潛在因素內隱性影響，並且因為INT1無法完美測量內隱性,所以還有誤差項$e_1$。換句話說,$e_1$代表INT1無法被內隱性解釋的變異，這種誤差又被稱為“測量誤差”。  



```{r}
#| label: fig-fig15-22
#| classes: .enlarge-image
#| fig-cap: ASQ潛在因子結構的最初預先指定  
knitr::include_graphics("images/fig15-22.png")
```

<!--- The next step is to consider whether the latent factors should be allowed to correlate in our model. As mentioned earlier, in the psychological and behavioural sciences constructs are often related to each other, and we also think that Internality, Stability, and Globality might be correlated with each other, so in our model we should allow these latent factors to co-vary, as shown in @fig-fig15-23.

Final pre-specification of latent factor structure for the ASQ, including latent factor correlations, and shared method error term correlations for the observed variable INT1, STAB1 and GLOB1, in a CFA MTMM model. For clarity, other pre-specified error term correlations are not shown. --->

接著要考慮模型裡的潛在因素是否應該有相關性。如同探索性因素分析的範例，心理和行為科學的模型經常有彼此相關的因素，使用ASQ的研究人員也同意內隱性、穩定性和全局性可能互有關聯。因此 @fig-fig15-23 展示的模型還包括潛在因素之間的共變，以串連各潛在因素的雙向箭頭表示。

@fig-fig15-23 還有呈現共用方法誤差之間的相關性，也就是INT1, STAB1 與 GLOB1 三個項目誤差項之間的雙向箭頭。為了保持視覺簡潔，其他誤差異的相關性就予以省略。




```{r}
#| label: fig-fig15-23
#| classes: .enlarge-image
#| fig-cap: 進行CFA MTMM分析前，預先假設的ASQ 潛在因素結構最終版,包括潛在因素之間相關、以及反應變項INT1、STAB1和GLOB1的共享方法誤差之間相關。為清楚起見,未呈現其他預先指定的誤差項相關。
knitr::include_graphics("images/fig15-23.png")
```

<!--- At the same time, we should consider whether there is any good, systematic, reason for some of the error terms to be correlated with each other. Thinking back to the ASQ questions, there were three different sub-questions (a, b and c) for each main question (1-6). Q1 was about unsuccessful job hunting and it is plausible that this question has some distinctive artefactual or methodological aspects over and above the other questions (2-5), something to do with job hunting perhaps. Similarly, Q2 was about not helping a friend with a problem, and there may be some distinctive artefactual or methodological aspects to do with not helping a friend that is not present in the other questions (1, and 3-5).

So, as well as multiple factors, we also have multiple methodological features in the ASQ, where each of Questions 1-6 has a slightly different "method", but each "method" is shared across the sub-questions a, b and c. In order to incorporate these different methodological features into the model we can specify that certain error terms are correlated with each other. For example, the errors associated with INT1, STAB1 and GLOB1 should be correlated with each other to reflect the distinct and shared methodological variance of Q1a, Q1b and Q1c. Looking at @fig-fig15-21, this means that as well as the latent factors represented by the columns, we will have correlated measurement errors for the variables in each row of the Table.

Whilst a basic CFA model like the one shown in @fig-fig15-22 could be tested against our observed data, we have in fact come up with a more sophisticated model, as shown in the diagram in @fig-fig15-23. This more sophisticated CFA model is known as a **Multi-Trait Multi-Method (MTMM)** model, and it is the one we will test in jamovi. --->


研究人員同時要考慮某些測量誤差因為任何合理的、有系統性的理由而互有相關。仔細看一下ASQ的題目,每個主要題目(1-6)都有三個子題(a、b和c)。Q1與找不到工作有關,這個問題與其他問題(2-5)相比,在找工作方面可能具有某些獨特的人為或方法論特性。同樣地,Q2與不幫助朋友解決問題有關,在不幫助朋友這一點上,與其他問題(1和3-5)相比可能存在某些獨特的人為或方法特性。  

因此,除了不只一個因素,ASQ還有多種方法特性,其中每個主要題目都有特定的“測量方法”,但是每種“測量方法”貫穿a、b和c子題。為了將不同方法特性納入模型,研究人員會指定某些誤差項彼此相關。例如,INT1、STAB1和GLOB1的誤差項應該彼此相關,代表Q1a、Q1b和Q1c各自的方法誤差有共變。


儘管可以用如同 @fig-fig15-22 的基本CFA模型檢驗資料,但這裡設計一個更複雜的模型,如同 @fig-fig15-23 的模型所示。這種更複雜的CFA模型被稱為**多種特質多項相關(MTMM)**模型,以下示範如何使用jamovi執行。


### 使用jamovi完成多種特質多項相關驗證性因素分析

<!---Open up the *ASQ.csv*  file and check that the 18 variables (six "Internality", six "Stability" and six "Globality" variables) are specified as continuous variables.

To perform MTMM CFA in jamovi:

- Select Factor - Confirmatory Factor Analysis from the main jamovi button bar to open the CFA analysis window (@fig-fig15-24).

- Select the 6 INT variables and transfer them into the 'Factors' box and give them the label "Internality".

- Create a new Factor in the 'Factors' box and label it "Stability". Select the 6 STAB variables and transfer them into the 'Factors' box under the "Stability" label.

- Create another new Factor in the 'Factors' box and label it "Globality". Select the 6 GLOB variables and transfer them into the 'Factors' box under the "Globality" label.

- Open up the Residual Covariances options, and for each of our pre-specified correlations move the associated variables across into the 'Residual Covariances' box on the right. For example, highlight both INT1 and STAB1 and then click the arrow to move these across. Now do the same for INT1 and GLOB1, for STAB1 and GLOB1, for INT2 and STAB2, for INT2 and GLOB2, for STAB2 and GLOB2, for INT3 and STAB3, and so on.

- Check other appropriate options, the defaults are ok for this initial work through, though you might want to check the "Path diagram" option under 'Plots' to see jamovi produce a (fairly) similar diagram to our @fig-fig15-23, and including all the error term correlations that we have added above.

The jamovi CFA analysis window. --->


打開 _ASQ.csv_ 文件並檢查18個變項(6個“內隱性”、6個“穩定性”和6個“全局性”變項)是否被指定為連續變項。

要在jamovi中執行多特徵多方法確認性因素分析:  

- 從主界面按鈕欄中選擇“因子” - “確認性因素分析”以打開確認性因素分析窗口(@fig-fig15-24)。

- 在“因子”框中選擇6個INT變項並將其轉移到“因子”框中,並給予“內隱性”的標籤。

- 在“因子”框中創建一個新的因子並給它貼上“穩定性”的標籤。選擇6個STAB變項並將其轉移到“穩定性”標籤下的“因子”框中。  

- 在“因子”框中再創建一個新的因子並給它貼上“全局性”的標籤。選擇6個GLOB變項並將其轉移到“全局性”標籤下的“因子”框中。

- 打開殘差協方差選項,並對於每個預先指定的相關,將相關的變項移動到右側的“殘差協方差”框中。例如,同時突出顯示INT1和STAB1,然後單擊箭頭將其移動。現在對INT1和GLOB1、STAB1和GLOB1、INT2和STAB2、INT2和GLOB2、STAB2和GLOB2、INT3和STAB3等執行相同操作。  

- 檢查其他適當的選項,默認值對於這第一個嘗試來說是可以的,儘管您可能想要在“圖形”下檢查“路徑圖”選項,以查看jamovi生成的圖(相當)類似於我們的@fig-fig15-23,並包括我們上面添加的所有誤差項相關。  





```{r}
#| label: fig-fig15-24
#| classes: .enlarge-image
#| fig-cap: jamovi確認性因素分析窗口
knitr::include_graphics("images/fig15-24.png")
```

<!---Once we have set up the analysis we can turn our attention to the jamovi results window and see what's what. The first thing to look at is "Model fit" as this tells us how good a fit our model is to the observed data (@fig-fig15-25). NB in our model only the pre-specified covariances are estimated, everything else is set to zero, so model fit is testing both whether the pre-specified "free" parameters are not zero, and conversely whether the other relationships in the data -- the ones we have not specified in the model -- can be held at zero.

The jamovi CFA Model Fit results for our CFA MTMM model.--->


一旦設定好分析,我們就可以把注意力轉到jamovi的結果窗口,看看狀況如何。首先要看的是“模型適配度”,因為這告訴了我們模型與反應資料的匹配程度(@fig-fig15-25)。請注意,在我們的模型中,只估計了預先指定的協方差,其他都是設定為零,所以模型適配度測試的是預先指定的“自由”參數是否不為零,反過來是否資料中的其他關係——那些我們沒有在模型中指定的關係——可以保持為零。  

```{r}
#| label: fig-fig15-25
#| classes: .enlarge-image
#| fig-cap: jamovi MTMM確認性因素分析模型適配結果
knitr::include_graphics("images/fig15-25.png")
```

<!---
Looking at @fig-fig15-25 we can see that the chi-square value is highly significant, which is not a surprise given the large sample size (N = 2748). The CFI is 0.98 and the TLI is also 0.98, indicating a very good fit. The RMSEA is 0.02 with a 90% confidence interval from 0.02 to 0.02 -- pretty tight!

Overall, I think we can be satisfied that our pre-specified model is a very good fit to the observed data, lending support to our MTMM model for the ASQ.

We can now go on to look at the factor loadings and the factor covariance estimates, as in @fig-fig15-26. Often the standardized estimates are easier to interpret, and these can be specified under the 'Estimates' option. These tables can usefully be incorporated into a written report or scientific article.

The jamovi CFA Factor Loadings and Covariances tables for our CFA MTMM model.
--->

看@fig-fig15-25我們可以看到,卡方值非常顯著,考慮到樣本量很大(N = 2748)這一點就不足為奇了。 CFI為0.98,TLI也為0.98,表示模型適配非常好。 RMSEA為0.02,90%置信區間從0.02到0.02,非常緊密!  

總的來說,我認為我們可以滿意地認為我們預先指定的模型與反應資料的匹配非常好,這支持了我們對ASQ的MTMM模型。  

現在我們可以繼續查看因子加載量和因子協方差估計,如@fig-fig15-26所示。通常標準化估計值更容易解釋,這些可以在“估計”選項下指定。這些表可以很好地併入書面報告或科學文章中。


```{r}
#| label: fig-fig15-26
#| classes: .enlarge-image
#| fig-cap: jamovi MTMM確認性因素分析的因子加載量和協方差表  
knitr::include_graphics("images/fig15-26.png")
```

<!---You can see from @fig-fig15-26 that all of our pre-specified factor loadings and factor covariances are significantly different from zero. In other words, they all seem to be making a useful contribution to the model.

We've been pretty lucky with this analysis, getting a very good fit on our first attempt! --->

從@fig-fig15-26您可以看到,我們預先指定的所有因子加載量和因子協方差明顯不同於零。換句話說,它們似乎都在為模型做出有用的貢獻。  

在這次分析中,我們相當幸運,在第一次嘗試就得到了非常好的適配效果!


## 內部一致性信度分析 {#sec-Internal-consistency-reliability-analysis}

<!---
After you have been through the process of initial scale development using EFA and CFA, you should have reached a stage where the scale holds up pretty well using CFA with different samples. One thing that you might also be interested in at this stage is to see how well the factors are measured using a scale that combines the observed variables.

In psychometrics we use reliability analysis to provide information about how consistently a scale measures a psychological construct (See earlier section on @sec-Assessing-the-reliability-of-a-measurement). **Internal consistency** is what we are concerned with here, and that refers to the consistency across all the individual items that make up a measurement scale. So, if we have $V1, V2, V3, V4$ and $V5$ as observed item variables, then we can calculate a statistic that tells us how internally consistent these items are in measuring the underlying construct.

A popular statistic used to check the internal consistency of a scale is **Cronbach's alpha** [@Cronbach1951]. Cronbach's alpha is a measure of equivalence (whether different sets of scale items would give the same measurement outcomes). Equivalence is tested by dividing the scale items into two groups (a "split-half") and seeing whether analysis of the two parts gives comparable results. Of course, there are many ways a set of items could be split, but if all possible splits are made then it is possible to produce a statistic that reflects the overall pattern of split-half coefficients. Cronbach's alpha ($\alpha$) is such a statistic: a function of all the split-half coefficients for a scale. If a set of items that measure a construct (e.g. an Extraversion scale) has an $\alpha$ of $0.80$, then the proportion of error variance in the scale is $0.20$. In other words, a scale with an $\alpha$ of $0.80$ includes approximately 20% error.

BUT, (and that's a BIG "BUT"), Cronbach's alpha is not a measure of unidimensionality (i.e. an indicator that a scale is measuring a single factor or construct rather than multiple related constructs). Scales that are multidimensional will cause alpha to be under-estimated if not assessed separately for each dimension, but high values for alpha are not necessarily indicators of unidimensionality. So, an $\alpha$ of 0.80 does not mean that 80% of a single underlying construct is accounted for. It could be that the 80% comes from more than one underlying construct. That's why EFA and CFA are useful to do first.

Further, another feature of $\alpha$ is that it tends to be sample specific: it is not a characteristic of the scale, but rather a characteristic of the sample in which the scale has been used. A biased, unrepresentative, or small sample could produce a very different $\alpha$ coefficient than a large, representative sample. $\alpha$ can even vary from large sample to large sample. Nevertheless, despite these limitations, Cronbach's $\alpha$ has been popular in Psychology for estimating internal consistency reliability. It's pretty easy to calculate, understand and interpret, and therefore it can be a useful initial check on scale performance when you administer a scale with a different sample, from a different setting or population, for example.

An alternative is **McDonald's omega** ($\omega$), and jamovi also provides this statistic. Whereas $\alpha$ makes the following assumptions: (a) no residual correlations, (b) items have identical loadings, and (c) the scale is unidimensional, $\omega$ does not and is therefore a more robust reliability statistic. If these assumptions are not violated then $\alpha$ and $\omega$ will be similar, but if they are then $\omega$ is to be preferred.

Sometimes a threshold for $\alpha$ or $\omega$ is provided, suggesting a "good enough" value. This might be something like $\alpha$s of $0.70$ or $0.80$ representing "acceptable" and "good" reliability, respectively. However, this does depend on what exactly the scale is supposed to be measuring, so thresholds like this should be used cautiously. It could be better to simply state that an $\alpha$ or $\omega$ of $0.70$ is associated with 30% error variance in a scale, and an $\alpha$ or $\omega$ of $0.80$ is associated with 20%.

Can $\alpha$ be too high? Probably: if you are getting an $\alpha$ coefficient above $0.95$ then this indicates high inter-correlations between the items and that there might be too much overly redundant specificity in the measurement, with a risk that the construct being measured is perhaps overly narrow.
--->


初步了解運用探索性因素分析和確認性因素分析開發量表的過程後,現在對運用因素分析的認識應該到達了新階段:有效的量表利用不同樣本的確認性因素分析會得到一致的結果。到了這個階段,也許會想知道使用反應變項組合的量表所測得的因素分數有多可信。

心理測量常使用可靠性分析評估心理建構的測量一致性資訊(印象模糊的話，請複習一下 @sec-Assessing-the-reliability-of-a-measurement )。這裡要討論的是**內部一致性**,這是指組成一個量表的所有題目之間一致性。比如有 $V_1、V_2、V_3、V_4$ 和 $V_5$ 等反應變項,就可以計算一個統計量,以此評估這些變項在測量潛在因素的內部一致性。

**克隆巴赫$\alpha$係數**是最常被用來檢驗量表內部一致性的統計量[@Cronbach1951]。克隆巴赫$\alpha$是一種評估測量等價性的指標(不同量表的題目產生相同測量結果的程度)。驗證測量等價性的方法是將量表項目分半,查看各半的分析結果是否具有可比性。同一套題目的題目有多種分半方式,如果比較所有的分半分析結果,就會得到一個反映整體分半等價係數的統計量。克隆巴赫$\alpha$就是這樣一種統計量:綜合一個量表的所有項目分半係數的函數。如果一組測量一個構建的項目(例如外向性量表)的 $\alpha$ 為 $0.80$,那麼該量表的誤差變異比例為 $0.20$。換句話說,$\alpha$ 為 $0.80$ 的量表包括大約 20% 的誤差。

,
**但是**，克隆巴赫$\alpha$不是單維性測量值(指係數呈現單一量表只測量單一因子或構建，而不是測量複數構建)。如果一份量表不只評估一種因素，得到的$\alpha$會是被低估的值。也就是說如果一份評估不只一種潛在因素的量表$\alpha$為0.80，這個量表的題目呈現的一致性不只反映在單一因素。這是為什麼本書建議先進行探索性因素分析或確認性因素分析的原因。


克隆巴赫$\alpha$的另一個特性是會呈現樣本特異性:不只是量表題目的內部一致性，而是樣本資料的特徵也會影響$\alpha$係數。有取樣偏誤、不具代表性或小樣本資料的$\alpha$係數，可能與有代表性的大樣本所測出的$\alpha$係數非常不同。即使是兩套樣本量相當的大型資料之間,$\alpha$也可能不一樣。儘管有這些使用限制,心理學領域一直很愛用克隆巴赫$\alpha$估計內部一致性。因為計算簡單、容易理解和解釋。研究者將量表用於不同樣本、不同環境或人群的施測,可以作為評估量表是否有用的初級指標。  

另一種指標是**麥當勞$\omega$**，也可以用jamovi計算。使用$\alpha$有這些條件：(a)殘差項目之間沒有相關,(b)所有題目的因素負荷量相等,以及(c)量表只有測量單一因素。不過使用$\omega$沒有這些限制，因此是一種更穩健的內部一致性統計量。本書建議如果沒有上述使用條件，$\alpha$和$\omega$的值會相當接近；如果有違反，應優先採用$\omega$。

有的時候研究人員需要一套閾值，判斷$\alpha$或$\omega$夠不夠好。像是$\alpha$為$0.70$ 或 $0.80$ 分別代表量表內部一致性“可接受”及“良好”。更好的報告方法是呈現$\alpha$或$\omega$的值都是$0.70$，且量表測量誤差約佔30%；或者呈現$\alpha$或$\omega$的值都是$0.80$，且量表測量誤差約佔20%。  

$\alpha$太高是不是好事？若是係數值大於$0.95$，表示量表題目之間有高相關，不過測量方法可能存在過度冗餘資訊導致的特異性,而且要測量的因素建構可能有過度窄化之風險。


### 使用jamovi完成內部一致性信度分析

<!---
We have a third sample of personality data to use to undertake reliability analysis: in the bfi_sample3.csv file. Once again, check that the 25 personality item variables are coded as continuous. To perform reliability analysis in jamovi:

- Select Factor - Reliability Analysis from the main jamovi button bar to open the reliability analysis window (@fig-fig15-27).

- Select the 5 A variables and transfer them into the 'Items' box.

- Under the "Reverse Scaled Items" option, select variable A1 in the "Normal Scaled Items" box and move it across to the "Reverse Scaled Items" box.

- Check other appropriate options, as in @fig-fig15-27.

The jamovi Reliability Analysis window.
--->

您提醒得非常到位,文本中还存在简体词汇“變項”和“資料”。已经校对替换为“變項”和“資料”。譯文重新生成如下:  

我們有第三個人格資料樣本可以用於進行可靠性分析:在 bfi\_sample3.csv 檔中。再次檢查25個人格項目變項是否被編碼為連續變項。要在 jamovi 中執行可靠性分析:  

- 從主界面按鈕欄中選擇“因子” - “可靠性分析”以打開可靠性分析窗口(@fig-fig15-27)。   

- 選擇5個A變項並將其轉移到“項目”框中。   

- 在“反向計分項目”選項下,選擇“正常計分項目”框中的A1變項,並將其移動到“反向計分項目”框中。   

- 檢查其他適當的選項,如@fig-fig15-27所示。   


```{r}
#| label: fig-fig15-27
#| classes: .enlarge-image
#| fig-cap: jamovi 可靠性分析窗口
knitr::include_graphics("images/fig15-27.png")
```

<!---
Once done, look across at the jamovi results window. You should see something like @fig-fig15-28. This tells us that the Cronbach's $\alpha$ coefficient for the Agreeableness scale is 0.72. This means that just under 30% of the Agreeableness scale score is error variance. McDonald's $\omega$ is also given, and this is 0.74, not much different from $\alpha$.

The jamovi Reliability Analysis results for the Agreeableness factor.
--->


完成後,查看 jamovi 結果窗口。您應該看到類似 @fig-fig15-28 的內容。這告訴我們親和力量表的克隆巴赫 α 係數為 0.72。這意味著親和力量表分數中的錯誤變異略低於 30%。麥當勞 ω 也給出了,為 0.74,與 α 沒有太大區別。   



```{r}
#| label: fig-fig15-28
#| classes: .enlarge-image
#| fig-cap: jamovi 親和力因子的可靠性分析結果
knitr::include_graphics("images/fig15-28.png")
```

<!---
We can also check how $\alpha$ or $\omega$ can be improved if a specific item is dropped from the scale. For example, $\alpha$ would increase to 0.74 and $\omega$ to 0.75 if we dropped item A1. This isn't a big increase, so probably not worth doing.

The process of calculating and checking scale statistics ($\alpha$ and $\omega$) is the same for all the other scales, and they all had similar reliability estimates apart from Openness. For Openness, the amount of error variance in the Scale score is around 40%, which is high and indicates that Openness is substantially less consistent as a reliable measure of a personality attribute than the other personality scales.
--->


我們也可以檢查如果從量表中刪除特定項目,α 或 ω 如何得到改善。例如,如果刪除項目 A1,α 將增加到 0.74,ω 增加到 0.75。這個增幅並不大,所以可能不值得這樣做。   

計算和檢查量表統計量(α 和 ω)的過程對於所有其他量表也是相同的,除了開放性,它們都有類似的可靠性估計。 對於開放性,量表分數中的錯誤變異量約為 40%,這很高,並表明與其他人格特徵量表相比,開放性作為人格特徵可靠測量的一致性要差得多。  


## 本章小結

這一章我們學習因素分析的相關技術，特別是評估資料內各種相關性的方法。本章的學習重點包括：

- [探索性因素分析]  (EFA)用於辨識資料內的潛在因素。根據因素負荷量，每個觀察變項都有可能代表某個潛在因素。研究者也會使用EFA簡化資料項目，像是使用序列分析整合數個觀察變項為一個因素。 

- [主成分分析] (PCA)是一種簡化資料項目的技術，但是並非用於辨識潛在變項。PCA只是生成觀察變項的線性組合。


- [驗證性因素分析]  (CFA)不同於EFA，執行前已經有一個理想的模型～也就是觀察變項之間的關聯模型。CFA的用途是檢測理想模性與資料模型的擬合度。

- [多種特質多項相關驗證性因素分析] (MTMM CFA) 用於分析潛在因素模型的方法不只一種，需要評估各種分析方法所所估計的變異合理程度。

- [內部一致性信度分析] 用於評估量表所測對象，與假設的心理建構之間的一致性程度。

<!---
In this chapter on factor analysis and related techniques we have introduced and demonstrated statistical analyses that assess the pattern of relationships in a data set. Specifically, we have covered:

- [Exploratory Factor Analysis] (EFA). EFA is a statistical technique for identifying underlying latent factors in a data set. Each observed variable is conceptualised as representing the latent factor to some extent, indicated by a factor loading. Researchers also use EFA as a way of data reduction, i.e. identifying observed variables than can be combined into new factor variables for subsequent analysis.

- [Principal Component Analysis] (PCA) is a data reduction technique which, strictly speaking, does not identify underlying latent factors. Instead, PCA simply produces a linear combination of observed variables.

- [Confirmatory Factor Analysis] (CFA). Unlike EFA, with CFA you start with an idea - a model - of how the variables in your data are related to each other. You then test your model against the observed data and assess how good a fit the model is to the data.

- In [Multi-Trait Multi-Method CFA] (MTMM CFA), both latent factor and method variance are included in the model in an approach that is useful when there are different methodological approaches used and therefore method variance is an important consideration.

- [Internal consistency reliability analysis]. This form of reliability analysis tests how consistently a scale measures a measurement (psychological) construct. --->
