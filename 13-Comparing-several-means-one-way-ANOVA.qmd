# 比較多組平均值(單因子變異數分析) {#sec-Comparing-several-means-one-way-ANOVA}

```{r}
#| include: FALSE
source("header.R")
```

> **譯者註** 20240414完成實例演練以外的編修。

這個單元要介紹心理學研究最常使用的一種統計方法～"變異數分析"，通常簡稱ANOVA。羅蘭．費雪爵士在20世紀初奠定了今天這套方法的基本運算原則，同時他給的命名也困擾著今天的學習者，**變異數分析**這個名稱通常會造成兩種誤會。其一是「變異數」，實際上ANOVA是比較平均數之間的差異。其二是有好幾套統計方法都是奠基於變異數分析，然而有些方法與變異數的關係非常微弱。後面的單元裡，讀者會學到各式各樣的變異數分析方法，分別有各自適用的條件。這個單元要學的只是最簡單的單因子變異數分析，適用研究設計只有幾個實驗組，研究者想要分析每個實驗組在各獨變項條件之間的測量結果差異。<!---這就是單因素ANOVA所要解決的問題。--->

這個單元的學習順序是：首先介紹這個單元用來解說及示範jamovi操作的虛擬資料集。接著說明<!---變異數分析的實際運作機制--->[單因子變異數分析的運算原理]，然後說明如何使用 [jamovi的變異數分析模組]執行變異數分析程序。這兩小節是這個單元的重點。

接下來分別討論在執行變異數分析時必須考慮的一系列重要課題，像是如何計算效果量大小、事後檢定和多重比較的校正，以及變異數分析的適用條件。我們還會討論如何檢查這些條件，以及適用條件不成立時有什麼樣的補救措施。最後一節，我們會學習[單因子重覆量數變數分析]。

<!--- This chapter introduces one of the most widely used tools in psychological statistics, known as "the analysis of variance", but usually referred to as ANOVA. The basic technique was developed by Sir Ronald Fisher in the early 20th century and it is to him that we owe the rather unfortunate terminology. The term ANOVA is a little misleading, in two respects. Firstly, although the name of the technique refers to variances, ANOVA is concerned with investigating differences in means. Secondly, there are several different things out there that are all referred to as ANOVAs, some of which have only a very tenuous connection to one another. Later on in the book we'll encounter a range of different ANOVA methods that apply in quite different situations, but for the purposes of this chapter we'll only consider the simplest form of ANOVA, in which we have several different groups of observations, and we're interested in finding out whether those groups differ in terms of some outcome variable of interest. This is the question that is addressed by a one-way ANOVA.

The structure of this chapter is as follows: first I'll introduce a fictitious data set that we'll use as a running example throughout the chapter. After introducing the data, I'll describe the mechanics of how a one-way ANOVA actually works [How ANOVA works] and then focus on how you can run one in jamovi [Running an ANOVA in jamovi]. These two sections are the core of the chapter.

The remainder of the chapter discusses a range of important topics that inevitably arise when running an ANOVA, namely how to calculate effect sizes, post hoc tests and corrections for multiple comparisons and the assumptions that ANOVA relies upon. We'll also talk about how to check those assumptions and some of the things you can do if the assumptions are violated. Then we'll cover repeated measures ANOVA. --->


> [導讀簡報](slides13.html){target="_blank"}


## 獨立樣本變異數分析示範資料

想像你正在協助進行一項臨床試驗，測試一種名為*Joyzepam*的新型抗憂鬱藥物的藥效。為了能公平地測試這種新藥的效果，需要分別測試包括新藥的三種藥物，另外兩種藥物之一是安慰劑，還有已經上市的抗憂鬱/抗焦慮藥物，名為*Anxifree*。研究一開始招募18位患有中度至重度抑鬱症的參與者。其中有一半參與者不只是服藥，同時進行認知行為治療（CBT），另一半參與者未同時進行任何心理治療。藥物以雙盲隨機方法分派給參與者，因此每種藥物分派給3位有進行CBT的參與者及3位未進行心理治療的參與者。每位參與者各自使用藥物3個月後，研究者再評估參與者的情緒改善狀況，以$-5$到$+5$的數值代表每位參與者的情緒改善狀況。讀者可以載入資料集 *Clinical Trial*，瀏覽範例資料的內容，其中的變項分別是藥物、治療和情緒改善分數。

為了學習如何使用單因子變異數分析，這裡的目的是要評估各種藥物改善情緒狀況的效果。首先要進行描述統計及繪製統計圖表，我們從  @sec-Descriptive-statistics  已經學到如何使用jamovi完成描述統計，報表會如同 @fig-fig12-1 。



<!--- Suppose you've become involved in a clinical trial in which you are testing a new antidepressant drug called *Joyzepam*. In order to construct a fair test of the drug's effectiveness, the study involves three separate drugs to be administered. One is a placebo, and the other is an existing antidepressant / anti-anxiety drug called *Anxifree*. A collection of 18 participants with moderate to severe depression are recruited for your initial testing. Because the drugs are sometimes administered in conjunction with psychological therapy, your study includes 9 people undergoing cognitive behavioural therapy (CBT) and 9 who are not. Participants are randomly assigned (doubly blinded, of course) a treatment, such that there are 3 CBT people and 3 no-therapy people assigned to each of the 3 drugs. A psychologist assesses the mood of each person after a 3 month run with each drug, and the overall improvement in each person's mood is assessed on a scale ranging from $-5$ to $+5$. With that as the study design, let's now load up the data file in *clinicaltrial.csv* . We can see that this data set contains the three variables drug, therapy and mood.gain.

For the purposes of this chapter, what we're really interested in is the effect of drug on mood.gain. The first thing to do is calculate some descriptive statistics and draw some graphs. In the @sec-Descriptive-statistics chapter we showed you how to do this, and some of the descriptive statistics we can calculate in jamovi are shown in @fig-fig12-1 --->

```{r}
#| label: fig-fig12-1
#| classes: .enlarge-image
#| fig-cap: 情緒改善效果的描述統計報表，以及三種藥物效果的箱形圖。
#Descriptives for mood gain, and box plots by drug administered
knitr::include_graphics("images/fig13-1.png")
```

從 @fig-fig12-1 可以看出，服用Joyzepam的參與者，情緒的改善程度優於服用Anxifree及安慰劑。Anxifree的情緒提升程度優於安慰劑，但是沒有像Joyzepam那麼明顯。這裡要回答的問題是，這些藥物的效果是否“真正有效”，還是只是一次偶然的發現？

<!--- As the plot makes clear, there is a larger improvement in mood for participants in the Joyzepam group than for either the Anxifree group or the placebo group. The Anxifree group shows a larger mood gain than the control group, but the difference isn't as large. The question that we want to answer is are these difference "real", or are they just due to chance? --->

## 單因子變異數分析的運算原理 {#sec-How-ANOVA-works}

為了運用臨床試驗資料回答以上的問題，我們要學習使用單因素變異數分析（one-way ANOVA）。如果讀者不知如何操作jamovi的ANOVA模組選單裡眼花撩亂的選項，先仔細閱讀這一節說明的基本原理，了解ANOVA程序每個步驟的運算概念，跟著[實例演練]操作一兩次，掌握概念後，後續與ANOVA有關的統計方法就不必如此學習了。

[獨立樣本變異數分析示範資料]的說明提到，研究人員有興趣的是三種藥物改善參與者憂鬱情緒的效果，這個研究設計的分析問題類似 @sec-Comparing-two-means 介紹的t檢定範例，不過要比較的不只兩組。在此先定義$\mu_P$代表安慰劑的情緒變化母群平均值，$\mu_A$和$\mu_J$分別對對應Anxifree和Joyzepam兩種藥物效果的平均值，所以要檢定的虛無假設就是：三組的母群平均值是相等的。也就是有點悲觀的預測，兩種藥物的效果都沒有比安慰劑好。這樣的虛無假設可以寫成：

$$H_0: \text{結果顯示 } \mu_P=\mu_A=\mu_J$$

因此對立假設就是：三種藥物之中，至少有一種的效果不同於其他兩種。用數學式表示的話，可能會讓有些同學困惑，由於有很多方式能表達虛無假設是錯誤的，我們先將對立假設寫成：

$$H_1: \text{結果}\underline{沒有}\text{顯示 } \mu_P=\mu_A=\mu_J$$

這道虛無假設比之前單元遇到的要棘手得多，應該要如何進行檢定呢？因為這個單元的標題是變異數分析，聰明的讀者應該猜到就是用「變異數分析」，但是如初學的讀者至此可能還不太了解為何這個方法其實是用來處理平均值。這是許多學生第一次上到變異數分析時，最大的挑戰。為了說明運算原理，我們要從變異數的組成談起，請先參考 @fig-fig12-2 了解什麼是組間變異(Between-group variation)及組內變異(Within-group variation)。

<!--- In order to answer the question posed by our clinical trial data we're going to run a one-way ANOVA. I'm going to start by showing you how to do it the hard way, building the statistical tool from the ground up and showing you how you could do it if you didn't have access to any of the cool built-in ANOVA functions in jamovi. And I hope you'll read it carefully, try to do it the long way once or twice to make sure you really understand how ANOVA works, and then once you've grasped the concept never ever do it this way again.

The experimental design that I described in the previous section strongly suggests that we're interested in comparing the average mood change for the three different drugs. In that sense, we're talking about an analysis similar to the t-test (see @sec-Comparing-two-means) but involving more than two groups. If we let $\mu_P$ denote the population mean for the mood change induced by the placebo, and let $\mu_A$ and $\mu_J$ denote the corresponding means for our two drugs, Anxifree and Joyzepam, then the (somewhat pessimistic) null hypothesis that we want to test is that all three population means are identical. That is, neither of the two drugs is any more effective than a placebo. We can write out this null hypothesis as:

$$H_0: \text{ it is true that } \mu_P=\mu_A=\mu_J$$

As a consequence, our alternative hypothesis is that at least one of the three different treatments is different from the others. It's a bit tricky to write this mathematically, because (as we'll discuss) there are quite a few different ways in which the null hypothesis can be false. So for now we'll just write the alternative hypothesis like this:

$$H_1: \text{ it } \underline{ is \text{ } not } \text{ true that }
\mu_P=\mu_A=\mu_J$$

This null hypothesis is a lot trickier to test than any of the ones we've seen previously. How shall we do it? A sensible guess would be to "do an ANOVA", since that's the title of the chapter, but it's not particularly clear why an "analysis of variances" will help us learn anything useful about the means. In fact, this is one of the biggest conceptual difficulties that people have when first encountering ANOVA. To see how this works, I find it most helpful to start by talking about variances, specifically between group variability and within-group variability (@fig-fig12-2). --->

```{r}
#| label: fig-fig12-2
#| fig-width: 8
#| fig-height: 4
#| fig-cap: 圖解**組間變異** ((a) Between-group variation) 和**組內變異**((b) Within-group variatioon)。圖(a)裡的箭頭顯示分組平均值之間的差異。圖(b)裡的箭頭代表各組之內的變異。
#Graphical illustration of 'between groups' variation (panel (a)) and 'within groups' variation (panel (b)). On the left the arrows show the differences in the group means. On the right the arrows highlight the variability within each group.

p1 <- ggplot(data = data.frame(x = seq(-5, 5, 1)), aes(x)) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = -2, sd = 1), col="darkgrey", linewidth=1) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 0, sd = 1), col="darkgrey", linewidth=1) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 2, sd = 1), col="darkgrey", linewidth=1) +
  geom_segment(x=-2, xend=0, y=0.33, yend=0.33, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  geom_segment(x=0, xend=2, y=0.28, yend=0.28, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  geom_segment(x=-2, xend=2, y=0.23, yend=0.23, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  scale_x_continuous(breaks = seq(-5, 5, 1)) +
  ggtitle("組間變異\n(分組平均值之間的差異)") +
  xlab("\n(a)") +
  scale_x_continuous(breaks=c(-2,0,2), labels=c("分組1", "分組2", "分組3")) +
  theme_classic() +
  theme(
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    plot.title = element_text(hjust = 0.5))

p2 <- ggplot(data = data.frame(x = seq(-5, 5, 1)), aes(x)) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = -2, sd = 1), col="darkgrey", linewidth=1) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 0, sd = 1), col="darkgrey", linewidth=1) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 2, sd = 1), col="darkgrey", linewidth=1) +
  geom_segment(x=-2.8, xend=-1.2, y=0.28, yend=0.28, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  geom_segment(x=-0.8, xend=0.8, y=0.28, yend=0.28, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  geom_segment(x=1.2, xend=2.8, y=0.28, yend=0.28, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  scale_x_continuous(breaks = seq(-5, 5, 1)) +
  ggtitle("組內變異\n(各組資料與該組平均值的差異)") +
  xlab("\n(b)") +
  scale_x_continuous(breaks=c(-2,0,2), labels=c("分組1", "分組2", "分組3")) +
  theme_classic() +
  theme(
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    plot.title = element_text(hjust = 0.5))

gridExtra::grid.arrange(p1,p2,ncol=2)

```

### 計算依變項變異數的兩套公式

我們先定義幾個運算用的符號：G代表分組的數量，因為資料集有三種藥物，所以有 $G = 3$ 個分組。然後定義$N$表示總樣本量，這個資料集有 $N = 18$ 位參與者，任可一組的人數同樣用 $N_k$ 表示。這份資料集的三組樣本量都是$N_k = 6$。[^13-comparing-several-means-one-way-anova-1] 最後是定義代表結果變項的Y，也就是每位參與者的情緒狀況改善數值，這裡用$Y_{ik}$ 代表第 k 組的第 i 位參與者改善數值。因此， $\bar{Y}$是所有18位參與者的平均改善數值，$\bar{Y}_k$就是第 k 組的第6位參與者的改善狀況。

[^13-comparing-several-means-one-way-anova-1]: 若是各組的的觀察值數目相等，這樣的研究設計就是“平衡設計”。以這個單位介紹的單因子變異數分析來說，設計是否平衡並不重要。不過要進行較複雜的變異數分析運算，設計是否平衡大有關係。

至此會用的符號都已經就定位，可以開始寫公式了。先回想一下談描述統計的 @sec-Measures-of-variability 提過的變異數公式，這裡的結果變項Y的樣本變異數公式是
 $$Var(Y)=\frac{1}{N}\sum_{k=1}^{G}\sum_{i=1}^{N_k}(Y_{ik}-\bar{Y})^2$$ 這個公式看起來和 @sec-Measures-of-variability 提到的變異數公式長得幾乎一樣。唯一的區別是這個公式有兩個連加記號：各組$k$的平均值總和及組內所有參與者 $i$ 個人數值的總和。請留意一下符號表示的差別，若結果變項符號是
$Y_p$，代表資料裡第p位參與者的數值，這樣子只會有所有參與者個人數值的總和。這裡要寫兩個連加符號，原因是要先將每筆數值歸到其中一組，再指定各組內所代表的個人數值。

這裡用具體的例子來理解應該會有用。來看看 @tbl-tab12-1 的例子，一供有 $N = 5$ 個人分為$G = 2$ 組。我們可以武斷地指定「酷」的人是第 1 組，「不酷」的人是第 2 組。最後列出其中有三個人很酷（$N_1 = 3$）和兩個人不算酷（$N_2 = 2$）。



<!--- First, let's start by introducing some notation. We'll use G to refer to the total number of groups. For our data set there are three drugs, so there are $G = 3$ groups. Next, we'll use $N$ to refer to the total sample size; there are a total of $N = 18$ people in our data set. Similarly, let's use $N_k$ to denote the number of people in the k-th group. In our fake clinical trial, the sample size is $N_k = 6$ for all three groups.[^13-comparing-several-means-one-way-anova-1] Finally, we'll use Y to denote the outcome variable. In our case, Y refers to mood change. Specifically, we'll use Yik to refer to the mood change experienced by the i-th member of the k-th group. Similarly, we'll use $\bar{Y}$ to be the average mood change, taken across all 18 people in the experiment, and $\bar{Y}_k$ to refer to the average mood change experienced by the 6 people in group $k$.

[^13-comparing-several-means-one-way-anova-1]: When all groups have the same number of observations, the experimental design is said to be "balanced". Balance isn't such a big deal for one-way ANOVA, which is the topic of this chapter. It becomes more important when you start doing more complicated ANOVAs.

Now that we've got our notation sorted out we can start writing down formulas. To start with, let's recall the formula for the variance that we used in @sec-Measures-of-variability, way back in those kinder days when we were just doing descriptive statistics. The sample variance of Y is defined as follows $$Var(Y)=\frac{1}{N}\sum_{k=1}^{G}\sum_{i=1}^{N_k}(Y_{ik}-\bar{Y})^2$$ This formula looks pretty much identical to the formula for the variance in @sec-Measures-of-variability. The only difference is that this time around I've got two summations here: I'm summing over groups (i.e., values for $k$) and over the people within the groups (i.e., values for $i$). This is purely a cosmetic detail. If I'd instead used the notation $Y_p$ to refer to the value of the outcome variable for person p in the sample, then I'd only have a single summation. The only reason that we have a double summation here is that I've classified people into groups, and then assigned numbers to people within groups.

A concrete example might be useful here. Let's consider @tbl-tab12-1, in which we have a total of $N = 5$ people sorted into $G = 2$ groups. Arbitrarily, let's say that the "cool" people are group 1 and the "uncool" people are group 2. It turns out that we have three cool people ($N_1 = 3$) and two uncool people ($N_2 = 2$) --->

```{r}
#| label: tbl-tab12-1
#| tbl-cap: 「酷」組和「不酷」組的個別沮喪指數資料。
#Grumpiness for people in cool and uncool groups
huxtabs[[13]][[1]]
```

這個表格結合兩種標記方式。變項 p代表個人，所以用$Y_p$代表第 p 人的沮喪指數。像是第四位是Tim，就用 $p = 4$ 代表他。我們若要用數字討論「Tim」這個人的沮喪程度，可以用$Y_4 = 91$來溝通。而這不是唯一可以描述Tim的方式，另一種方式是根據Tim的分組。因為Tim 是「不酷」組（$k = 2$）的第一人（$i = 1$），也可以用$Y_{12} = 91$代表Tim的沮喪程度。

也就是說，每個人 p 都對應一個獨一無二的 ik 組合，這也就能解釋為他我說上面的變異數公式，與以下更早學到的變異數公式相同的
$$Var(Y)=\frac{1}{N}\sum_{p=1}^{N}(Y_p-\bar{Y})^2$$

這兩個公式都是求樣本資料裡所有觀察值的總和，因為$Y_p$的公式較簡單，做運算練習的功課大都是用第二個公式。但是變異數分析必須要區別那位參與組是屬於那一組，就需要用$Y_{ij}$的公式來做運算。

<!--- Notice that I've constructed two different labelling schemes here. We have a "person" variable p so it would be perfectly sensible to refer to Yp as the grumpiness of the p-th person in the sample. For instance, the table shows that Tim is the fourth so we'd say $p = 4$. So, when talking about the grumpiness $Y$ of this "Tim" person, whoever he might be, we could refer to his grumpiness by saying that $Y_p = 91$, for person $p = 4$ that is. However, that's not the only way we could refer to Tim. As an alternative we could note that Tim belongs to the "uncool" group ($k = 2$), and is in fact the first person listed in the uncool group ($i = 1$). So it's equally valid to refer to Tim's grumpiness by saying that $Y_{ik} = 91$, where $k = 2$ and $i = 1$.

In other words, each person p corresponds to a unique ik combination, and so the formula that I gave above is actually identical to our original formula for the variance, which would be $$Var(Y)=\frac{1}{N}\sum_{p=1}^{N}(Y_p-\bar{Y})^2$$ In both formulas, all we're doing is summing over all of the observations in the sample. Most of the time we would just use the simpler Yp notation; the equation using $Y_p$ is clearly the simpler of the two. However, when doing an ANOVA it's important to keep track of which participants belong in which groups, and we need to use the Yik notation to do this. --->

### 變異數與離均差平方和

好啦，更進一步認識變異數的計算方法後，就能討論什麼是**總離均差平方和**（total sum of squares），簡記為$SS_{tot}$。變異數是離均差平方和的平均結果，計算$SS_{tot}$只要算總和就好。[^13-comparing-several-means-one-way-anova-2]

[^13-comparing-several-means-one-way-anova-2]: 所以總離均差平方和的公式與變異數的公式長得幾乎一樣 $$SS_{tot}=\sum_{k=1}^{G} \sum_{i=1}^{N_k} (Y_{ik} - \bar{Y})^2$$

在ANOVA的單元討論如何分析變異數，其實是談如何處理離均差平方和，而不是講如何處理變異數。[^13-comparing-several-means-one-way-anova-3]

[^13-comparing-several-means-one-way-anova-3]: 總離均差平方和能被分解成兩種離均差，帶來計算的便利性。第一種離均差是組內離均差平方和，是每個資料與所屬分組平均值之間差異$$SS_{w}= \sum_{k=1}^{G} \sum_{i=1}^{N_k} (Y_{ik} - \bar{Y}_k)^2$$ $\bar{Y}_k$ 是某一分組平均值，在此代表服用第 k 種藥物的參與者情緒狀態改善狀況，也就是並非比較每個人的數值與所有參與者的總平均值，而是各分組之內的參與者彼此比較。所以$SS_w$的值一定會小於總離均差平方和，因為完全不包括分組之間的差異，也就是各種藥物的效果。

接著來談較難講的組間離均差是怎麼回事，這裡就要來拆解分組平均值 $\bar{Y}_k$ 和總平均值 $\bar{Y}$是怎麼構成了。[^13-comparing-several-means-one-way-anova-4]

[^13-comparing-several-means-one-way-anova-4]: 這一步要知道的是如何計算組間離均差平方和 $$ \begin{aligned} SS_{b} &= \sum_{k=1}^{G} \sum_{i=1}^{N_k} ( \bar{Y}_{k} - \bar{Y} )^2 \\ &= \sum_{k=1}^{G} N_k ( \bar{Y}_{k} - \bar{Y} )^2 \end{aligned} $$

如此看來，所有實驗參與者之間的總離均差平方和（$SS_{tot}$），等於組間離均差平方和（$SS_b$），加上組內離均差平方和（$SS_w$）。其實不怎麼需要證明

$$SS_w+SS_b=SS_{tot}$$ 

太棒了！

所以我們學到什麼？我們已經懂得與結果變項相關的總離均差平方和（$SS_{tot}$），可以被劃分為“分組的樣本平均值之間的差異所造成的變異”的總和（$SS_b$），加上“除此之外的任何變異”的總和（$SS_w$）[^13-comparing-several-means-one-way-anova-5]。

那要怎麼幫研究人員確認各組的母群平均值相不相等呢？嗯，稍等一下，有沒有看到每種離均差平方和都是各種平均值之間的差異？若是虛無假設的推測是成立的，代表各組樣本平均值$\bar{Y_k}$ 應該是非常相等的，沒錯吧？也就是說$SS_b$要非常小，至少要比“除此之外的任何變異”（$SS_w$）明顯的小。有沒有聞到假設檢定的味道了？

[^13-comparing-several-means-one-way-anova-5]: 在獨立樣本變異數分的報告裡， $SS_w$ 也被稱為誤差總和 $SS_{error}$。

<!--- 

Okay, now that we've got a good grasp on how the variance is calculated, let's define something called the **total sum of squares**, which is denoted SStot. This is very simple. Instead of averaging the squared deviations, which is what we do when calculating the variance, we just add them up.[^13-comparing-several-means-one-way-anova-2]

[^13-comparing-several-means-one-way-anova-2]: So the formula for the total sum of squares is almost identical to the formula for the variance $$SS_{tot}=\sum_{k=1}^{G} \sum_{i=1}^{N_k} (Y_{ik} - \bar{Y})^2$$

When we talk about analysing variances in the context of ANOVA, what we're really doing is working with the total sums of squares rather than the actual variance. [^13-comparing-several-means-one-way-anova-3]

[^13-comparing-several-means-one-way-anova-3]: One very nice thing about the total sum of squares is that we can break it up into two different kinds of variation First, we can talk about the within-group sum of squares, in which we look to see how different each individual person is from their own group mean $$SS_{w}= \sum_{k=1}^{G} \sum_{i=1}^{N_k} (Y_{ik} - \bar{Y}_k)^2$$ where $\bar{Y}_k$ is a group mean. In our example, $\bar{Y}_k$ would be the average mood change experienced by those people given the k-th drug. So, instead of comparing individuals to the average of all people in the experiment, we're only comparing them to those people in the the same group. As a consequence, you'd expect the value of $SS_w$ to be smaller than the total sum of squares, because it's completely ignoring any group differences, i.e., whether the drugs will have different effects on people's moods

Next, we can define a third notion of variation which captures only the differences between groups. We do this by looking at the differences between the group means $\bar{Y}_k$ and grand mean $\bar{Y}$. [^13-comparing-several-means-one-way-anova-4]

[^13-comparing-several-means-one-way-anova-4]: In order to quantify the extent of this variation, what we do is calculate the between-group sum of squares $$ \begin{aligned} SS_{b} &= \sum_{k=1}^{G} \sum_{i=1}^{N_k} ( \bar{Y}_{k} - \bar{Y} )^2 \\ &= \sum_{k=1}^{G} N_k ( \bar{Y}_{k} - \bar{Y} )^2 \end{aligned} $$

It's not too difficult to show that the total variation among people in the experiment ($SS_{tot}$ is actually the sum of the differences between the groups $SS_b$ and the variation inside the groups $SS_w$. That is,

$$SS_w+SS_b=SS_{tot}$$ Yay.

Okay, so what have we found out? We've discovered that the total variability associated with the outcome variable ($SS_{tot}$) can be mathematically carved up into the sum of "the variation due to the differences in the sample means for the different groups" ($SS_b$) plus "all the rest of the variation" ($SS_w$) [^13-comparing-several-means-one-way-anova-5].

How does that help me find out whether the groups have different population means? Um. Wait. Hold on a second. Now that I think about it, this is exactly what we were looking for. If the null hypothesis is true then you'd expect all the sample means to be pretty similar to each other, right? And that would imply that you'd expect $SS_b$ to be really small, or at least you'd expect it to be a lot smaller than "the variation associated with everything else", $SS_w$. Hmm. I detect a hypothesis test coming on.

[^13-comparing-several-means-one-way-anova-5]: SS_w is also referred to in an independent ANOVA as the error variance, or $SS_{error}$

--->

### 離均差平方和與F檢定

前一節我們已經了解ANOVA運算的核心思想是比較$SS_b$ 和 $SS_w$，若是組間離均差平方和$SS_b$是相對大於組內離均差平方和$SS_w$，就有理由懷疑各組的母群平均值並不相等。為了轉化為可操作的假設檢定程序，我們要進行一些“微調”。我們先來認識如何計算檢驗統計值——**F值(F ratio)**，然後再來討論要計算F值的原因。

為了將離均差平方和轉換為F值，首先要計算$SS_b$ 和 $SS_w$的**自由度**。通常自由度是指為了計算估計值，需要貢獻的“資料點”數量，減去滿足“要估計”的參數數量。組內離均差平方和的計算元素是$N$筆個別觀察值與$G$ 個分組平均值之間的變異；而組間離均差平方和的計算元素是$G$ 個分組平均值與唯一一個總體平均值之間的變異。所以有兩個自由度：

$$df_b=G-1$$ $$df_w=N-G$$

這看起來很簡單，是吧。接著是將平方和轉換為“平方和的平均”，也就是各自除以自由度：

$$MS_b=\frac{SS_b}{df_b}$$ $$MS_w=\frac{SS_w}{df_w}$$

最後，將組間 MS 除以組內 MS 就能算出 F 值：

$$F=\frac{MS_b}{MS_w}$$

表面上來看，F統計值的運算相當直覺又好懂。F 值越大，就表示組間變異與組內變異之間的差異越大。所以F值起大，能反駁虛無假設的證據力就越強。但是 $F$ 要有多大才能確實拒絕 $H_0$？為了清楚理解，我們要更深入了解 ANOVA 是什麼，以及什麼是離均差平方和的平均？

這些問題在[實例演練]將有詳細討論，不過如果讀者對於詳細的回答不感興趣，這裡提供一個簡短的說明。為了完成假設檢定，分析人員需要知道虛無假設符合推測時的F值取樣分佈。這一點都不奇怪，因為由虛無假設生成的F統計值取樣分佈，必定是一個F分佈。回想 @sec-Introduction-to-probability 有關F 分佈的說明，$F$ 分佈的兩個參數各對應兩個自由度。第一個 $df_1$ 對應組間自由度 $df_b$，第二個 $df_2$ 對應組內自由度 $df_w$。

<!---
As we saw in the last section, the qualitative idea behind ANOVA is to compare the two sums of squares values $SS_b$ and $SS_w$ to each other. If the between-group variation $SS_b$ is large relative to the within-group variation $SS_w$ then we have reason to suspect that the population means for the different groups aren't identical to each other. In order to convert this into a workable hypothesis test, there's a little bit of "fiddling around" needed. What I'll do is first show you what we do to calculate our test statistic, the **F ratio**, and then try to give you a feel for why we do it this way.

In order to convert our SS values into an F-ratio the first thing we need to calculate is the **degrees of freedom** associated with the $SS_b$ and $SS_w$ values. As usual, the degrees of freedom corresponds to the number of unique "data points" that contribute to a particular calculation, minus the number of "constraints" that they need to satisfy. For the within-groups variability what we're calculating is the variation of the individual observations ($N$ data points) around the group means ($G$ constraints). In contrast, for the between groups variability we're interested in the variation of the group means (G data points) around the grand mean (1 constraint). Therefore, the degrees of freedom here are:

$$df_b=G-1$$ $$df_w=N-G$$

Okay, that seems simple enough. What we do next is convert our summed squares value into a "mean squares" value, which we do by dividing by the degrees of freedom:

$$MS_b=\frac{SS_b}{df_b}$$ $$MS_w=\frac{SS_w}{df_w}$$

Finally, we calculate the F-ratio by dividing the between-groups MS by the within-groups MS:

$$F=\frac{MS_b}{MS_w}$$

At a very general level, the intuition behind the F statistic is straightforward. Bigger values of F means that the between-groups variation is large relative to the within-groups variation. As a consequence, the larger the value of F the more evidence we have against the null hypothesis. But how large does $F$ have to be in order to actually reject $H_0$? In order to understand this, you need a slightly deeper understanding of what ANOVA is and what the mean squares values actually are.

The next section discusses that in a bit of detail, but for readers that aren't interested in the details of what the test is actually measuring I'll cut to the chase. In order to complete our hypothesis test we need to know the sampling distribution for F if the null hypothesis is true. Not surprisingly, the sampling distribution for the F <u>statistic</u> under the null hypothesis is an $F$ distribution. If you recall our discussion of the F distribution in @sec-Introduction-to-probability, the $F$ <u>distribution</u> has two parameters, corresponding to the two degrees of freedom involved. The first one $df_1$ is the between groups degrees of freedom $df_b$, and the second one $df_2$ is the within groups degrees of freedom $df_w$. --->

```{r}
#| label: tbl-tab12-2
#| tbl-cap: 組織所有變異數分析計算過程所產生的關鍵計數，構成的“標準化” 變異數分析報表。此表展示所有關鍵計數的公式，除了 p 值，因為公式非常複雜，沒有計算機的話，算起來會非常困難。
#All of the key quantities involved in an ANOVA organised into a 'standard' ANOVA table. The formulas for all quantities (except the p-value which has a very ugly formula and would be nightmarishly hard to calculate without a computer) are shown
huxtabs[[13]][[2]]
```

@tbl-tab12-2 摘要所有單因子變異數計算過程所產生的關鍵計數，包括各項計數的計算公式。

[額外的技術細節 [^13-comparing-several-means-one-way-anova-6]]

[^13-comparing-several-means-one-way-anova-6]: 追根究底來說，ANOVA 就是兩種不同的統計模型，$H_0$和$H_1$，的對決過程。這個單元一開始提到虛無假設和對立假設所用描述方式，其實不夠精確。在此要做點補救，儘管這樣會讓一些讀者感到厭煩。回憶一下，這個單元設定的虛無假設是各分組平均值彼此相等。若是如此，拆解結果變項 $Y_{ik}$ 的方式應該是將個別數值當成唯一的母群平均值$\mu$，加上因為測量方式，實際數值與母群平均值之間的偏差，通常會用$\epsilon_{ik}$表示，學術界習慣稱為誤差或殘差。不過請小心用詞，如同“顯著”這個詞義的歷史演變，“誤差”的詞義在統計學的場域不完全等於日常生活的模糊含義。日常用語的“誤差”暗示某種錯誤，但是統計學所指的不完全是任何一種錯誤。因此在統計學場域用“殘差”，會比“誤差”不易讓人誤會。這兩個詞都表示“剩餘變異”，也就是模型無法解釋的“部分”。不論是那種稱呼，將虛無假設寫成統計模型的話，看起來就是 $$Y_{ik}=\mu+\epsilon_{ik}$$ 本書稍後會討論到，通常會設定各分組的殘差值 $\epsilon_{ik}$皆符合平均值為 $0$，標準差為 $\sigma$的常態分佈。運用從[機率入門](@sec-Introduction-to-probability)學到的符號，殘差的數學模型可以寫成 $$\epsilon_{ik} \sim Normal(0,\sigma^2)$$ 那要如何設定對立假設 $H_1$ 呢？虛無假設和對立假設的唯一區別是，研究者認為各組的母群平均值並不相等。所以只要設定$\mu_k$ 表示第 k 組的母群平均值，$H_1$ 的統計模型就是 $$Y_{ik}=\mu_k+\epsilon_{ik}$$ 同樣地，其中的分組殘差也都是平均值為 $0$，標準差為 $\sigma$的常態分佈。也就是說，對立假設還帶上 $\epsilon_{ik} \sim Normal(0,\sigma^2)$ 這個條件。<br/> 現在$H_0$ 和 $H_1$的統計模型都正式登場，可以清楚說明如何評估離均差平方和平均，以及如何解釋$F$的意思。這裡不需要做任何數學證明，我們只要知道，組內離均差平方和平均 $MS_w$ 可以當成各組殘差的變異數估計值。組間離均差平方和平均$MS_b$也是一組估計值，除了各組殘差的變異數估計值，還有各組平均值之間的差異值。以$Q$代表這項差異值，就能將F統計數的公式改寫為 $^a$ $$F=\frac{\hat{Q}+\hat{\sigma}^2}{\hat{\sigma}^2}$$ 若是虛無假設的推測成立，$Q = 0$；若是對立假設的推測成立，$Q < 0$(請參考 @Hays1994 ，ch. 10)<br/>這就是為什麼在變異數分析的狀況，$F$ *值必須大於* 1，是拒絕虛無假設的基本條件。讀者要注意的是，這不是說F 值不可能小於 1。嚴格地說，如果虛無假設的推測成立，估計值的取樣分佈會逼近期望值是1的F分佈 $^b$，所以F 值必須要大於 1，才能安全地拒絕虛無假設。<br/> 從上一段的F值公式可知，$MS_b$和$MS_w$，都有殘差 $\epsilon_{ik}$ 變異數的估計值，如果虛無假設的推測成立，兩者就只有殘差變異數的估計值。若殘差符合常態分佈，根據 @sec-Other-useful-distributions 學過的卡方分佈，讀者會想到$\epsilon_{ik}$的變異數估計值其實應該符合卡方分佈。這就是卡方分佈的真正面貌：無數個符合常態分佈的隨機變數平方後，累加形成的機率分佈。F分佈則是兩件符合卡方分佈的隨機變數之比值，集合形成的機率分佈。當然，以上說明省略許多細節，不過這是至此介紹過的各種統計檢定方法，所依據的取樣分佈來源。<br /> --- <br />  $^a$ 如果讀者已經讀過 @sec-Factorial-ANOVA ，學到如何用 $\alpha_k$ 定義因子內水準 k 的「處理效應」（參考 @sec-Factorial-ANOVA-balanced-n-interaction 及 @sec-Factorial-ANOVA-balanced-w-interaction ），會知道 $Q$ 是處理效應平方的加權平均值，$Q = \frac{(\sum_{k=1}^{G}N_k \alpha_k^2)}{(G-1)}$ <br /> $^b$ 或者是更精確的F分佈期望值 $1+\frac{2}{df_2-2}$。

<!---
A summary of all the key quantities involved in a one-way ANOVA, including the formulas showing how they are calculated, is shown in @tbl-tab12-2.

[Additional technical detail [^13-comparing-several-means-one-way-anova-6]]

[^13-comparing-several-means-one-way-anova-6]: At a fundamental level ANOVA is a competition between two different statistical models, $H_0$ and $H_1$. When I described the null and alternative hypotheses at the start of the section, I was a little imprecise about what these models actually are. I'll remedy that now, though you probably won't like me for doing so. If you recall, our null hypothesis was that all of the group means are identical to one another. If so, then a natural way to think about the outcome variable $Y_{ik}$ is to describe individual scores in terms of a single population mean µ, plus the deviation from that population mean. This deviation is usually denoted $\epsilon_{ik}$ and is traditionally called the error or residual associated with that observation. Be careful though. Just like we saw with the word "significant", the word "error" has a technical meaning in statistics that isn't quite the same as its everyday English definition. In everyday language, "error" implies a mistake of some kind, but in statistics it doesn't (or at least, not necessarily). With that in mind, the word "residual" is a better term than the word "error". In statistics both words mean "leftover variability", that is "stuff" that the model can't explain. In any case, here's what the null hypothesis looks like when we write it as a statistical model $$Y_{ik}=\mu+\epsilon_{ik}$$ where we make the assumption (discussed later) that the residual values $\epsilon_{ik}$ are normally distributed, with mean $0$ and a standard deviation $\sigma$ that is the same for all groups. To use the notation that we introduced in the [Introduction to probability] we would write this assumption like this $$\epsilon_{ik} \sim Normal(0,\sigma^2)$$ What about the alternative hypothesis, $H_1$? The only difference between the null hypothesis and the alternative hypothesis is that we allow each group to have a different population mean. So, if we let $\mu_k$ denote the population mean for the k-th group in our experiment, then the statistical model corresponding to $H_1$ is $$Y_{ik}=\mu_k+\epsilon_{ik}$$ where, once again, we assume that the error terms are normally distributed with mean 0 and standard deviation $\sigma$. That is, the alternative hypothesis also assumes that $\epsilon \sim Normal(0,\sigma^2)$ Okay, now that we've described the statistical models underpinning $H_0$ and $H_1$ in more detail, it's now pretty straightforward to say what the mean square values are measuring, and what this means for the interpretation of $F$. I won't bore you with the proof of this but it turns out that the within-groups mean square, $MS_w$, can be viewed as an estimator of the error variance $\sigma^2$ . The between-groups mean square $MS_b$ is also an estimator, but what it estimates is the error variance plus a quantity that depends on the true differences among the group means. If we call this quantity $Q$, then we can see that the F-statistic is basically$^a$ $$F=\frac{\hat{Q}+\hat{\sigma}^2}{\hat{\sigma}^2}$$ where the true value $Q = 0$ if the null hypothesis is true, and Q < 0 if the alternative hypothesis is true (e.g., @Hays1994, ch. 10). Therefore, at a bare minimum the $F$ *value must be larger than* 1 to have any chance of rejecting the null hypothesis. Note that this doesn't mean that it's impossible to get an F-value less than 1. What it means is that if the null hypothesis is true the sampling distribution of the F ratio has a mean of 1,[\^b] and so we need to see F-values larger than 1 in order to safely reject the null. To be a bit more precise about the sampling distribution, notice that if the null hypothesis is true, both MSb and MSw are estimators of the variance of the residuals $\epsilon_{ik}$. If those residuals are normally distributed, then you might suspect that the estimate of the variance of $\epsilon_{ik}$ is chi-square distributed, because (as discussed in the @sec-Other-useful-distributions) that's what a chi-square distribution is: it's what you get when you square a bunch of normally-distributed things and add them up. And since the F distribution is (again, by definition) what you get when you take the ratio between two things that are $\chi^2$ distributed, we have our sampling distribution. Obviously, I'm glossing over a whole lot of stuff when I say this, but in broad terms, this really is where our sampling distribution comes from. <br /> --- <br />  $^a$ If you read ahead to @sec-Factorial-ANOVA and look at how the "treatment effect" at level k of a factor is defined in terms of the $\alpha_k$ values (see section on Factorial ANOVA 2: balanced designs, interactions allowed]), it turns out that $Q$ refers to a weighted mean of the squared treatment effects, $Q = \frac{(\sum_{k=1}^{G}N_k \alpha_k^2)}{(G-1)}$ <br /> $^b$ Or, if we want to be sticklers for accuracy, $1+ \frac{2}{df_2-2}$

--->

### 實例演練

前一節的說明相當抽象且有點技術性，因此這裡採用範例的計算做個完整的說明。我們再回到一開始介紹的[獨立樣本變異數分析示範資料]，這份臨床試驗資料已經有描述統計表，我們知道各組平均值：安慰劑的情緒改善平均分數是 $0.45$，Anxifree 是 $0.72$，Joyzepam 是 $1.48$。有了這些資訊和計算公式，我們可以辦個1899年的統計趴[^13-comparing-several-means-one-way-anova-7]，純粹用鉛筆和紙做計算。不過這裡只做前5筆資料的計算，因為現在不是沒有計算機的1899年，而且原作者本人相當懶惰。首先從計算組內離均差平方和$SS_w$ 開始，我們要畫一張像 @tbl-tab12-3 的表格來協助計算。


[^13-comparing-several-means-one-way-anova-7]: 或者更確切描述是像 "1899年的統計專家那樣熱衷計算，當時我們沒有朋友，也沒有比算術更有趣的事情可做，因為直到 1920 年左右，ANOVA 並不存在於世上。"

<!--- The previous discussion was fairly abstract and a little on the technical side, so I think that at this point it might be useful to see a worked example. For that, let's go back to the clinical trial data that I introduced at the start of the chapter. The descriptive statistics that we calculated at the beginning tell us our group means: an average mood gain of $0.45$ for the placebo, $0.72$ for Anxifree, and $1.48$ for Joyzepam. With that in mind, let's party like it's 1899 [^13-comparing-several-means-one-way-anova-7] and start doing some pencil and paper calculations. I'll only do this for the first $5$ observations because it's not bloody $1899$ and I'm very lazy. Let's start by calculating $SS_w$, the within-group sums of squares. First, let's draw up a nice table to help us with our calculations (@tbl-tab12-3)

[^13-comparing-several-means-one-way-anova-7]: Or, to be precise, party like "it's 1899 and we've got no friends and nothing better to do with our time than do some calculations that wouldn't have made any sense in 1899 because ANOVA didn't exist until about the 1920s". --->

```{r}
#| label: tbl-tab12-3
#| tbl-cap: 實例演練第一步
#A worked example...1
huxtabs[[13]][[3]]
```

第一步的表格只有原始資料，也就是每位參與者服用藥物的分組變項，以及情緒改善狀況的結果變項。請注意，這個結果變項對應前面提到的$\bar{Y}_{ik}$。接下來是計算每位參與者所屬分組的分平均值，$\bar{Y}_k$。這個步驟並不困難，因為描述統計表裡都有了，加上去後就變成 @tbl-tab12-4 。

<!--- At this stage, the only thing I've included in the table is the raw data itself. That is, the grouping variable (i.e., drug) and outcome variable (i.e. mood.gain) for each person. Note that the outcome variable here corresponds to the $\bar{Y}_{ik}$ value in our equation previously. The next step in the calculation is to write down, for each person in the study, the corresponding group mean, $\bar{Y}_k$. This is slightly repetitive but not particularly difficult since we already calculated those group means when doing our descriptive statistics, see @tbl-tab12-4. --->

```{r}
#| label: tbl-tab12-4
#| tbl-cap: 實例演練第二步
#A worked example...2
huxtabs[[13]][[4]]
```

都算到這裡了，接著就能計算每位參與者的離均差，也就是$Y_{ik} - \bar{Y}_k$，也能順手把每個離均差平方，最後就得到 @tbl-tab12-5 



<!---Now that we've written those down, we need to calculate, again for every person, the deviation from the corresponding group mean. That is, we want to subtract $Y_{ik} - \bar{Y}_k$. After we've done that, we need to square everything. When we do that, here's what we get (@tbl-tab12-5) --->

```{r}
#| label: tbl-tab12-5
#| tbl-cap: 實例演練第三步
#A worked example...3
huxtabs[[13]][[5]]
```

計算組內離均差平方和就簡單啦，就是將所有離均差平方加起來：

$$
\begin{split}
SS_w & = 0.0025 + 0.0225 + 0.1225 + 0.0136 + 0.1003 \\
& = 0.2614
\end{split}
$$

當然，真正完整的計算是要將全部18筆觀察值進行以上四個計算步驟，而不是只算演練的五筆。讀者有心的話，可以繼續筆算，不過這麼做相當繁瑣。其實也可以用LibreOffice或Excel試算表軟體演練，試試看並不困難。讀者們可以自已在Excel開一個檔案，命名為clinicaltrial_anova.xls。完成這裡示範的四個步驟，就能得到組內離均差平方和的值是$1.39$。

到這裡已經算出組內離均差平方和$SS_w$的值，接下來就是處理組間離均差平方和$SS_b$ 。其實計算步驟相當類似，差異是要改成計算各分組平均值 $\bar{Y}_k$ 與總平均值 $\bar{Y}$的差異，計算表格就變成 @tbl-tab12-6 ，得到的值是 $0.88$。

<!---

The last step is equally straightforward. In order to calculate the within-group sum of squares we just add up the squared deviations across all observations:

$$
\begin{split}
SS_w & = 0.0025 + 0.0225 + 0.1225 + 0.0136 + 0.1003 \\
& = 0.2614
\end{split}
$$

Of course, if we actually wanted to get the right answer we'd need to do this for all 18 observations in the data set, not just the first five. We could continue with the pencil and paper calculations if we wanted to, but it's pretty tedious. Alternatively, it's not too hard to do this in a dedicated spreadsheet programme such as OpenOffice or Excel. Try and do it yourself. The one that I did, in Excel, is in the file clinicaltrial_anova.xls. When you do it you should end up with a within-group sum of squares value of $1.39$.

Okay. Now that we've calculated the within groups variation, $SS_w$, it's time to turn our attention to the between-group sum of squares, $SS_b$. The calculations for this case are very similar. The main difference is that instead of calculating the differences between an observation Yik and a group mean $\bar{Y}_k$ for all of the observations, we calculate the differences between the group means $\bar{Y}_k$ and the grand mean $\bar{Y}$ (in this case $0.88$) for all of the groups (@tbl-tab12-6).

--->

```{r}
#| label: tbl-tab12-6
#| tbl-cap: 實例演練第4步
huxtabs[[13]][[6]]
```

不過因為是計算組間的平方和，還要將每個離均差平方先乘以 $N_k$，也就是各組的觀察值數量。這樣做是因為同組的$N_k$個觀察值，都與組間差異有關。安慰劑組有六筆資料，而安慰劑組的平均值與總平均值相差 $0.19$，因此六位參與者的組間離均差平方加權總和是$6 \times 0.19 = 1.14$。所以計算表格還要擴展成 @tbl-tab12-7 。

<!---
However, for the between group calculations we need to multiply each of these squared deviations by $N_k$, the number of observations in the group. We do this because every observation in the group (all $N_k$ of them) is associated with a between group difference. So if there are six people in the placebo group and the placebo group mean differs from the grand mean by $0.19$, then the total between group variation associated with these six people is $6 \times 0.19 = 1.14$. So we have to extend our little table of calculations (@tbl-tab12-7). --->

```{r}
#| label: tbl-tab12-7
#| tbl-cap: 實例演練第5步
huxtabs[[13]][[7]]
```

接著就可以將所有“加權的離均差平方”加起來，得到組間離均差平方和：

$$\begin{aligned} SS_b & = 1.14 + 0.18 + 2.16 \\ &= 3.48 \end{aligned}$$

正如讀者看到的，這次計算離均差平方和的步驟比較少 [^13-comparing-several-means-one-way-anova-8]。即然己經算出$SS_b$ 和 $SS_w$的值，ANOVA剩下的工作就就相當簡單了。接下來是計算自由度。由於知道 $G = 3$ 個分組以及 $N = 18$ 個觀察值，自由度用簡單的減法就可以計算：

[^13-comparing-several-means-one-way-anova-8]: 使用 Excel 計算完整的$SS_b$，會因為四捨五入得到不大一樣的值，可能是 $3.45$。

$$
\begin{split}
df_b & = G-1 = 2 \\
df_w & = N-G = 15
\end{split}
$$

有了離均差平方和和自由度的值，只要以前者除以後者，就能算出組內與組間變異數，也就是離均差平方和的平均：

$$
\begin{split}
MS_b & = \frac{SS_b}{df_b} = \frac{3.48}{2} = 1.74 \\
MS_w & = \frac{SS_w}{df_w} = \frac{1.39}{15} = 0.09
\end{split}
$$

快要完成了。有了兩個平均值，就能計算最想知道的F值。只要將$MS_b$除以$MS_w$就能得到。

$$
\begin{split}
F & = \frac{MS_b}{MS_w}  = \frac{1.74}{0.09} \\
& = 19.3
\end{split}
$$

我們真的完成了，很令人高興對吧！有了檢定統計值，最後就是判斷這個統計值是否代表結果是顯著的。如同在 @sec-Hypothesis-testing 討論過的手作方法，有心的讀者可以翻開任何一本統計教科書的附錄，查找其中有關F檢定的表，只要找到指定 $\alpha$值所對應的閾值，例如 $0.05$，$0.01$ 或 $0.001$，搭配 自由度2 和15。設定$\alpha$為 $0.001$ 的話，會查到F的閾值是$11.34$。因為小於最後算出的F值，可以宣稱$p < 0.001$。但這是時代的眼淚，今天各式各樣的統計軟體能為我們算出精確的p值。這個範例的p值是 $0.000071$。除非我們對型一錯誤率採取非常謹慎的立場，我們幾乎 可以結論這樣的研究結果能拒絕虛無假設。

至此己經完成了ANOVA的基本計算，將以上步驟算出的數值，整理成如同 @tbl-tab12-1  的報表，是傳統的變異數分析報告規範。完整的ANOVA報表請見 @tbl-tab12-8 。


<!---
And so now our between group sum of squares is obtained by summing these "weighted squared deviations" over all three groups in the study:

$$\begin{aligned} SS_b & = 1.14 + 0.18 + 2.16 \\ &= 3.48 \end{aligned}$$

As you can see, the between group calculations are a lot shorter[^13-comparing-several-means-one-way-anova-8]. Now that we've calculated our sums of squares values, $SS_b$ and $SS_w$, the rest of the ANOVA is pretty painless. The next step is to calculate the degrees of freedom. Since we have $G = 3$ groups and $N = 18$ observations in total our degrees of freedom can be calculated by simple subtraction:

[^13-comparing-several-means-one-way-anova-8]: In the Excel *clinicaltrial-anova.xls*  the value for SSb worked out to be very slightly different, $3.45$, than that shown in the text above (rounding errors!)

$$
\begin{split}
df_b & = G-1 = 2 \\
df_w & = N-G = 15
\end{split}
$$

Next, since we've now calculated the values for the sums of squares and the degrees of freedom, for both the within-groups variability and the between-groups variability, we can obtain the mean square values by dividing one by the other:

$$
\begin{split}
MS_b & = \frac{SS_b}{df_b} = \frac{3.48}{2} = 1.74 \\
MS_w & = \frac{SS_w}{df_w} = \frac{1.39}{15} = 0.09
\end{split}
$$

We're almost done. The mean square values can be used to calculate the F-value, which is the test statistic that we're interested in. We do this by dividing the between-groups MS value by the within-groups MS value.

$$
\begin{split}
F & = \frac{MS_b}{MS_w}  = \frac{1.74}{0.09} \\
& = 19.3
\end{split}
$$

Woohooo! This is terribly exciting, yes? Now that we have our test statistic, the last step is to find out whether the test itself gives us a significant result. As discussed in @sec-Hypothesis-testing back in the "old days" what we'd do is open up a statistics textbook or flick to the back section which would actually have a huge lookup table and we would find the threshold $F$ value corresponding to a particular value of alpha (the null hypothesis rejection region), e.g. $0.05$, $0.01$ or $0.001$, for 2 and 15 degrees of freedom. Doing it this way would give us a threshold F value for an alpha of $0.001$ of $11.34$. As this is less than our calculated $F$ value we say that $p < 0.001$. But those were the old days, and nowadays fancy stats software calculates the exact p-value for you. In fact, the exact p-value is $0.000071$. So, unless we're being *extremely* conservative about our Type I error rate, we're pretty much guaranteed to reject the null hypothesis.

At this point, we're basically done. Having completed our calculations, it's traditional to organise all these numbers into an ANOVA table like the one in Table 13.1. For our clinical trial data, the ANOVA table would look like @tbl-tab12-8. --->

```{r}
#| label: tbl-tab12-8
#| tbl-cap: 完整的變異數分析報表
#The ANOVA results table
huxtabs[[13]][[8]]
```

到這裡，讀者應該不大想靠純手工計算整理出這樣的報表，幾乎所有專業統計軟體，包括 jamovi，都能將ANOVA 的結果統整成像 @tbl-tab12-8 的表格，所以最好習慣一下。儘管軟體能輸出完整的 ANOVA 報表，我們從未有需要在報告裡置放整份表格，現代學術寫作規範所建議的標準格式是類似以下的句子：

> *單因子變異數分析顯示，測試的藥物對情緒改善有顯著影響，F(2,15) = 19.3，p < .001。*

我的老天！做了這麼多事，只為了寫這一行短句。

<!--- These days, you'll probably never have much reason to want to construct one of these tables yourself, but you will find that almost all statistical software (jamovi included) tends to organise the output of an ANOVA into a table like this, so it's a good idea to get used to reading them. However, although the software will output a full ANOVA table, there's almost never a good reason to include the whole table in your write up. A pretty standard way of reporting the stats block for this result would be to write something like this:

> *One-way ANOVA showed a significant effect of drug on mood gain (F(2,15) = 19.3, p < .001).*

Sigh. So much work for one short sentence. --->

## jamovi的變異數分析模組 {#running-an-anova-in-jamovi}

> **譯者註** 本單元內容為AI初翻，請謹慎使用。


我相當確定在讀完上一節之後，您在想什麼，特別是如果您按照我的建議，用鉛筆和紙（即在試算表中）自己完成所有這些工作。自己做 ANOVA 計算很糟糕。沿途我們需要做相當多的計算，如果每次想做 ANOVA 都要一次又一次地做這些計算，會讓人厭煩。

<!-- I'm pretty sure I know what you're thinking after reading the last section, especially if you followed my advice and did all of that by pencil and paper (i.e., in a spreadsheet) yourself. Doing the ANOVA calculations yourself sucks. There's quite a lot of calculations that we needed to do along the way, and it would be tedious to have to do this over and over again every time you wanted to do an ANOVA. --->

### 使用jamovi進行變異數分析

為了讓您的生活更輕鬆，jamovi 可以做 ANOVA... 哈拉！ 轉到「ANOVA」-「ANOVA」分析，將 mood.gain 變項移到「依賴變項」框中，然後將 drug 變項移到「固定因子」框中。這樣應該會得到 @fig-fig12-3 中所示的結果。[^13-comparing-several-means-one-way-anova-9] 注意我還勾選了 'Effect Size'選項下的 $\eta^2$ 复选框，念作“ eta 平方”，這也顯示在結果表格上。稍後我們將回到效應大小。



<!--- To make life easier for you, jamovi can do ANOVA...hurrah! Go to the 'ANOVA' - 'ANOVA' analysis, and move the mood.gain variable across so it is in the 'Dependent Variable' box, and then move the drug variable across so it is in the 'Fixed Factors' box. This should give the results as shown in @fig-fig12-3. [^13-comparing-several-means-one-way-anova-9] Note I have also checked the $\eta^2$ checkbox, pronounced "eta" squared, under the 'Effect Size' option and this is also shown on the results table. We will come back to effect sizes a bit later. --->

```{r}
#| label: fig-fig12-3
#| classes: .enlarge-image
#| fig-cap: jamovi的結果表格，用於根據施用的藥物進行情緒增益的 ANOVA。
#jamovi results table for ANOVA of mood gain by drug administered
knitr::include_graphics("images/fig13-3.png")
```

[^13-comparing-several-means-one-way-anova-9]: 與上文中的數字相比，jamovi 的結果更為準確，這是由於四捨五入誤差。

jamovi 的結果表格顯示了平方和值、自由度以及我們現在並不真正感興趣的其他一些數量。然而，請注意，jamovi 不使用「組間」和「組內」這兩個名稱。 相反，它嘗試分配更有意義的名稱。 在我們的特定示例中，組間方差對應於藥物對結果變項的影響，組內方差對應於“剩餘”的可變性，因此它將其稱為殘差。 如果我們將這些數字與 [A worked example] 中我手工計算的數字進行比較，可以看到它們或多或少是相同的，除了四捨五入誤差。組間平方和為 $SS_b = 3.45$，組內平方和為 $SS_w = 1.39$，各自的自由度為 $2$ 和 $15$。我們還得到了 F 值和 p 值，同樣，這些數字與我們在手工計算時的數字差不多相同，只是四捨五入誤差。

<!--- 
[^13-comparing-several-means-one-way-anova-9]: The jamovi results are more accurate than the ones in the text above, due to rounding errors.

The jamovi results table shows you the sums of squares values, the degrees of freedom, and a couple of other quantities that we're not really interested in right now. Notice, however, that jamovi doesn't use the names "between-group" and "within-group". Instead, it tries to assign more meaningful names. In our particular example, the between groups variance corresponds to the effect that the drug has on the outcome variable, and the within groups variance corresponds to the "leftover" variability so it calls that the residuals. If we compare these numbers to the numbers that I calculated by hand in [A worked example], you can see that they're more or less the same, apart from rounding errors. The between groups sums of squares is $SS_b = 3.45$, the within groups sums of squares is $SS_w = 1.39$, and the degrees of freedom are $2$ and $15$ respectively. We also get the F-value and the p-value and, again, these are more or less the same, give or take rounding errors, to the numbers that we calculated ourselves when doing it the long and tedious way. --->

## 效果量

衡量 ANOVA結果效果量有好幾種方法，其中最常用的指標是 $\eta^2$( eta sqaured )和淨 $\eta^2$( partial eta sqaured )。在單因子變異數分析的狀況，這兩種指標是一樣的，因此這裡只解釋 $\eta^2$。$\eta^2$ 定義相當簡單明瞭：

$$\eta^2=\frac{SS_b}{SS_{tot}}$$

前面有認真演練的話一看就懂。 @fig-fig12-3 展示的ANOVA 報表有呈現$\eta^2$，簡單驗算一下，因為$SS_b = 3.45$ 還有 $SS_tot = 3.45 + 1.39 = 4.84$，所以可以算出：

$$\eta^2=\frac{3.45}{4.84}=0.71$$

解讀$\eta^2$同樣直接了當，它的效果量公式就是指根據預測變項，結果變項的變異可以被解釋的比例。$\eta^2=0$ 代表兩種變項之間完全無關，$\eta^2=1$則表示兩者關係密切。值得一提的是，$\eta^2$與 @sec-The-R2-value 提過的是同一種效果量家族成員，有效力相等的解釋力。許多統計教科書建議使用 $\eta^2$ 作為 ANOVA的預設效果量指標，不過荷蘭心理學者Daniel Lakens在一篇有趣的<a href="https://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html" target="_blank">blog文章</a>提到，以統計實務處理的真實資料來看，$\eta^2$可能不是最好的效果量指標，因為這是一個有偏誤的估計值。還好jamovi還可以選擇使用另一個估計偏誤較少的指標 $\omega^2$ (omega squared) 。


<!--- There's a few different ways you could measure the effect size in an ANOVA, but the most commonly used measures are $\eta^2$ (eta squared) and partial $\eta^2$. For a one way analysis of variance they're identical to each other, so for the moment I'll just explain $\eta^2$ . The definition of $\eta^2$ is actually really simple

$$\eta^2=\frac{SS_b}{SS_{tot}}$$

That's all it is. So when I look at the ANOVA table in @fig-fig12-3, I see that $SS_b = 3.45$ and $SS_tot = 3.45 + 1.39 = 4.84$. Thus we get an $\eta^2$ value of

$$\eta^2=\frac{3.45}{4.84}=0.71$$

The interpretation of $\eta^2$ is equally straightforward. It refers to the proportion of the variability in the outcome variable (mood.gain) that can be explained in terms of the predictor (drug). A value of $\eta^2=0$ means that there is no relationship at all between the two, whereas a value of $\eta^2=1$ means that the relationship is perfect. Better yet, the $\eta^2$ value is very closely related to $R^2$, as discussed previously in @sec-The-R2-value, and has an equivalent interpretation. Although many statistics text books suggest $\eta^2$ as the default effect size measure in ANOVA, there's an interesting <a href="https://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html" target="_blank">blog post</a> by Daniel Lakens suggesting that eta-squared is perhaps not the best measure of effect size in real world data analysis, because it can be a biased estimator. Usefully, there is also an option in jamovi to specify omega-squared ($\omega^2$), which is less biased, alongside eta-squared. --->

## 多重比較與事後檢定

ANOVA報表顯示至少三組樣本之間存在顯著差異時，研究者會想知道是那幾組之間存在差異。以藥物臨床試驗的範例來說，由於虛無假設是三種藥物的情緒改善狀況完全一樣。不過仔細一想的話，這個範例的虛無假設宣告了三件不一樣的預測：

- Anxifree這款舊藥的效果沒有比安慰劑更好： $\mu_A = \mu_P$
- 新藥Joyzepam的效果沒有比安慰劑更好： $\mu_J = \mu_P$
- Anxifree 和 Joyzepam 兩款藥的效果沒什麼差別：  $\mu_A = \mu_J$

如果以上三項宣告有一項不成立，整個虛無假設也是不成立。因為ANOVA的分析結果已經確認可以拒絕虛無假設，所以至少有一個宣告是不成立的。儘管任何一個宣告被拒絕都是一個有趣的結論，但是是那幾個宣告呢？即然關注的是新藥 Joyzepam的效果有沒有確實地比安慰劑好，新藥與舊藥Anxifree的比較就非常重要。想清楚關注的目標，真正有意義的對比更有可能是Anxifree與安慰劑的效果差異。雖然更早有其他研究人員比較過Anxifree與安慰劑的效果好幾次，這次分析能再次確認早期的研究成果可以重現

將虛無假設分解為三個宣告後，就能將八種可能的分析結果表列出來，也就是 @tbl-tab12-9 。



<!---
Any time you run an ANOVA with more than two groups and you end up with a significant effect, the first thing you'll probably want to ask is which groups are actually different from one another. In our drugs example, our null hypothesis was that all three drugs (placebo, Anxifree and Joyzepam) have the exact same effect on mood. But if you think about it, the null hypothesis is actually claiming three different things all at once here. Specifically, it claims that:

- Your competitor's drug (Anxifree) is no better than a placebo (i.e., $\mu_A = \mu_P$ )
- Your drug (Joyzepam) is no better than a placebo (i.e., $\mu_J = \mu_P$ )
- Anxifree and Joyzepam are equally effective (i.e., $\mu_J = \mu_A$)

If any one of those three claims is false, then the null hypothesis is also false. So, now that we've rejected our null hypothesis, we're thinking that at least one of those things isn't true. But which ones? All three of these propositions are of interest. Since you certainly want to know if your new drug Joyzepam is better than a placebo, it would be nice to know how well it stacks up against an existing commercial alternative (i.e., Anxifree). It would even be useful to check the performance of Anxifree against the placebo. Even if Anxifree has already been extensively tested against placebos by other researchers, it can still be very useful to check that your study is producing similar results to earlier work.

When we characterise the null hypothesis in terms of these three distinct propositions, it becomes clear that there are eight possible "states of the world" that we need to distinguish between (@tbl-tab12-9). --->

```{r}
#| label: tbl-tab12-9
#| tbl-cap: 虛無假設與八種可能的"分析結果"
#The null hypothesis and eight possible 'states of the world'
huxtabs[[13]][[9]]
```

既然已經拒絕虛無假設，第一種分析結果已經出局。接著就要問，其餘七種可能的分析結果，才是*正確的*結論？面對這樣的局面，最後再看一次描述統計報告，像是 @fig-fig12-1 的統計圖，我們可以看到 Joyzepam 比安慰劑和 Anxifree好，但是Anxifree 和安慰劑的效果沒有差別是最有可能的結論。不過，若是要提出精確的報告，就需要做進一步的檢定。

<!--- By rejecting the null hypothesis, we've decided that we don't believe that #1 is the true state of the world. The next question to ask is, which of the other seven possibilities *do* we think is right? When faced with this situation, its usually helps to look at the data. For instance, if we look at the plots in @fig-fig12-1, it's tempting to conclude that Joyzepam is better than the placebo and better than Anxifree, but there's no real difference between Anxifree and the placebo. However, if we want to get a clearer answer about this, it might help to run some tests. --->

> **譯者註** 本節其餘內容有部分為AI初翻，請謹慎使用。


### 成對t檢定

能要怎麼檢定？由於要比較三對分組平均值：安慰劑對 Anxifree，安慰劑對 Joyzepam，和 Anxifree 對 Joyzepam，最單純的方法是執行三個獨立t檢定，一一確認檢定結果。在 jamovi 中這很容易做到。轉到 ANOVA 的 'Post Hoc Tests'（事後檢驗）選項，將 'drug'（藥物）變項移到右側的活動框中，然後單擊 'No correction'（無校正）複選框。這將產生一個整齊的表格，顯示藥物變項的三個水平之間的所有成對 t 檢驗比較，如 @fig-fig12-4 中所示。


<!--- 
How might we go about solving our problem? Given that we've got three separate pairs of means (placebo versus Anxifree, placebo versus Joyzepam, and Anxifree versus Joyzepam) to compare, what we could do is run three separate t-tests and see what happens. This is easy to do in jamovi. Go to the ANOVA 'Post Hoc Tests' options, move the 'drug' variable across into the active box on the right, and then click on the 'No correction' checkbox. This will produce a neat table showing all the pairwise t-test comparisons amongst the three levels of the drug variable, as in @fig-fig12-4 --->

```{r}
#| label: fig-fig12-4
#| classes: .enlarge-image
#| fig-cap: 未經校正的成對 t 檢驗作為 jamovi 中的事後比較。
#Uncorrected pairwise t-tests as post hoc comparisons in jamovi
knitr::include_graphics("images/fig13-4.png")
```

### 多重檢定的校正

前面提過一次做大批t檢定可能會有問題，最大的問題是同時執行多組t檢定，在沒有太多理論指引的時候，就只是單純期待有那幾組會出現顯著結果，很容易把科學分析搞成一場「魷魚遊戲」。這種對多組差異進行無理論基礎的比較，稱為**事後分析**（"post hoc" 是拉丁語，意為 "在正事之後"）。[^13-comparing-several-means-one-way-anova-10]

[^13-comparing-several-means-one-way-anova-10]:若是研究前已經有些理論，預期某幾組比較*確實*是有意義的，那就是另一回事了。這種情況執行多重檢定其實不是「事後分析」，而是「預先計劃的比較」。下一個單元的 @sec-The-method-of-planned-comparisons 會更進一步介紹。

事後分析不是不可以做，但需要非常小心。像是前一節介紹的成對t檢定應該儘量避免，因為每組t檢定的型一錯誤率都設定為.05的話，在此條件執行了三組t檢定，會導致型一錯誤率膨脹。想像有件ANOVA程序要分析10組平均值，然後挑出其中45筆組間差異進行「事後」t檢定，想知道有那些組別之間有顯著差異，如同 @sec-Hypothesis-testing 已經討論過的，這種狀況僅憑偶然性，就會看到2或3個顯著結果。虛無假設檢定有效的基本原則是，分析者嚴格控制型一錯誤率，現在為了確定造成ANOVA顯著結果的原因，不受控制地執行多組t檢定，己經導致全族45組的型一錯誤率膨脹到天邊了。

解決方法通常是校正p值，控制全族的總型一錯誤率[參考 @Shaffer1995]。這種要於事後分析的校正，通常稱為**多重比較校正**，有時也叫「即時推論」(simultaneous inference)。其實統計學已經開發出許多校正方法，在這一節還有下一個單元的 @sec-Post-hoc-tests 會討論其中幾種，本書介紹的只是最常見的而己[有與趣的讀者請參考 @Hsu1996 ]。

<!---
In the previous section I hinted that there's a problem with just running lots and lots of t-tests. The concern is that, when running these analyses, what we're doing is going on a "fishing expedition". We're running lots and lots of tests without much theoretical guidance in the hope that some of them come up significant. This kind of theory-free search for group differences is referred to as **post hoc analysis** ("post hoc" being Latin for "after this").[^13-comparing-several-means-one-way-anova-10]

[^13-comparing-several-means-one-way-anova-10]: If you *do* have some theoretical basis for wanting to investigate some comparisons but not others, it's a different story. In those circumstances you're not really running "post hoc" analyses at all, you're making "planned comparisons". I do talk about this situation later in the book - @sec-The-method-of-planned-comparisons, but for now I want to keep things simple.

It's okay to run post hoc analyses, but a lot of care is required. For instance, the analysis that I ran in the previous section should be avoided, as each individual t-test is designed to have a 5% Type I error rate (i.e., $\alpha = .05$) and I ran three of these tests. Imagine what would have happened if my ANOVA involved 10 different groups, and I had decided to run 45 "post hoc" t-tests to try to find out which ones were significantly different from each other, you'd expect 2 or 3 of them to come up significant by chance alone. As we saw in @sec-Hypothesis-testing, the central organising principle behind null hypothesis testing is that we seek to control our Type I error rate, but now that I'm running lots of t-tests at once in order to determine the source of my ANOVA results, my actual Type I error rate across this whole family of tests has gotten completely out of control.

The usual solution to this problem is to introduce an adjustment to the p-value, which aims to control the total error rate across the family of tests (see @Shaffer1995). An adjustment of this form, which is usually (but not always) applied because one is doing post hoc analysis, is often referred to as a **correction for multiple comparisons**, though it is sometimes referred to as "simultaneous inference". In any case, there are quite a few different ways of doing this adjustment. I'll discuss a few of them in this section and in @sec-Post-hoc-tests in the next chapter, but you should be aware that there are many other methods out there (see, e.g., @Hsu1996). --->

### Bonferroni校正

Bonferroni校正是其中最簡單的一種方法[@Dunn1961]。如果現在要處理m個單獨的檢定，這個方法能確保出現*任何*型一錯誤的總機率上限是$\alpha$。[^13-comparing-several-means-one-way-anova-11] 照字面說的話，Bonferroni校正只是「將所有原始 p 值乘以 m」。真正的做法是指定校正前的p值為$p$，校正後的p值為$p_j^{'}$，根據Bonferroni校正，校正前後的p值關係是：

[^13-comparing-several-means-one-way-anova-11]: 順便一提，並不是所有校正方法都是這樣搞，因為Bonferroni校正是著眼於控制「家族式型一錯誤率」。有些校正方法則是從控制「偽發現率」(False Discovery Rate)下手。


$$p_j^{'}=m \times p$$

採用Bonferroni校正的話，只要得到$p_j^{'} < \alpha$就能拒絕虛無假設。這種方法的邏輯非常簡單：現在要進行m組單獨的檢定，如果設定每個檢定的型一錯誤率上限是$\frac{\alpha}{m}$，所有檢定的*總*型一錯誤率就不會大於 $\alpha$。這種方法簡單到Bonferroni在描寫這種方法的論文裡說道：

>因為這個方法如此簡單，又易於使用，我肯定以前一定有人用過。但是，翻遍任何文獻我都找不到，只能推想：正是因為這種方法簡單到讓諸位聰明的統計學家，意識不到在某些情況是一個絕妙方法[@Dunn1961，第52-53頁]。

要在 jamovi 中使用邦弗隆尼校正，只需單擊「校正」選項中的「邦弗隆尼」復選框，您將在 ANOVA 結果表中看到另一列，顯示邦弗隆尼校正的調整後 p 值（ @tbl-tab12-8 ）。如果我們將這三個 p 值與未校正的成對 t 檢驗的 p 值進行比較，很明顯 jamovi 所做的唯一事情就是將它們乘以 $3$。

<!---

The simplest of these adjustments is called the **Bonferroni correction** [@Dunn1961], and it's very very simple indeed. Suppose that my post hoc analysis consists of m separate tests, and I want to ensure that the total probability of making *any* Type I errors at all is at most $\alpha$.[^13-comparing-several-means-one-way-anova-11] If so, then the Bonferroni correction just says "multiply all your raw p-values by m". If we let $p$ denote the original p-value, and let $p_j^{'}$ be the corrected value, then the Bonferroni correction tells that:

[^13-comparing-several-means-one-way-anova-11]: It's worth noting in passing that not all adjustment methods try to do this. What I've described here is an approach for controlling "family wise Type I error rate". However, there are other post hoc tests that seek to control the "false discovery rate", which is a somewhat different thing.

$$p_j^{'}=m \times p$$

And therefore, if you're using the Bonferroni correction, you would reject the null hypothesis if $p_j^{'} < \alpha$. The logic behind this correction is very straightforward. We're doing m different tests, so if we arrange it so that each test has a Type I error rate of at most $\frac{\alpha}{m}$, then the *total* Type I error rate across these tests cannot be larger than $\alpha$. That's pretty simple, so much so that in the original paper, the author writes:

>The method given here is so simple and so general that I am sure it must have been used before this. I do not find it, however, so can only conclude that perhaps its very simplicity has kept statisticians from realizing that it is a very good method in some situations (@Dunn1961, pp 52-53).

To use the Bonferroni correction in jamovi, just click on the 'Bonferroni' checkbox in the 'Correction' options, and you will see another column added to the ANOVA results table showing the adjusted p-values for the Bonferroni correction (@tbl-tab12-8). If we compare these three p-values to those for the uncorrected, pairwise t-tests, it is clear that the only thing that jamovi has done is multiply them by $3$.

--->

### Holm校正

雖然Bonferroni校正非常簡單，但是不是最好的校正方法。另一種常用的方法是**Holm校正**[@Holm1979]。這種方法背後的思路是假設按照p 值的大小，從最小的比較開始，調整到第j個比較的p值為止，以下列公式校正p值

$$p_j^{'}=j \times p_j$$

也就是最大的 p 值保持不變，第二大的 p 值翻倍，第三大的 p 值翻三倍，依此類推。或者用以下等式挑出較*大*者。

$$p_j^{'}=p_{j+1}^{'}$$

這可能不大好懂，讓我們慢慢了解Holm校正的原理。首先將$m$組檢定的p值按照數值大小排序，從最小的排到最大的。最小的 p 值只要乘以 $m$，其他p值則要兩個步驟校正。像是第二小的 p 值首先要乘以 $m - 1$，若是這個校正後的p值大於前一次校正的p值，就是完成校正；若是小於前一次校正的p值，改換為前一次的校正後p值為此次的校正結果。 @tbl-tab12-10 展示五次多重比較檢定的p值，如何用Holm校正來調整每個檢定的p值。

<!---
Although the Bonferroni correction is the simplest adjustment out there, it's not usually the best one to use. One method that is often used instead is the **Holm correction** [@Holm1979]. The idea behind the Holm correction is to pretend that you're doing the tests sequentially, starting with the smallest (raw) p-value and moving onto the largest one. For the j-th largest of the p-values, the adjustment is *either*

$$p_j^{'}=j \times p_j$$

(i.e., the biggest p-value remains unchanged, the second biggest p-value is doubled, the third biggest p-value is tripled, and so on), or

$$p_j^{'}=p_{j+1}^{'}$$

whichever one is <u>larger</u>. This might sound a little confusing, so let's go through it a little more slowly. Here's what the Holm correction does. First, you sort all of your p-values in order, from smallest to largest. For the smallest p-value all you do is multiply it by $m$, and you're done. However, for all the other ones it's a two-stage process. For instance, when you move to the second smallest p value, you first multiply it by $m - 1$. If this produces a number that is bigger than the adjusted p-value that you got last time, then you keep it. But if it's smaller than the last one, then you copy the last p-value. To illustrate how this works, consider @tbl-tab12-10 which shows the calculations of a Holm correction for a collection of five p-values. --->

```{r}
#| label: tbl-tab12-10
#| tbl-cap: 經過霍爾姆校正計算的p值
#Holm corrected p values
huxtabs[[13]][[10]]
```

希望以下說明能讓讀者們了解。

雖然計算稍微麻煩，Holm校正有一些優點，像是比Bonferroni校正保證更低的型二錯誤率，因此可提高統計考驗力。此外，Holm校正保障每個檢定有相同的型一錯誤率，雖然這套方法執行下來看起來不大像。多數真正要跑統計的研究者，搞清楚兩種校正方法的原理好，一致支持Holm校正。所以對於還在起步的讀者，Holm校正應該是*首選*的校正方法。 @fig-fig12-4 展示Holm校正的 p 值，如同以上說明，最大的 p 值（ Anxifree 和安慰劑的比較）沒有改變。它的值為 .15，和一開始未做校正的值完全相同。相比之下，最小的 p 值（Joyzepam 與安慰劑）是原來的三倍。

<!---
Hopefully that makes things clear.

Although it's a little harder to calculate, the Holm correction has some very nice properties. It's more powerful than Bonferroni (i.e., it has a lower Type II error rate) but, counter-intuitive as it might seem, it has the same Type I error rate. As a consequence, in practice there's never any reason to use the simpler Bonferroni correction since it is always outperformed by the slightly more elaborate Holm correction. Because of this, the Holm correction should be your *go to* multiple comparison correction. @fig-fig12-4 also shows the Holm corrected p-values and, as you can see, the biggest p-value (corresponding to the comparison between Anxifree and the placebo) is unaltered. At a value of .15, it is exactly the same as the value we got originally when we applied no correction at all. In contrast, the smallest p-value (Joyzepam versus placebo) has been multiplied by three.

--->

### 事後檢定的報告格式

完成事後比較，確定是那幾組有真正的顯著差異之後，我們可以寫正式報告：

> *以Holm校正調整後 p 值的事後檢定顯示，與 Anxifree（p = .001）和安慰劑（$（p = 9.0 \times{10^{-5}}$）相比，Joyzepam 有更顯著的情緒改善效果。此次研究沒有發現 Anxifree 的效果比安慰劑好的證據（$p = .15$）。*

若是不想報告精確的 p 值，可以將其中的數值改為 $p < .01$、$p < .001$ 和 $p > .05$。無論哪種表達方式，關鍵是要說明p 值有用Holm校正調整 。當然，這段報告之外的其他部分，應該要包括組平均值和標準差的描述統計資訊，因為這些 p 值並不是什麼充分的資訊。

<!---
Finally, having run the post hoc analysis to determine which groups are significantly different to one another, you might write up the result like this:

> *Post hoc tests (using the Holm correction to adjust p) indicated that Joyzepam produced a significantly larger mood change than both Anxifree (p = .001) and the placebo ($(p = 9.0 \times{10^{-5}}$). We found no evidence that Anxifree performed better than the placebo ($p = .15$).*

Or, if you don't like the idea of reporting exact p-values, then you'd change those numbers to $p < .01$, $p < .001$ and $p > .05$ respectively. Either way, the key thing is that you indicate that you used Holm's correction to adjust the p-values. And of course, I'm assuming that elsewhere in the write up you've included the relevant descriptive statistics (i.e., the group means and standard deviations), since these p-values on their own aren't terribly informative. --->

## 單因子變異數分析的適用條件

變異數分析也和其他統計方法一樣，需要確認資料性質符合幾個適用條件，尤其是殘差。這裡特別談三個關鍵條件：常態性、變異同質性和獨立性。

[額外的技術細節 [^13-comparing-several-means-one-way-anova-12]]

[^13-comparing-several-means-one-way-anova-12]: 若是讀者沒有真正親手演練[單因子變異數分析的運算原理]的範例，最好至少要讀過一遍。這一節裡提到了撐起ANOVA運算流程的統計模型：$$H_0:Y_{ik}=\mu + \epsilon_{ik}$$ $$H_1:Y_{ik}=\mu_k + \epsilon_{ik}$$其中$\mu$是指處於所有分組平均值中心的總平均之母群期望值，$\mu_k$是指第k組平均值的母群期望值。至此一直反覆討論的問題是，研究資料是最適配虛無假設代表的單一總平均，還是對應假設代表的分組平均值。這些討論是有必要的，因為統計模型的設定就是研究問題的形式化！但是在檢定過程的有效性其實是建立在殘差 $\epsilon_{ik}$ 符合常態分佈的條件，也就是$$\epsilon_{ik} \sim Normal(0,\sigma^2)$$如果沒有這個條件，所有ANOVA的數學運算都無法執行。也可以說，即使依然能進行所有計算，最後得到一個F統計值，但是違反條件造成這個F統計值並不能代表研究結果支持任何一個模型的指標，無法提出有科學意義的結論。 

那要如何檢查殘差的適用條件呢？就以上提到的三個條件，以下分別討論。

- **變異同質性**。因為會用單因子變異數分析的狀況只會有一個母群標準差$\sigma$，各分組資料不會有各自的母群標準差$\sigma_k$。這就是變異同質性的真義，設定各分組的標準差都與總標準差相等，因此又被稱為*等變異性*。[檢核變異同質性]將會詳細說明如何檢測。
- **常態性**。殘差必定符合常態分佈。如同 @sec-Checking-the-normality-of-a-sample 介紹過的，可以察看Q-Q圖，或執行Shapiro-Wilk檢定來做評估。[檢核常態性]將有進一步說明。
- **獨立性**。解釋這個條件有點棘手。基本意思是，任何一筆觀察值的殘差與其他觀察值的殘差彼此之間毫無關聯。符合獨立性的一組資料裡，所有 $\epsilon_{ik}$ 的來源不存在任何交集。這個條件沒有現成或簡易的檢核方法，只能從研究設計(參考 @sec-A-brief-introduction-to-research-design )發覺有無違反獨立性的狀況。不存在獨立性的最經典狀況是重複測量設計，每個研究參與者會在多個條件中被測量，如此一來就違反獨立性的條件，不可能以單因子變異數分析處理資料。如果一項研究具備這樣的設計，就需要使用[單因子重覆量數變異數分析]。


<!---
Like any statistical test, analysis of variance relies on some assumptions about the data, specifically the residuals. There are three key assumptions that you need to be aware of: normality, homogeneity of variance and independence.

[Additional technical detail [^13-comparing-several-means-one-way-anova-12]]

[^13-comparing-several-means-one-way-anova-12]: If you remember back to [A worked example], which I hope you at least skimmed even if you didn't read the whole thing, I described the statistical models underpinning ANOVA in this way: $$H_0:Y_{ik}=\mu + \epsilon_{ik}$$ $$H_1:Y_{ik}=\mu_k + \epsilon_{ik}$$ In these equations $\mu$ refers to a single grand population mean which is the same for all groups, and µk is the population mean for the k-th group. Up to this point we've been mostly interested in whether our data are best described in terms of a single grand mean (the null hypothesis) or in terms of different group-specific means (the alternative hypothesis). This makes sense, of course, as that's actually the important research question! However, all of our testing procedures have, implicitly, relied on a specific assumption about the residuals, $\epsilon\_{ik}$, namely that $$\epsilon_{ik} \sim Normal(0,\sigma^2)$$ None of the maths works properly without this bit. Or, to be precise, you can still do all the calculations and you'll end up with an F-statistic, but you have no guarantee that this F-statistic actually measures what you think it's measuring, and so any conclusions that you might draw on the basis of the F test might be wrong.

So, how do we check whether the assumption about the residuals is accurate? Well, as I indicated above, there are three distinct claims buried in this one statement, and we'll consider them separately.

- **Homogeneity of variance**. Notice that we've only got the one value for the population standard deviation (i.e., $\sigma$), rather than allowing each group to have it's own value (i.e., $\sigma_k$). This is referred to as the homogeneity of variance (sometimes called homoscedasticity) assumption. ANOVA assumes that the population standard deviation is the same for all groups. We'll talk about this extensively in the [Checking the homogeneity of variance assumption] section.
- **Normality**. The residuals are assumed to be normally distributed. As we saw in @sec-Checking-the-normality-of-a-sample, we can assess this by looking at QQ plots (or running a Shapiro-Wilk test. I'll talk about this more in an ANOVA context in the [Checking the normality assumption] section.
- **Independence**. The independence assumption is a little trickier. What it basically means is that, knowing one residual tells you nothing about any other residual. All of the $\epsilon_{ik}$ values are assumed to have been generated without any "regard for" or "relationship to" any of the other ones. There's not an obvious or simple way to test for this, but there are some situations that are clear violations of this. For instance, if you have a repeated measures design, where each participant in your study appears in more than one condition, then independence doesn't hold. There's a special relationship between some observations, namely those that correspond to the same person! When that happens, you need to use something like a [Repeated measures one-way ANOVA].

--->

### 檢核變異同質性 {#sec-Checking-the-homogeneity-of-variance-assumption}

> *檢核變異數分析的第一步，就像坐大型遊輪出海，要仔細觀察海面是不是平靜無波，能讓遊輪安全離港！* \
> -- 喬治·博克斯 [@Box1953]

據說殺貓有千百種方法，檢核變異同質性也有千百種方法。當然在動物保護意識極高的現代，這句話不能亂說。依照原作者曾閱讀文獻，最常見到的檢核方法是Levene檢定法[@Levene1960]，以及Brown-Forsythe檢定法[@BrownForsythe1974]。

無論是採用Levene還是Brown-Forsythe，檢定統計值$F$或$W$的計算程序都和ANOVA的F統計值一樣，只是結果變項的符號是用$Z_{ik}$代表而不是$Y_{ik}$。知道了這些，我們就可以看看如何使用jamovi進行檢檢。

[額外的技術細節[^13-comparing-several-means-one-way-anova-13]]

[^13-comparing-several-means-one-way-anova-13]: Levene檢定法非常簡單，先設定結果變項$Y_{ik}$。第一步是定義一個新變項$Z_{ik}$，表示各組觀察值與該組平均值的偏誤 $$Z_{ik}=Y_{ik}-\bar{Y}_{k}$$ 製造新變項有什麼好處？讓我們花一點時間來思考一下$Z_{ik}$到底是什麼，以及我們要檢檢什麼。$Z_{ik}$代表量測第$k$組的第$i$次觀察得到的數值，與其組平均值的誤差。變異數分析的虛無假設設定各分組的平均值相等，因此各組平均值的總變異應該也是相等！所以Levene檢定法的虛無假設是設定各組的$Z$之母群平均值相等。嗯，那麼有什麼統計方法能用來檢核這個變項？沒錯，就是ANOVA，所以Levene檢定法的流程就是以$Z_{ik}$為依變項做分析的ANOVA。那Brown-Forsythe檢定法是怎麼做？有什麼特別之處嗎？其實與Levene檢定法的唯一不同是建立新變項$Z$的方式，是用分組中位數計算所有觀察值的誤差分數而不是用分組平均值。所以說，Brown-Forsythe檢定法建立新變項的公式是 $$Z_{ik}=Y_{ik}-median_k(Y)$$ $median_k(Y)$代表第k組的中位數。

<!---

> *To make the preliminary test on variances is rather like putting to sea in a rowing boat to find out whether conditions are sufficiently calm for an ocean liner to leave port!* \
> -- George Box [@Box1953]

There's more than one way to skin a cat, as the saying goes, and more than one way to test the homogeneity of variance assumption, too (though for some reason no-one made a saying out of that). The most commonly used test for this that I've seen in the literature is the Levene test [@Levene1960], and the closely related Brown-Forsythe test [@BrownForsythe1974].

Regardless of whether you're doing the standard Levene test or the Brown-Forsythe test, the test statistic, which is sometimes denoted $F$ but also sometimes written as $W$, is calculated in exactly the same way that the F-statistic for the regular ANOVA is calculated, just using a $Z_{ik}$ rather than $Y_{ik}$. With that in mind, we can go on to look at how to run the test in jamovi.

[Additional technical detail [^13-comparing-several-means-one-way-anova-13]]

[^13-comparing-several-means-one-way-anova-13]: The Levene test is shockingly simple. Suppose we have our outcome variable $Y_{ik}$. All we do is define a new variable, which I'll call $Z_{ik}$, corresponding to the absolute deviation from the group mean $$Z_{ik}=Y_{ik}-\bar{Y}_{k}$$ Okay, what good does this do us? Well, let's take a moment to think about what $Z_{ik}$ actually is and what we're trying to test. The value of $Z_{ik}$ is a measure of how the $i$-th observation in the $k$-th group deviates from its group mean. And our null hypothesis is that all groups have the same variance, i.e., the same overall deviations from the group means! So the null hypothesis in a Levene test is that the population means of $Z$ are identical for all groups. Hmm. So what we need now is a statistical test of the null hypothesis that all group means are identical. Where have we seen  that before? Oh right, that's what ANOVA is, and so all that the Levene test does is run an ANOVA on the new variable $Z_{ik}$. What about the Brown-Forsythe test? Does that do anything particularly different? Nope. The only change from the Levene test is that it constructs the transformed variable Z in a slightly different way, using deviations from the group medians rather than deviations from the group means. That is, for the Brown-Forsythe test: $$Z_{ik}=Y_{ik}-median_k(Y)$$ where $median_k(Y)$ is the median for group k.
--->

### jamovi的Levene檢定

> **譯者註** 本單元內容為AI初翻，請謹慎使用。


好的，那麼我們該如何進行Levene檢驗呢？其實很簡單 - 在ANOVA的"假設檢查"選項下，只需點擊"變異數同質性檢驗"複選框。如果我們查看 @fig-fig12-5 中的輸出，我們可以看到檢驗結果並無顯著差異（$F_{2,15} = 1.45, p = .266$），所以變異數同質性假設看起來沒有問題。然而，外表可能會讓人受騙！如果您的樣本量相當大，那麼即使變異數同質性假設沒有被違反到影響ANOVA的穩健性，Levene檢驗也可能顯示出顯著效應（即p < .05）。這正是George Box在上面引述中所指出的觀點。同樣地，如果您的樣本量相當小，那麼變異數同質性假設可能不被滿足，而Levene檢驗可能不顯著（即p > .05）。這意味著，在對假設是否被滿足進行任何統計檢驗的同時，您應該總是繪製每個分組/類別的均值周圍的標準差......只是為了看看它們是否看起來相當相似（即變異數同質性）或不相似。



<!---
Okay, so how do we run the Levene test? Simple really - under the ANOVA 'Assumption Checks' option, just click on the 'Homogeneity tests' checkbox. If we look at the output, shown in @fig-fig12-5, we see that the test is non-significant ($F_{2,15} = 1.45, p = .266$), so it looks like the homogeneity of variance assumption is fine. However, looks can be deceptive! If your sample size is pretty big, then the Levene test could show up a significant effect (i.e. p < .05) even when the homogeneity of variance assumption is not violated to an extent which troubles the robustness of ANOVA. This was the point George Box was making in the quote above. Similarly, if your sample size is quite small, then the homogeneity of variance assumption might not be satisfied and yet a Levene test could be non-significant (i.e. p > .05). What this means is that, alongside any statistical test of the assumption being met, you should always plot the standard deviation around the means for each group / category in the analysis...just to see if they look fairly similar (i.e. homogeneity of variance) or not. --->

```{r}
#| label: fig-fig12-5
#| fig-cap: jamovi中單因素ANOVA的Levene檢驗輸出
#Levene test output for one-way ANOVA in jamovi
knitr::include_graphics("images/fig13-5.png")
```

### 校正異質性的分析結果

> **譯者註** 本單元內容為AI初翻，請謹慎使用。

在我們的示例中，變異數同質性假設被證明是相當可靠的：Levene檢驗結果並無顯著差異（儘管我們還應該查看標準差的圖形），因此我們可能不需要擔心。然而，在現實生活中，我們並非總是如此幸運。當變異數同質性假設被違反時，我們該如何拯救我們的ANOVA呢？如果您回想一下我們對t檢驗的討論，我們之前遇到過這個問題。Student t檢驗假設等方差，所以解決方法是使用不需要等方差假設的Welch t檢驗。實際上， @Welch1951 還展示了我們如何解決ANOVA的這個問題（**Welch單因素檢驗**）。它在jamovi中使用One-Way ANOVA分析實現。這是一種專為單因素ANOVA設計的分析方法，要在我們的示例中執行Welch單因素ANOVA，我們將按照之前的方式重新運行分析，但這次使用jamovi的ANOVA - One Way ANOVA分析命令，並選擇Welch檢驗的選項（參見 @fig-fig12-6 ）。為了理解這裡發生了什麼，讓我們將這些數字與我們最初在[使用jamovi進行變異數分析]時得到的數字進行比較。為了省去您回顧的麻煩，上次我們得到的是：$F(2, 15) = 18.611, p = .00009$，這也顯示為 @fig-fig12-6 中One-Way ANOVA的Fisher檢驗。

<!---

In our example, the homogeneity of variance assumption turned out to be a pretty safe one: the Levene test came back non-significant (notwithstanding that we should also look at the plot of standard deviations), so we probably don't need to worry. However, in real life we aren't always that lucky. How do we save our ANOVA when the homogeneity of variance assumption is violated? If you recall from our discussion of t-tests, we've seen this problem before. The Student t-test assumes equal variances, so the solution was to use the Welch t-test, which does not. In fact, @Welch1951 also showed how we can solve this problem for ANOVA too (the **Welch one-way test**). It's implemented in jamovi using the One-Way ANOVA analysis. This is a specific analysis approach just for one-way ANOVA, and to run the Welch one-way ANOVA for our example, we would re-run the analysis as previously, but this time use the jamovi ANOVA - One Way ANOVA analysis command, and check the option for Welch's test (see @fig-fig12-6). To understand what's happening here, let's compare these numbers to what we got earlier when [Running an ANOVA in jamovi] originally. To save you the trouble of flicking back, this is what we got last time: $F(2, 15) = 18.611, p = .00009$, also shown as the Fisher's test in the One-Way ANOVA shown in @fig-fig12-6.

--->

```{r}
#| label: fig-fig12-6
#| classes: .enlarge-image
#| fig-cap: Welch檢驗作為jamovi中One Way ANOVA分析的一部分
#Welch's test as part of the One Way ANOVA analysis in jamovi
knitr::include_graphics("images/fig13-6.png")
```



好的，最初我們的ANOVA結果是$F(2, 15) = 18.6$，而Welch單因素檢驗給出的是$F(2, 9.49) = 26.32$。換句話說，Welch檢驗將組內自由度從15降低到了9.49，而F值從18.6上升到了26.32。

<!---Okay, so originally our ANOVA gave us the result $F(2, 15) = 18.6$, whereas the Welch one way test gave us $F(2, 9.49) = 26.32$. In other words, the Welch test has reduced the within-groups degrees of freedom from 15 to 9.49, and the F-value has increased from 18.6 to 26.32. --->

### 檢核常態性 {#sec-Checking-the-normality-assumption}

檢驗常態性條件相對簡單， @sec-Checking-the-normality-of-a-sample 已經介紹所需要的工。要做的只是畫Q-Q圖，可以的話也跑個Shapiro-Wilk檢定法。以 @fig-fig12-7 的Q-Q圖看來，這份資料相當符合常態性。若是Shapiro-Wilk檢定結果也是不顯著，$p > .05$，就能確認這筆資料符合常態性條件。不過要注意的是，若是樣本量很大，那麼顯著的Shapiro-Wilk檢定結果實際上可能是偽陽的，也就是說，違反常態性並不會對分析結果造成任何問題。同樣地，非常小的樣本量可能會造成偽陰的檢定結果。這就是為什麼需要Q-Q圖輔助檢核。




<!--- Testing the normality assumption is relatively straightforward. We covered most of what you need to know in @sec-Checking-the-normality-of-a-sample. The only thing we really need to do is draw a QQ plot and, in addition if it is available, run the Shapiro-Wilk test. The QQ plot is shown in @fig-fig12-7 and it looks pretty normal to me. If the Shapiro-Wilk test is not significant (i.e. $p > .05$) then this indicates that the assumption of normality is not violated. However, as with Levene's test, if the sample size is large then a significant Shapiro-Wilk test may in fact be a false positive, where the assumption of normality is not violated in any substantive problematic sense for the analysis. And, similarly, a very small sample can produce false negatives. That's why a visual inspection of the QQ plot is important. --->

```{r}
#| label: fig-fig12-7
#| fig-cap: jamovi的One Way ANOVA模組繪製的Q-Q圖
#QQ plot in the One Way ANOVA analysis in jamovi
knitr::include_graphics("images/fig13-7.png")
```

除了看Q-Q圖檢查有沒有偏離常態的狀況，Shapiro-Wilk檢定結果並未顯示顯著，p = 0.6053，報表詳見 @fig-fig12-6 。因此，兩種檢核都沒有發現違反常態性的證據。

<!--- Alongside inspecting the QQ plot for any deviations from normality, the Shapiro-Wilk test for our data does show a non-significant effect, with p = 0.6053 (see @fig-fig12-6. This therefore supports the QQ plot assessment; both checks find no indication that normality is violated. --->

### 排除非常態性的分析結果

了解如何檢核常態性，另一方面也要學會如何分析違反常態性的資料。以單因子ANOVA的狀況來說，最簡單的解法是改用不必在意任何適用條件的無母數統計方法。 @sec-Comparing-two-means 已經介紹過分析兩組平均值的無母數統計方法：Mann-Whitney以及Wilcoxon檢定，若要分析三組以上的平均值，可以使用**Kruskal-Wallis秩和檢定法**[@KruskalWallis1952]。


<!--- Now that we've seen how to check for normality, we are led naturally to ask what we can do to address violations of normality. In the context of a one-way ANOVA, the easiest solution is probably to switch to a non-parametric test (i.e., one that doesn't rely on any particular assumption about the kind of distribution involved). We've seen non-parametric tests before, in @sec-Comparing-two-means. When you only have two groups, the Mann-Whitney or the Wilcoxon test provides the non-parametric alternative that you need. When you've got three or more groups, you can use the **Kruskal-Wallis rank sum test** [@KruskalWallis1952]. So that's the test we'll talk about next. --->

###  Kruskal-Wallis檢定的運算原理

Kruskal-Wallis檢定與單因子ANOVA有許多相似之處。ANOVA的計算是從定義第k個組的第i個觀察對象，標定在結果變項的數值$Y_{ik}$開始。Kruskal-Wallis檢定的第一步是排序所有$Y_{ik}$，以資料的序位進行分析。[^13-comparing-several-means-one-way-anova-14]

[^13-comparing-several-means-one-way-anova-14]: 首先創建新的結果變項$R_{ik}$，表示第k組的第i位成員排序。接著計算第k組觀察值的平均排序 $\bar{R}_k$: $$\bar{R}_k=\frac{1}{N_k}\sum_i R_{ik}$$，以及總平均排序$\bar{R}$: $$\bar{R}=\frac{1}{N}\sum_i\sum_k R_{ik}$$ 完成後，就可以計算與總平均排名$\bar{R}$的離均差平方。$(R_{ik} - \bar{R})^2$代表第ik個觀察值排序與總平均排序的離均差，是一種無母數的計量；還有$(R_{ik} - \bar{R_k})^2$代表第k組平均排序與總平均排序的離均差，也是一種無母數的計量。因此，離均差平方$(R_{ik} - \bar{R})^2$就是總體誤差的無母數計量。如此一來，就能按照ANOVA的運算原理，定義排序變異的估計值。首先是“總排序平方和”$$RSS_{tot}=\sum_k\sum_i (R_{ik}-\bar{R})^2$$，以及“組間排序平方和” $$\begin{aligned} RSS_{b}& =\sum{k}\sum_{i}(\bar{R}_{k}-\bar{R})^2 \\ &= \sum_{k} N_k (\bar{R}_{k}-\bar{R})^2 \end{aligned}$$ 若是虛無假設成立，且根本沒有真正的組差異，組間排序和$RSS_b$應該非常微小，遠小於總排序和$RSS_{tot}$。就計算公式來看，這和計算ANOVA 的F統計值非常像，不過因為背後的取樣分佈不同，Kruskal-Wallis檢定統計值記號是K，而K的計算方法是$$K=(N-1) \times \frac{RSS_b}{RSS_{tot}}$$ 若是虛無假設成立，K的取樣分佈會逼近自由度為$G-1$的卡方分佈。 K的值越大，資料就越不適配虛無假設，因此這是一個單側檢定。當K值足夠大時，就有機會拒絕$H_0$。

<!---
The Kruskal-Wallis test is surprisingly similar to ANOVA, in some ways. In ANOVA we started with $Y_{ik}$, the value of the outcome variable for the ith person in the kth group. For the Kruskal Wallis test what we'll do is rank order all of these $Y_{ik}$ values and conduct our analysis on the ranked data. [^13-comparing-several-means-one-way-anova-14]

[^13-comparing-several-means-one-way-anova-14]: So let's let R\_{ik} refer to the ranking given to the ith member of the kth group. Now, let's calculate $\bar{R}_k$, the average rank given to observations in the kth group $$\bar{R}_k=\frac{1}{N_k}\sum_i R_{ik}$$ and let's also calculate $\bar{R}$, the grand mean rank $$\bar{R}=\frac{1}{N}\sum_i\sum_k R_{ik}$$ Now that we've done this, we can calculate the squared deviations from the grand mean rank $\bar{R}$. When we do this for the individual scores, i.e., if we calculate $(R_{ik} - \bar{R})^2$ , what we have is a "nonparametric" measure of how far the ik-th observation deviates from the grand mean rank. When we calculate the squared deviation of the group means from the grand means, i.e., if we calculate $(R_{ik} - \bar{R})^2$, then what we have is a nonparametric measure of how much the group deviates from the grand mean rank. With this in mind, we'll follow the same logic that we did with ANOVA and define our ranked sums of squares measures, much like we did earlier. First, we have our "total ranked sums of squares" $$RSS_{tot}=\sum_k\sum_i (R_{ik}-\bar{R})^2$$ and we can define the "between groups ranked sums of squares" like this $$\begin{aligned} RSS_{b}& =\sum{k}\sum_{i}(\bar{R}_{k}-\bar{R})^2 \\ &= \sum_{k} N_k (\bar{R}_{k}-\bar{R})^2 \end{aligned}$$ So, if the null hypothesis is true and there are no true group differences at all, you'd expect the between group rank sums $RSS_b$ to be very small, much smaller than the total rank sums $RSS_{tot}$. Qualitatively this is very much the same as what we found when we went about constructing the ANOVA F-statistic, but for technical reasons the Kruskal-Wallis test statistic, usually denoted K, is constructed in a slightly different way, $$K=(N-1) \times \frac{RSS_b}{RSS_{tot}}$$ and if the null hypothesis is true, then the sampling distribution of K is approximately chi square with $G-1$ degrees of freedom (where $G$ is the number of groups). The larger the value of K, the less consistent the data are with the null hypothesis, so this is a one-sided test. We reject $H_0$ when K is sufficiently large.--->

### 更多分析細節

前一節說明Kruskal-Wallis檢定的運算原理，我認為這是思考一種統計檢定如何運作的正確方法。[^13-comparing-several-means-one-way-anova-15]

[^13-comparing-several-means-one-way-anova-15]: 不過，從純數學的觀點來看，這樣的複雜解說是不必要的。雖然這裡不會推導公式，讀者可以使用一些線性代數$^b$來推想K的公式，為什麼可以轉換為K統計值$$K=\frac{12}{N(N-1)}\sum_k N_k \bar{R}_k^2 -3(N+1)$$ K的運算比在前面描述的F要容易得多，但是對於實際操作統計方法的分析人員來說完全沒有意義，將K類比為分析排序資料的ANOVA可能是最好的解讀方法。但是請記住，檢定統計值K與前面的ANOVA統計值F有很大的不同。<br>---<br> $b$就只是數學運算術語。

但是要跟讀者抱歉一下，還有一個使用限制要交待！什麼限制？因為前面的範例是原始資料沒有任何兩個觀察值數值是相等的，才能使用Kruskal-Wallis檢定。也就是說，如果存在相同的數值，就必須引進一個校正因子才能計算。因為再有耐心的讀者看到這裡，也不再想讀下去了，或者覺得遇到問題再查什麼是tie-correction factor(TFC)就好了。這裡只用範例資料做個簡單的說明，以及解釋為何可以暫視無視這個限制。以下根據*clinicaltrails*的原始資料變項*mood.gain*建立一個對應觀察值出現次數的資料表單，以$f_j$表示每個觀察值數值在資料裡的出現次數，下標$j$代表資料數值的排序。全部例出後就如 @tbl-tab12-11 的第二列。



<!--- The description in the previous section illustrates the logic behind the Kruskal-Wallis test. At a conceptual level, this is the right way to think about how the test works.[^13-comparing-several-means-one-way-anova-15]

[^13-comparing-several-means-one-way-anova-15]: However, from a purely mathematical perspective it's needlessly complicated. I won't show you the derivation, but you can use a bit of algebraic jiggery-pokery$^b$ to show that the equation for K can be $$K=\frac{12}{N(N-1)}\sum_k N_k \bar{R}_k^2 -3(N+1)$$ It's this last equation that you sometimes see given for K. This is way easier to calculate than the version I described in the previous section, but it's just that it's totally meaningless to actual humans. It's probably best to think of K the way I described it earlier, as an analogue of ANOVA based on ranks. But keep in mind that the test statistic that gets calculated ends up with a rather different look to it than the one we used for our original ANOVA. <br>---<br> $b$ A technical term

But wait, there's more! Dear lord, why is there always more? The story I've told so far is only actually true when there are no ties in the raw data. That is, if there are no two observations that have exactly the same value. If there are ties, then we have to introduce a correction factor to these calculations. At this point I'm assuming that even the most diligent reader has stopped caring (or at least formed the opinion that the tie-correction factor is something that doesn't require their immediate attention). So I'll very quickly tell you how it's calculated, and omit the tedious details about why it's done this way. Suppose we construct a frequency table for the raw data, and let fj be the number of observations that have the j-th unique value. This might sound a bit abstract, so here's a concrete example from the frequency table of mood.gain from the *clinicaltrials.csv* data set (@tbl-tab12-11) --->

```{r}
#| label: tbl-tab12-11
#| tbl-cap: clinicaltrials資料集情緒改善分數的出現次數表
#Frequency table of mood gain from the *clinicaltrials.csv* data
huxtabs[[13]][[11]]
```

次數表排序第三的情緒改善分數是0.3，出現次數是2，表示所有參與者裡有兩位的情緒改善是0.3分。[^13-comparing-several-means-one-way-anova-16]

[^13-comparing-several-means-one-way-anova-16]: 根據上一段介紹的數學方法，我們可以知道$f_3 = 2$。想通這一點，就可以了解TCF的公式是用來算什麼了：$$TCF=1-\frac{\sum_j f_j^3 - f_j}{N^3 - N}$$jamovi計算出來的K值，正是除以TCF之後，輸出在Kruskal-Wallis檢定報表。

所以，我們不用太擔心使用限制，jamovi輸出的Kruskall-Wallis統計值是校正處理後的。我們終於走完Kruskal-Wallis檢定的學習之路了，讀者也了解為什麼不需要在意手上的資料有沒有使用限制的理由了吧？


<!--- Looking at this table, notice that the third entry in the frequency table has a value of 2. Since this corresponds to a mood.gain of 0.3, this table is telling us that two people's mood increased by 0.3. [^13-comparing-several-means-one-way-anova-16]

[^13-comparing-several-means-one-way-anova-16]: More to the point, in the mathematical notation I introduced above, this is telling us that $f_3 = 2$. Yay. So, now that we know this, the tie correction factor (TCF) is: $$TCF=1-\frac{\sum_j f_j^3 - f_j}{N^3 - N}$$ The tie-corrected value of the Kruskal-Wallis statistic is obtained by dividing the value of K by this quantity. It is this tie-corrected version that jamovi calculates.

And so jamovi uses a tie-correction factor to calculate the tie-corrected Kruskall-Wallis statistic. And at long last, we're actually finished with the theory of the Kruskal-Wallis test. I'm sure you're all terribly relieved that I've cured you of the existential anxiety that naturally arises when you realise that you don't know how to calculate the tie-correction factor for the Kruskal-Wallis test. Right? --->

### 使用jamovi完成Kruskal-Wallis檢定

> **譯者註** 本單元內容為AI初翻，請謹慎使用。

儘管我們在努力理解Kruskal Wallis檢驗實際上做了什麼方面經歷了恐懼，但事實證明，進行該檢驗相當無痛，因為jamovi在ANOVA分析集中有一個名為「非參數」-「單因子ANOVA（Kruskall-Wallis）」的分析。大多數時候，你將擁有像*clinicaltrial.csv*這樣的數據集，其中包含你的結果變項mood.gain和一個分組變項drug。如果是這樣，你可以直接在jamovi中運行分析。這給我們提供了一個Kruskal-Wallis $\chi^2 =12.076, df = 2, p = 0.00239$，如 @fig-fig12-8 所示。


<!--- Despite the horror that we've gone through in trying to understand what the Kruskal Wallis test actually does, it turns out that running the test is pretty painless, since jamovi has an analysis as part of the ANOVA analysis set called 'Non-Parametric' - 'One Way ANOVA (Kruskall-Wallis)' Most of the time you'll have data like the *clinicaltrial.csv*  data set, in which you have your outcome variable mood.gain and a grouping variable drug. If so, you can just go ahead and run the analysis in jamovi. What this gives us is a Kruskal-Wallis $\chi^2 =12.076, df = 2, p = 0.00239$, as in @fig-fig12-8 --->

```{r}
#| label: fig-fig12-8
#| classes: .enlarge-image
#| fig-cap: jamovi中的Kruskall-Wallis單因子非參數ANOVA
#Kruskall-Wallis one-way non-parametric ANOVA in jamovi
knitr::include_graphics("images/fig13-8.png")
```

## 單因子重覆量數變異數分析 {#sec-oneway-repeated-measure}

單因子重覆量數變數分析檢驗是一種用於每位參與者有參與三種以上實驗條件，或者各組的參與者有密切匹配條件，也有三個以上組平均差異要比較的狀況。所以各實驗條件應該有數量相等的觀察值。搭配這種研究設計的分析也可叫做「相依樣本變異數分析」或「參與者內變異數分析」。

重覆量數變數分析的運算原理與獨立樣本ANOVA非常像，後者有時也叫做「參與者間變異數分析」。之前討論參與者間變異數分析時提到組間離均差平方和（$SS_b$），以及組內離均差平方和（$SS_w$），各自除以對應的自由度就會得到$MS_b$和$MS_w$，如同 @tbl-tab12-1 。F統計值的計算公式是：

$$F=\frac{MS_b}{MS_w}$$


重覆量數變異數分析的F統計值的計算方法也是差不多，只是$SS_w$要再分成兩部分，不像獨立樣本ANOVA直接用$SS_w$做為$MS_w$的分母。因為每一組的參與者都是同樣的人，可以從組內離均差平方和移出參與者間個別差異$SS_{subjects}$。在此不深談如何移出的細節，只要想像每位參與者都是名為「參與者」這個變項的其中一個變項水準。只要將$SS_w$減掉$SS_{subjects}$，就能得到一個較小的$SS_{error}$：

$$\text{獨立樣本變異數分析: } SS_{error} = SS_w$$ $$\text{重覆量數變異數分析: } SS_{error} = SS_w - SS_{subjects}$$
減少的$SS_{error}$可以增加統計檢定的考驗力，不過還要看減少的$SS_{error}$有沒有比減少的自由度更多，因為獨立組的參與者較多，重覆量數的自由度從$(n - k)$[^13-comparing-several-means-one-way-anova-17]變為$(n - 1)(k - 1)$


[^13-comparing-several-means-one-way-anova-17]:（n-k）：（參與者數量-組別數量）

<!--- The one-way repeated measures ANOVA test is a statistical method of testing for significant differences between three or more groups where the same participants are used in each group (or each participant is closely matched with participants in other experimental groups). For this reason, there should always be an equal number of scores (data points) in each experimental group. This type of design and analysis can also be called a 'related ANOVA' or a 'within subjects ANOVA'.

The logic behind a repeated measures ANOVA is very similar to that of an independent ANOVA (sometimes called a 'between-subjects' ANOVA). You'll remember that earlier we showed that in a between-subjects ANOVA total variability is partitioned into between-groups variability ($SS_b$) and within-groups variability ($SS_w$), and after each is divided by the respective degrees of freedom to give MSb and MSw (see Table 13.1) the F-ratio is calculated as:

$$F=\frac{MS_b}{MS_w}$$ 

In a repeated measures ANOVA, the F-ratio is calculated in a similar way, but whereas in an independent ANOVA the within-group variability ($SS_w$) is used as the basis for the $MS_w$ denominator, in a repeated measures ANOVA the $SS_w$ is partioned into two parts. As we are using the same subjects in each group, we can remove the variability due to the individual differences between subjects (referred to as SSsubjects) from the within-groups variability. We won't go into too much technical detail about how this is done, but essentially each subject becomes a level of a factor called subjects. The variability in this within-subjects factor is then calculated in the same way as any between-subjects factor. And then we can subtract SSsubjects from $SS_w$ to provide a smaller SSerror term:

$$\text{Independent ANOVA: } SS_{error} = SS_w$$ $$\text{Repeated Measures ANOVA: } SS_{error} = SS_w - SS_{subjects}$$
This change in $SS_{error}$ term often leads to a more powerful statistical test, but this does depend on whether the reduction in the $SS_{error}$ more than compensates for the reduction in degrees of freedom for the error term (as degrees of freedom go from $(n - k)$ [^13-comparing-several-means-one-way-anova-17] to $(n - 1)(k - 1)$ (remembering that there are more subjects in the independent ANOVA design).

[^13-comparing-several-means-one-way-anova-17]: (n - k) : (number of subjects - number of groups) --->

### jamovi的重覆量數變異數分析

> **譯者註** 本單元部份內容為AI初翻，請謹慎使用。


此處以來自 @Geschwind1972 的研究資料做示範。這個研究的對象是中風後出現語言缺陷的患者，研究者想了解導致語言缺陷的大腦損傷區域，找來六位確診Broca失語者的患者，研究資料如 @tbl-tab12-12 。



<!--- First, we need some data. @Geschwind1972 has suggested that the exact nature of a patient's language deficit following a stroke can be used to diagnose the specific region of the brain that has been damaged. A researcher is concerned with identifying the specific communication difficulties experienced by six patients suffering from Broca's Aphasia (a language deficit commonly experienced following a stroke) (@tbl-tab12-12). --->

```{r}
#| label: tbl-tab12-12
#| tbl-cap: 中風患者的三種單詞識別作業分數
#Word recognition task scores in stroke patients
huxtabs[[13]][[12]]
```

患者需要完成三個單詞識別任務。在第一個（言語生成）任務中，患者需要重複研究者大聲朗讀的單詞。在第二個（概念性）任務中，旨在測試單詞理解能力，患者需要將一系列圖片與其正確名稱匹配。在第三個（語法）任務中，旨在測試正確單詞順序的知識，要求患者對語法不正確的句子進行重新排序。每位患者都完成了所有三個任務。患者嘗試任務的順序在參與者之間進行了平衡。每個任務包括一系列10次嘗試。每位患者成功完成的嘗試次數如 @tbl-tab12-11 所示。將這些數據輸入jamovi以進行分析（或者使用捷徑加載*broca.csv*文件）。

要在jamovi中執行一個單因素相關ANOVA，打開一個單因素重覆量數變數分析對話框，如 @fig-fig12-9 中所示，通過ANOVA - Repeated Measures ANOVA進行。


<!--- The patients were required to complete three word recognition tasks. On the first (speech production) task, patients were required to repeat single words read out aloud by the researcher. On the second (conceptual) task, designed to test word comprehension, patients were required to match a series of pictures with their correct name. On the third (syntax) task, designed to test knowledge of correct word order, patients were asked to reorder syntactically incorrect sentences. Each patient completed all three tasks. The order in which patients attempted the tasks was counterbalanced between participants. Each task consisted of a series of 10 attempts. The number of attempts successfully completed by each patient are shown in @tbl-tab12-11. Enter these data into jamovi ready for analysis (or take a short-cut and load up the *broca.csv* file).

To perform a one-way related ANOVA in jamovi, open the one-way repeated measures ANOVA dialogue box, as in @fig-fig12-9, via ANOVA - Repeated Measures ANOVA. --->

```{r}
#| label: fig-fig12-9
#| fig-cap: jamovi中的重覆量數變數分析對話框
#Repeated measures ANOVA dialogue box in jamovi
knitr::include_graphics("images/fig13-9.png")
```

然後：

- 輸入一個重複測量因子名稱。這應該是您選擇的標籤，用於描述所有參與者重複的條件。例如，要描述所有參與者完成的語音、概念和語法任務，一個合適的標籤是“任務”。請注意，這個新的因子名稱代表了分析中的自變項。
- 在重複測量因子文本框中添加第三個級別，因為有三個級別代表三個任務：語音、概念和語法。相應地更改級別的標籤。
- 然後將每個級別變項移動到重複測量單元文本框中。
- 最後，在“假設檢查”選項下，選中“球形性檢查”文本框。

jamovi輸出一個單因素重覆量數變數分析，如 @fig-fig12-10 至 @fig-fig12-13 所示。我們應該首先查看的是Mauchly球形性檢驗，該檢驗測試各條件之間的差異方差是否相等（意味著研究條件之間的差異得分的分佈大致相同）。在 @fig-fig12-10 中，Mauchly檢驗的顯著性水平為$p = .720$。如果Mauchly檢驗的結果不顯著（即p > .05，正如此分析中的情況），那麼我們有理由得出差異的方差並無顯著差異（即它們大致相等，可以假定球形性。）。



<!--- Then:

- Enter a Repeated Measures Factor Name. This should be a label that you choose to describe the conditions repeated by all participants. For example, to describe the speech, conceptual and syntax tasks completed by all participants a suitable label would be 'Task'. Note that this new factor name represents the independent variable in the analysis.
- Add a third level in the Repeated Measures Factors text box, as there are three levels representing the three tasks: speech, conceptual and syntax. Change the labels of the levels accordingly.
- Then move each of the levels variables across to the Repeated Measures Cells text box.
- Finally, under the Assumption Checks option, tick the "Sphericity checks" text box.

jamovi output for a one-way repeated measures ANOVA is produced as shown in @fig-fig12-10 to @fig-fig12-13. The first output we should look at is Mauchly's Test of Sphericity, which tests the hypothesis that the variances of the differences between the conditions are equal (meaning that the spread of difference scores between the study conditions is approximately the same). In @fig-fig12-10 Mauchly's test significance level is $p = .720$. If Mauchly's test is non-significant (i.e. p > .05, as is the case in this analysis) then it is reasonable to conclude that the variances of the differences are not significantly different (i.e. they are roughly equal and sphericity can be assumed.). --->

```{r}
#| label: fig-fig12-10
#| classes: .enlarge-image
#| fig-cap: 單因子重覆量數變數分析輸出 - Mauchly球形性檢驗
#One-way repeated measures ANOVA output - Mauchly's Test of Sphericity
knitr::include_graphics("images/fig13-10.png")
```

如果另一方面，Mauchly檢驗顯著（p < .05），那麼我們將得出差異方差之間存在顯著差異，並且未滿足球形性要求。在這種情況下，我們應該對單因素相關ANOVA分析中獲得的F值進行修正：

-   如果"球形性檢驗"表中的Greenhouse-Geisser值> .75，那麼您應該使用Huynh-Feldt修正
-   但如果Greenhouse-Geisser值< .75，那麼您應該使用Greenhouse-Geisser修正。

這兩個修正過的F值都可以在“假設檢查”選項下的球形性修正復選框中指定，修正過的F值將顯示在結果表中，如 @fig-fig12-11 所示。



<!--- If, on the other hand, Mauchly's test had been significant (p < .05) then we would conclude that there are significant differences between the variance of the differences, and the requirement of sphericity has not been met. In this case, we should apply a correction to the F-value obtained in the one-way related ANOVA analysis:

-   If the Greenhouse-Geisser value in the "Tests of Sphericity" table is > .75 then you should use the Huynh-Feldt correction
-   But if the Greenhouse-Geisser value is < .75, then you should use the Greenhouse-Geisser correction.

Both these corrected F-values can be specified in the Sphericity Corrections check boxes under the Assumption Checks options, and the corrected F-values are then shown in the results table, as in @fig-fig12-11 . --->

```{r}
#| label: fig-fig12-11
#| classes: .enlarge-image
#| fig-cap: 單因素重覆量數變數分析輸出 - 內部受試者效應檢驗
#One-way repeated measures ANOVA output - Tests of Within-Subjects Effects
knitr::include_graphics("images/fig13-11.png")
```

在我們的分析中，我們發現Mauchly的球形性檢驗的顯著性為p = .720（即p > 0.05）。因此，這意味著我們可以假設已滿足球形性要求，因此無需對F值進行修正。因此，我們可以使用'無'球形性修正輸出值用於重複測量"任務"：$F = 6.93$，$df = 2$，$p = .013$，我們可以得出結論，語言任務中成功完成的測試次數確實會根據任務是語音、理解還是語法為基礎而顯著不同（$F(2, 10) = 6.93$，$p = .013$）。

在jamovi中，與獨立ANOVA相同，也可以為重覆量數變數分析指定事後檢驗。結果顯示在 @fig-fig12-12 。這些表明語音和語法之間存在顯著差異，但其他級別之間沒有差異。

<!--- In our analysis, we saw that the significance of Mauchly's Test of Sphericity was p = .720 (i.e. p > 0.05). So, this means we can assume that the requirement of sphericity has been met so no correction to the F-value is needed. Therefore, we can use the 'None' Sphericity Correction output values for the repeated measure 'Task': $F = 6.93$, $df = 2$, $p = .013$, and we can conclude that the number of tests successfully completed on each language task did vary significantly depending on whether the task was speech, comprehension or syntax based ($F(2, 10) = 6.93$, $p = .013$).

Post-hoc tests can also be specified in jamovi for repeated measures ANOVA in the same way as for independent ANOVA. The results are shown in @fig-fig12-12. These indicate that there is a significant difference between Speech and Syntax, but not between other levels. --->

```{r}
#| label: fig-fig12-12
#| classes: .enlarge-image
#| fig-cap: 重覆量數變數分析中jamovi的事後檢驗
#Post-hoc tests in repeated measures ANOVA in jamovi
knitr::include_graphics("images/fig13-12.png")
```

描述性統計（邊際均值）可以用於幫助解釋結果，在jamovi輸出中生成，如 @fig-fig12-13 。通過比較參與者成功完成試驗的平均次數，可以看出布洛卡失語症患者在語音產生（平均= 7.17）和語言理解（平均= 6.17）任務上表現相對較好。然而，他們在語法任務上的表現明顯較差（平均= 4.33），事後檢驗中語音和語法任務表現之間存在顯著差異。


<!--- Descriptive statistics (marginal means) can be reviewed to help interpret the results, produced in the jamovi output as in @fig-fig12-13. Comparison of the mean number of trials successfully completed by participants shows that Broca's Aphasics perform reasonably well on speech production (mean = 7.17) and language comprehension (mean = 6.17) tasks. However, their performance was considerably worse on the syntax task (mean = 4.33), with a significant difference in post-hoc tests between Speech and Syntax task performance. --->

```{r}
#| label: fig-fig12-13
#| classes: .enlarge-image
#| fig-cap: 單因子重覆量數變數分析輸出-描述性統計
#One-way repeated measures ANOVA output - Descriptive Statistics
knitr::include_graphics("images/fig13-13.png")
```

## Friedman無母數重覆量數變異數分析

> **譯者註** 本單元部份內容為AI初翻，請謹慎使用。


Friedman檢定是單因子重覆量數變異數分析的無母數版本，用來分析三個或更多組排序資料的差異，每組的參與者相同，或者各條件的參與者彼此有密切的匹配條件。如果依變項是序列數值，或者資料未滿足常態性條件，就可以使用這種方法進行假設檢定。

和Kruskall-Wallis檢定相同，徹底解釋需要先知道複雜的數學知識，這裡不會介紹。對於本書的目標讀者們，只要了解jamovi輸出的Friedman檢定報表是已校正的結果，  @fig-fig12-14 是用前面的失語症患者資料做Friedman檢定的報表範例。



<!--- The Friedman test is a non-parametric version of a repeated measures ANOVA and can be used instead of the Kruskall-Wallis test when testing for differences between three or more groups where the same participants are in each group, or each participant is closely matched with participants in other conditions. If the dependent variable is ordinal, or if the assumption of normality is not met, then the Friedman test can be used.

As with the Kruskall-Wallis test, the underlying mathematics is complicated, and won't be presented here. For the purpose of this book, it is sufficient to note that jamovi calculates the tie-corrected version of the Friedman test, and in @fig-fig12-14 there is an example using the Broca's Aphasia data we have already looked at. --->

```{r}
#| label: fig-fig12-14
#| classes: .enlarge-image
#| fig-cap: jamovi中的“無母數重覆量數變數分析”對話框和結果
#The 'Repeated Measures ANOVA (Non-parametric)' dialogue box and results in jamovi
knitr::include_graphics("images/fig13-14.png")
```

在jamovi中運行Friedman檢驗非常簡單。只需選擇分析 - ANOVA - 重覆量數變數分析（非參數），如 @fig-fig12-14 所示。然後將要比較的重複測量變項的名稱（語言、概念、語法）突顯並轉移到“測量：”文本框中。要為三個重複測量變項生成描述性統計（平均值和中位數），請單擊描述性按鈕。

jamovi結果顯示描述性統計、卡方值、自由度和p值（ @fig-fig12-14 ）。由於p值小於通常用於確定顯著性的水平（p < .05），我們可以得出結論，布洛卡失語症患者在語言生產（中位數= 7.5）和語言理解（中位數= 6.5）任務上表現相當好。然而，他們在語法任務上的表現明顯較差（中位數= 4.5），在事後檢驗中語言和語法任務表現之間存在顯著差異。

<!--- It's pretty straightforward to run a Friedman test in jamovi. Just select Analyses - ANOVA - Repeated Measures ANOVA (Non-parametric), as in @fig-fig12-14. Then highlight and transfer the names of the repeated measures variables you wish to compare (Speech, Conceptual, Syntax) into the 'Measures:' text box. To produce descriptive statistics (means and medians) for the three repeated measures variables, click on the Descriptives button

The jamovi results show descriptive statistics, chi-square value, degrees of freedom, and the p-value (@fig-fig12-14). Since the p-value is less than the level conventionally used to determine significance (p < .05), we can conclude that Broca's Aphasics perform reasonably well on speech production (median = 7.5) and language comprehension (median = 6.5) tasks. However, their performance was considerably worse on the syntax task (median = 4.5), with a significant difference in post-hoc tests between Speech and Syntax task performance. --->

## 變異數分析與t檢定的關係 {#sec-On-the-relationship-between-ANOVA-and-the-Student-t-test}

這個單元結束之前，還要一件事要讓讀者知道，初學者通常會感到訝異，不過了解這件事是值得的：以ANOVA和學生t檢定分析兩組差異的資料，結果是一樣的。的確，不只輸出的結果相似，各種資訊的統計意義是等價的。這裡用實際的示範取代公式推導讓讀者明白。拿*clinicaltrials*資料集來看，這次不用`drug`，改用`therapy`這個變項做為獨變項。完成ANOVA後，會得到一個F統計值 $F(1,16) = 1.71$，和p值 = $0.21$。又因為只有兩組，實際上做學生t檢驗就行。t檢定的結果得到t統計值 $t(16) = -1.3068$ 和 $p = 0.21$。讀者也許發現，p值是相同的，都是$p = .21$。那麼檢定統計值？因為t統計值是負的，顯然和ANOVA的F值不一樣。其實這裡有個相當直接的轉換關係。只要將t統計值平方，就會得到F統計值：$-1.3068^{2} = 1.7077$。



<!--- There's one last thing I want to point out before finishing. It's something that a lot of people find kind of surprising, but it's worth knowing about. An ANOVA with two groups is identical to the Student t-test. No, really. It's not just that they are similar, but they are actually equivalent in every meaningful way. I won't try to prove that this is always true, but I will show you a single concrete demonstration. Suppose that, instead of running an ANOVA on our mood.gain \~ drug model, let's instead do it using therapy as the predictor. If we run this ANOVA we get an F-statistic of $F(1,16) = 1.71$, and a p-value = $0.21$. Since we only have two groups, I didn't actually need to resort to an ANOVA, I could have just decided to run a Student t-test. So let's see what happens when I do that: I get a t-statistic of $t(16) = -1.3068$ and a $p-value = 0.21$. Curiously, the p-values are identical. Once again we obtain a value of $p = .21$. But what about the test statistic? Having run a t-test instead of an ANOVA, we get a somewhat different answer, namely $t(16) = -1.3068$. However, there is a fairly straightforward relationship here. If we square the t-statistic then we get the F-statistic from before: $-1.3068^{2} = 1.7077$ --->

## 單元小結

這一章份量不少，但是有一些細節我並未提到[^13-summary-1]。最明顯的是在此並未討論處理不只一個分組變項的資料，下一個 @sec-Factorial-ANOVA 會討論其中一部分。這個單元的學習重點有：

- 理解[單因子變異數分析的運算原理] 以及使用[jamovi的變異數分析模組]

- 學習如何計算變異數分析的[效果量]

- [多重比較與事後檢定]

- [單因子變異數分析的適用條件]
  - [檢核變異同質性]以及[校正異質性的分析結果]
  - [檢核常態性]以及[排除非常態性的分析結果]
- [單因子重覆量數變異數分析]以及無母數版本[Friedman無母數重覆量數變異數分析]

[^13-summary-1]: 就像其他章節，這個單元有許多參考來源，其中原作者參考最多的專書是 @Sahai2000 。這本書對初學者來說偏難，不過如果學到這裡，想知道更多變異數分析的數學原理，這本書是不錯的參考資源。

<!---
There's a fair bit covered in this chapter, but there's still a lot missing [^13-summary-1]. Most obviously, I haven't discussed how to run an ANOVA when you are interested in more than one grouping variable, but that will be discussed in a lot of detail in @sec-Factorial-ANOVA. In terms of what we have discussed, the key topics were:

- The basic logic behind [How ANOVA works] and [Running an ANOVA in jamovi]
- How to compute an [Effect size] for an ANOVA.
- [Multiple comparisons and post hoc tests] for multiple testing.
- [The assumptions of one-way ANOVA]
- [Checking the homogeneity of variance assumption] and what to do if it is violated: [Removing the homogeneity of variance assumption]
- [Checking the normality assumption] and what to do if it is violated: [Removing the normality assumption]
- [Repeated measures one-way ANOVA] and the non-parametric equivalent, [The Friedman non-parametric repeated measures ANOVA test]

[^13-summary-1]: As with all of the chapters in this book, there are quite a few different sources that I've relied upon, but the one stand-out text that I've been most heavily influenced by @Sahai2000. It's not a good book for beginners, but it's an excellent book for more advanced readers who are interested in understanding the mathematics behind ANOVA.--->
