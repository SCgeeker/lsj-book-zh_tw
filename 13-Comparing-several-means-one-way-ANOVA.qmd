# 比較多組平均值(單因子變異數分析) {#sec-Comparing-several-means-one-way-ANOVA}

```{r}
#| include: FALSE
source("header.R")
```

> **譯者註** 20230416初步以ChatGPT-4完成翻譯，內容待編修。

這個單元要介紹心理學研究最常使用的一種統計方法～"變異數分析"，通常簡稱ANOVA。羅蘭．費雪爵士在20世紀初奠定了今天這套方法的基本運算原則，同時他給的命名也困擾著今天的學習者，**變異數分析**這個名稱通常會造成兩種誤會。其一是「變異數」，實際上ANOVA是比較平均數之間的差異。其二是有好幾套統計方法都是奠基於變異數分析，然而有些方法與變異數的關係非常微弱。後面的單元裡，讀者會學到各式各樣的變異數分析方法，分別有各自適用的條件。這個單元要學的只是最簡單的單因子變異數分析，適用研究設計只有幾個實驗組，研究者想要分析每個實驗組在各獨變項條件之間的測量結果差異。<!---這就是單因素ANOVA所要解決的問題。--->

這個單元的學習順序是：首先介紹這個單元用來解說及示範jamovi操作的虛擬資料集。接著說明<!---變異數分析的實際運作機制--->[單因子變異數分析的運算原理]，然後說明如何使用 [jamovi的變異數分析模組]執行變異數分析程序。這兩小節是這個單元的重點。

接下來分別討論在執行變異數分析時必須考慮的一系列重要課題，像是如何計算效果量大小、事後檢定和多重比較的校正，以及變異數分析的適用條件。我們還會討論如何檢查這些條件，以及適用條件不成立時有什麼樣的補救措施。最後一節，我們會學習[單因子重覆量數變數分析]。

<!--- This chapter introduces one of the most widely used tools in psychological statistics, known as "the analysis of variance", but usually referred to as ANOVA. The basic technique was developed by Sir Ronald Fisher in the early 20th century and it is to him that we owe the rather unfortunate terminology. The term ANOVA is a little misleading, in two respects. Firstly, although the name of the technique refers to variances, ANOVA is concerned with investigating differences in means. Secondly, there are several different things out there that are all referred to as ANOVAs, some of which have only a very tenuous connection to one another. Later on in the book we'll encounter a range of different ANOVA methods that apply in quite different situations, but for the purposes of this chapter we'll only consider the simplest form of ANOVA, in which we have several different groups of observations, and we're interested in finding out whether those groups differ in terms of some outcome variable of interest. This is the question that is addressed by a one-way ANOVA.

The structure of this chapter is as follows: first I'll introduce a fictitious data set that we'll use as a running example throughout the chapter. After introducing the data, I'll describe the mechanics of how a one-way ANOVA actually works [How ANOVA works] and then focus on how you can run one in jamovi [Running an ANOVA in jamovi]. These two sections are the core of the chapter.

The remainder of the chapter discusses a range of important topics that inevitably arise when running an ANOVA, namely how to calculate effect sizes, post hoc tests and corrections for multiple comparisons and the assumptions that ANOVA relies upon. We'll also talk about how to check those assumptions and some of the things you can do if the assumptions are violated. Then we'll cover repeated measures ANOVA. --->

## 獨立樣本變異數分析示範資料

想像你正在協助進行一項臨床試驗，測試一種名為*Joyzepam*的新型抗憂鬱藥物的藥效。為了能公平地測試這種新藥的效果，需要分別測試包括新藥的三種藥物，另外兩種藥物之一是安慰劑，還有已經上市的抗憂鬱/抗焦慮藥物，名為*Anxifree*。研究一開始招募18位患有中度至重度抑鬱症的參與者。其中有一半參與者不只是服藥，同時進行認知行為治療（CBT），另一半參與者未同時進行任何心理治療。藥物以雙盲隨機方法分派給參與者，因此每種藥物分派給3位有進行CBT的參與者及3位未進行心理治療的參與者。每位參與者各自使用藥物3個月後，研究者再評估參與者的情緒改善狀況，以$-5$到$+5$的數值代表每位參與者的情緒改善狀況。讀者可以載入資料集 *Clinical Trial*，瀏覽範例資料的內容，其中的變項分別是藥物、治療和情緒改善分數。

為了學習如何使用單因子變異數分析，這裡的目的是要評估各種藥物改善情緒狀況的效果。首先要進行描述統計及繪製統計圖表，我們從  @sec-Descriptive-statistics  已經學到如何使用jamovi完成描述統計，報表會如同 @fig-fig12-1 。



<!--- Suppose you've become involved in a clinical trial in which you are testing a new antidepressant drug called *Joyzepam*. In order to construct a fair test of the drug's effectiveness, the study involves three separate drugs to be administered. One is a placebo, and the other is an existing antidepressant / anti-anxiety drug called *Anxifree*. A collection of 18 participants with moderate to severe depression are recruited for your initial testing. Because the drugs are sometimes administered in conjunction with psychological therapy, your study includes 9 people undergoing cognitive behavioural therapy (CBT) and 9 who are not. Participants are randomly assigned (doubly blinded, of course) a treatment, such that there are 3 CBT people and 3 no-therapy people assigned to each of the 3 drugs. A psychologist assesses the mood of each person after a 3 month run with each drug, and the overall improvement in each person's mood is assessed on a scale ranging from $-5$ to $+5$. With that as the study design, let's now load up the data file in *clinicaltrial.csv* . We can see that this data set contains the three variables drug, therapy and mood.gain.

For the purposes of this chapter, what we're really interested in is the effect of drug on mood.gain. The first thing to do is calculate some descriptive statistics and draw some graphs. In the @sec-Descriptive-statistics chapter we showed you how to do this, and some of the descriptive statistics we can calculate in jamovi are shown in @fig-fig12-1 --->

```{r}
#| label: fig-fig12-1
#| classes: .enlarge-image
#| fig-cap: 情緒改善效果的描述統計報表，以及三種藥物效果的箱形圖。
#Descriptives for mood gain, and box plots by drug administered
knitr::include_graphics("images/fig13-1.png")
```

從 @fig-fig12-1 可以看出，服用Joyzepam的參與者，情緒的改善程度優於服用Anxifree及安慰劑。Anxifree的情緒提升程度優於安慰劑，但是沒有像Joyzepam那麼明顯。這裡要回答的問題是，這些藥物的效果是否“真正有效”，還是只是一次偶然的發現？

<!--- As the plot makes clear, there is a larger improvement in mood for participants in the Joyzepam group than for either the Anxifree group or the placebo group. The Anxifree group shows a larger mood gain than the control group, but the difference isn't as large. The question that we want to answer is are these difference "real", or are they just due to chance? --->

## 單因子變異數分析的運算原理 {#sec-How-ANOVA-works}

為了運用臨床試驗資料回答以上的問題，我們要學習使用單因素變異數分析（one-way ANOVA）。如果讀者不知如何操作jamovi的ANOVA模組選單裡眼花撩亂的選項，先仔細閱讀這一節說明的基本原理，了解ANOVA程序每個步驟的運算概念，跟著[實例演練]操作一兩次，掌握概念後，後續與ANOVA有關的統計方法就不必如此學習了。

[獨立樣本變異數分析示範資料]的說明提到，研究人員有興趣的是三種藥物改善參與者憂鬱情緒的效果，這個研究設計的分析問題類似 @sec-Comparing-two-means 介紹的t檢定範例，不過要比較的不只兩組。在此先定義$\mu_P$代表安慰劑的情緒變化母群平均值，$\mu_A$和$\mu_J$分別對對應Anxifree和Joyzepam兩種藥物效果的平均值，所以要檢定的虛無假設就是：三組的母群平均值是相等的。也就是有點悲觀的預測，兩種藥物的效果都沒有比安慰劑好。這樣的虛無假設可以寫成：

$$H_0: \text{結果顯示 } \mu_P=\mu_A=\mu_J$$

因此對立假設就是：三種藥物之中，至少有一種的效果不同於其他兩種。用數學式表示的話，可能會讓有些同學困惑，由於有很多方式能表達虛無假設是錯誤的，我們先將對立假設寫成：

$$H_1: \text{結果}\underline{沒有}\text{顯示 } \mu_P=\mu_A=\mu_J$$

這道虛無假設比之前單元遇到的要棘手得多，應該要如何進行檢定呢？因為這個單元的標題是變異數分析，聰明的讀者應該猜到就是用「變異數分析」，但是如初學的讀者至此可能還不太了解為何這個方法其實是用來處理平均值。這是許多學生第一次上到變異數分析時，最大的挑戰。為了說明運算原理，我們要從變異數的組成談起，請先參考 @fig-fig12-2 了解什麼是組間變異(Between-group variation)及組內變異(Within-group variation)。

<!--- In order to answer the question posed by our clinical trial data we're going to run a one-way ANOVA. I'm going to start by showing you how to do it the hard way, building the statistical tool from the ground up and showing you how you could do it if you didn't have access to any of the cool built-in ANOVA functions in jamovi. And I hope you'll read it carefully, try to do it the long way once or twice to make sure you really understand how ANOVA works, and then once you've grasped the concept never ever do it this way again.

The experimental design that I described in the previous section strongly suggests that we're interested in comparing the average mood change for the three different drugs. In that sense, we're talking about an analysis similar to the t-test (see @sec-Comparing-two-means) but involving more than two groups. If we let $\mu_P$ denote the population mean for the mood change induced by the placebo, and let $\mu_A$ and $\mu_J$ denote the corresponding means for our two drugs, Anxifree and Joyzepam, then the (somewhat pessimistic) null hypothesis that we want to test is that all three population means are identical. That is, neither of the two drugs is any more effective than a placebo. We can write out this null hypothesis as:

$$H_0: \text{ it is true that } \mu_P=\mu_A=\mu_J$$

As a consequence, our alternative hypothesis is that at least one of the three different treatments is different from the others. It's a bit tricky to write this mathematically, because (as we'll discuss) there are quite a few different ways in which the null hypothesis can be false. So for now we'll just write the alternative hypothesis like this:

$$H_1: \text{ it } \underline{ is \text{ } not } \text{ true that }
\mu_P=\mu_A=\mu_J$$

This null hypothesis is a lot trickier to test than any of the ones we've seen previously. How shall we do it? A sensible guess would be to "do an ANOVA", since that's the title of the chapter, but it's not particularly clear why an "analysis of variances" will help us learn anything useful about the means. In fact, this is one of the biggest conceptual difficulties that people have when first encountering ANOVA. To see how this works, I find it most helpful to start by talking about variances, specifically between group variability and within-group variability (@fig-fig12-2). --->

```{r}
#| label: fig-fig12-2
#| fig-width: 8
#| fig-height: 4
#| fig-cap: 圖解**組間變異** ((a) Between-group variation) 和**組內變異**((b) Within-group variatioon)。圖(a)裡的箭頭顯示分組平均值之間的差異。圖(b)裡的箭頭代表各組之內的變異。
#Graphical illustration of 'between groups' variation (panel (a)) and 'within groups' variation (panel (b)). On the left the arrows show the differences in the group means. On the right the arrows highlight the variability within each group.

p1 <- ggplot(data = data.frame(x = seq(-5, 5, 1)), aes(x)) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = -2, sd = 1), col="darkgrey", linewidth=1) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 0, sd = 1), col="darkgrey", linewidth=1) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 2, sd = 1), col="darkgrey", linewidth=1) +
  geom_segment(x=-2, xend=0, y=0.33, yend=0.33, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  geom_segment(x=0, xend=2, y=0.28, yend=0.28, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  geom_segment(x=-2, xend=2, y=0.23, yend=0.23, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  scale_x_continuous(breaks = seq(-5, 5, 1)) +
  ggtitle("組間變異\n(分組平均值之間的差異)") +
  xlab("\n(a)") +
  scale_x_continuous(breaks=c(-2,0,2), labels=c("分組1", "分組2", "分組3")) +
  theme_classic() +
  theme(
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    plot.title = element_text(hjust = 0.5))

p2 <- ggplot(data = data.frame(x = seq(-5, 5, 1)), aes(x)) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = -2, sd = 1), col="darkgrey", linewidth=1) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 0, sd = 1), col="darkgrey", linewidth=1) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 2, sd = 1), col="darkgrey", linewidth=1) +
  geom_segment(x=-2.8, xend=-1.2, y=0.28, yend=0.28, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  geom_segment(x=-0.8, xend=0.8, y=0.28, yend=0.28, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  geom_segment(x=1.2, xend=2.8, y=0.28, yend=0.28, arrow=arrow(ends='both', length=unit(0.30,"cm"))) +
  scale_x_continuous(breaks = seq(-5, 5, 1)) +
  ggtitle("組內變異\n(各組資料與該組平均值的差異)") +
  xlab("\n(b)") +
  scale_x_continuous(breaks=c(-2,0,2), labels=c("分組1", "分組2", "分組3")) +
  theme_classic() +
  theme(
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    plot.title = element_text(hjust = 0.5))

gridExtra::grid.arrange(p1,p2,ncol=2)

```

### 計算依變項變異數的兩套公式

我們先定義幾個運算用的符號：G代表分組的數量，因為資料集有三種藥物，所以有 $G = 3$ 個分組。然後定義$N$表示總樣本量，這個資料集有 $N = 18$ 位參與者，任可一組的人數同樣用 $N_k$ 表示。這份資料集的三組樣本量都是$N_k = 6$。[^13-comparing-several-means-one-way-anova-1] 最後是定義代表結果變項的Y，也就是每位參與者的情緒狀況改善數值，這裡用$Y_{ik}$ 代表第 k 組的第 i 位參與者改善數值。因此， $\bar{Y}$是所有18位參與者的平均改善數值，$\bar{Y}_k$就是第 k 組的第6位參與者的改善狀況。

[^13-comparing-several-means-one-way-anova-1]: 若是各組的的觀察值數目相等，這樣的研究設計就是“平衡設計”。以這個單位介紹的單因子變異數分析來說，設計是否平衡並不重要。不過要進行較複雜的變異數分析運算，設計是否平衡大有關係。

至此會用的符號都已經就定位，可以開始寫公式了。先回想一下談描述統計的 @sec-Measures-of-variability 提過的變異數公式，這裡的結果變項Y的樣本變異數公式是
 $$Var(Y)=\frac{1}{N}\sum_{k=1}^{G}\sum_{i=1}^{N_k}(Y_{ik}-\bar{Y})^2$$ 這個公式看起來和 @sec-Measures-of-variability 提到的變異數公式長得幾乎一樣。唯一的區別是這個公式有兩個連加記號：各組$k$的平均值總和及組內所有參與者 $i$ 個人數值的總和。請留意一下符號表示的差別，若結果變項符號是
$Y_p$，代表資料裡第p位參與者的數值，這樣子只會有所有參與者個人數值的總和。這裡要寫兩個連加符號，原因是要先將每筆數值歸到其中一組，再指定各組內所代表的個人數值。

這裡用具體的例子來理解應該會有用。來看看 @tbl-tab12-1 的例子，一供有 $N = 5$ 個人分為$G = 2$ 組。我們可以武斷地指定「酷」的人是第 1 組，「不酷」的人是第 2 組。最後列出其中有三個人很酷（$N_1 = 3$）和兩個人不算酷（$N_2 = 2$）。



<!--- First, let's start by introducing some notation. We'll use G to refer to the total number of groups. For our data set there are three drugs, so there are $G = 3$ groups. Next, we'll use $N$ to refer to the total sample size; there are a total of $N = 18$ people in our data set. Similarly, let's use $N_k$ to denote the number of people in the k-th group. In our fake clinical trial, the sample size is $N_k = 6$ for all three groups.[^13-comparing-several-means-one-way-anova-1] Finally, we'll use Y to denote the outcome variable. In our case, Y refers to mood change. Specifically, we'll use Yik to refer to the mood change experienced by the i-th member of the k-th group. Similarly, we'll use $\bar{Y}$ to be the average mood change, taken across all 18 people in the experiment, and $\bar{Y}_k$ to refer to the average mood change experienced by the 6 people in group $k$.

[^13-comparing-several-means-one-way-anova-1]: When all groups have the same number of observations, the experimental design is said to be "balanced". Balance isn't such a big deal for one-way ANOVA, which is the topic of this chapter. It becomes more important when you start doing more complicated ANOVAs.

Now that we've got our notation sorted out we can start writing down formulas. To start with, let's recall the formula for the variance that we used in @sec-Measures-of-variability, way back in those kinder days when we were just doing descriptive statistics. The sample variance of Y is defined as follows $$Var(Y)=\frac{1}{N}\sum_{k=1}^{G}\sum_{i=1}^{N_k}(Y_{ik}-\bar{Y})^2$$ This formula looks pretty much identical to the formula for the variance in @sec-Measures-of-variability. The only difference is that this time around I've got two summations here: I'm summing over groups (i.e., values for $k$) and over the people within the groups (i.e., values for $i$). This is purely a cosmetic detail. If I'd instead used the notation $Y_p$ to refer to the value of the outcome variable for person p in the sample, then I'd only have a single summation. The only reason that we have a double summation here is that I've classified people into groups, and then assigned numbers to people within groups.

A concrete example might be useful here. Let's consider @tbl-tab12-1, in which we have a total of $N = 5$ people sorted into $G = 2$ groups. Arbitrarily, let's say that the "cool" people are group 1 and the "uncool" people are group 2. It turns out that we have three cool people ($N_1 = 3$) and two uncool people ($N_2 = 2$) --->

```{r}
#| label: tbl-tab12-1
#| tbl-cap: 「酷」組和「不酷」組的個別沮喪指數資料。
#Grumpiness for people in cool and uncool groups
huxtabs[[13]][[1]]
```

這個表格結合兩種標記方式。變項 p代表個人，所以用$Y_p$代表第 p 人的沮喪指數。像是第四位是Tim，就用 $p = 4$ 代表他。我們若要用數字討論「Tim」這個人的沮喪程度，可以用$Y_4 = 91$來溝通。而這不是唯一可以描述Tim的方式，另一種方式是根據Tim的分組。因為Tim 是「不酷」組（$k = 2$）的第一人（$i = 1$），也可以用$Y_{12} = 91$代表Tim的沮喪程度。

也就是說，每個人 p 都對應一個獨一無二的 ik 組合，這也就能解釋為他我說上面的變異數公式，與以下更早學到的變異數公式相同的
$$Var(Y)=\frac{1}{N}\sum_{p=1}^{N}(Y_p-\bar{Y})^2$$

這兩個公式都是求樣本資料裡所有觀察值的總和，因為$Y_p$的公式較簡單，做運算練習的功課大都是用第二個公式。但是變異數分析必須要區別那位參與組是屬於那一組，就需要用$Y_{ij}$的公式來做運算。

<!--- Notice that I've constructed two different labelling schemes here. We have a "person" variable p so it would be perfectly sensible to refer to Yp as the grumpiness of the p-th person in the sample. For instance, the table shows that Tim is the fourth so we'd say $p = 4$. So, when talking about the grumpiness $Y$ of this "Tim" person, whoever he might be, we could refer to his grumpiness by saying that $Y_p = 91$, for person $p = 4$ that is. However, that's not the only way we could refer to Tim. As an alternative we could note that Tim belongs to the "uncool" group ($k = 2$), and is in fact the first person listed in the uncool group ($i = 1$). So it's equally valid to refer to Tim's grumpiness by saying that $Y_{ik} = 91$, where $k = 2$ and $i = 1$.

In other words, each person p corresponds to a unique ik combination, and so the formula that I gave above is actually identical to our original formula for the variance, which would be $$Var(Y)=\frac{1}{N}\sum_{p=1}^{N}(Y_p-\bar{Y})^2$$ In both formulas, all we're doing is summing over all of the observations in the sample. Most of the time we would just use the simpler Yp notation; the equation using $Y_p$ is clearly the simpler of the two. However, when doing an ANOVA it's important to keep track of which participants belong in which groups, and we need to use the Yik notation to do this. --->

### 變異數與離均差平方和

好啦，更進一步認識變異數的計算方法後，就能討論什麼是**總離均差平方和**（total sum of squares），簡記為$SS_{tot}$。變異數是離均差平方和的平均結果，計算$SS_{tot}$只要算總和就好。[^13-comparing-several-means-one-way-anova-2]

[^13-comparing-several-means-one-way-anova-2]: 所以總離均差平方和的公式與變異數的公式長得幾乎一樣 $$SS_{tot}=\sum_{k=1}^{G} \sum_{i=1}^{N_k} (Y_{ik} - \bar{Y})^2$$

在ANOVA的單元討論如何分析變異數，其實是談如何處理離均差平方和，而不是講如何處理變異數。[^13-comparing-several-means-one-way-anova-3]

[^13-comparing-several-means-one-way-anova-3]: 總離均差平方和能被分解成兩種離均差，帶來計算的便利性。第一種離均差是組內離均差平方和，是每個資料與所屬分組平均值之間差異$$SS_{w}= \sum_{k=1}^{G} \sum_{i=1}^{N_k} (Y_{ik} - \bar{Y}_k)^2$$ $\bar{Y}_k$ 是某一分組平均值，在此代表服用第 k 種藥物的參與者情緒狀態改善狀況，也就是並非比較每個人的數值與所有參與者的總平均值，而是各分組之內的參與者彼此比較。所以$SS_w$的值一定會小於總離均差平方和，因為完全不包括分組之間的差異，也就是各種藥物的效果。

接著來談較難講的組間離均差是怎麼回事，這裡就要來拆解分組平均值 $\bar{Y}_k$ 和總平均值 $\bar{Y}$是怎麼構成了。[^13-comparing-several-means-one-way-anova-4]

[^13-comparing-several-means-one-way-anova-4]: 這一步要知道的是如何計算組間離均差平方和 $$ \begin{aligned} SS_{b} &= \sum_{k=1}^{G} \sum_{i=1}^{N_k} ( \bar{Y}_{k} - \bar{Y} )^2 \\ &= \sum_{k=1}^{G} N_k ( \bar{Y}_{k} - \bar{Y} )^2 \end{aligned} $$

如此看來，所有實驗參與者之間的總離均差平方和（$SS_{tot}$），等於組間離均差平方和（$SS_b$），加上組內離均差平方和（$SS_w$）。其實不怎麼需要證明

$$SS_w+SS_b=SS_{tot}$$ 

太棒了！

所以我們學到什麼？我們已經懂得與結果變項相關的總離均差平方和（$SS_{tot}$），可以被劃分為“分組的樣本平均值之間的差異所造成的變異”的總和（$SS_b$），加上“除此之外的任何變異”的總和（$SS_w$）[^13-comparing-several-means-one-way-anova-5]。

那要怎麼幫研究人員確認各組的母群平均值相不相等呢？嗯，稍等一下，有沒有看到每種離均差平方和都是各種平均值之間的差異？若是虛無假設的推測是成立的，代表各組樣本平均值$\bar{Y_k}$ 應該是非常相等的，沒錯吧？也就是說$SS_b$要非常小，至少要比“除此之外的任何變異”（$SS_w$）明顯的小。有沒有聞到假設檢定的味道了？

[^13-comparing-several-means-one-way-anova-5]: 在獨立樣本變異數分的報告裡， $SS_w$ 也被稱為誤差總和 $SS_{error}$。

<!--- 

Okay, now that we've got a good grasp on how the variance is calculated, let's define something called the **total sum of squares**, which is denoted SStot. This is very simple. Instead of averaging the squared deviations, which is what we do when calculating the variance, we just add them up.[^13-comparing-several-means-one-way-anova-2]

[^13-comparing-several-means-one-way-anova-2]: So the formula for the total sum of squares is almost identical to the formula for the variance $$SS_{tot}=\sum_{k=1}^{G} \sum_{i=1}^{N_k} (Y_{ik} - \bar{Y})^2$$

When we talk about analysing variances in the context of ANOVA, what we're really doing is working with the total sums of squares rather than the actual variance. [^13-comparing-several-means-one-way-anova-3]

[^13-comparing-several-means-one-way-anova-3]: One very nice thing about the total sum of squares is that we can break it up into two different kinds of variation First, we can talk about the within-group sum of squares, in which we look to see how different each individual person is from their own group mean $$SS_{w}= \sum_{k=1}^{G} \sum_{i=1}^{N_k} (Y_{ik} - \bar{Y}_k)^2$$ where $\bar{Y}_k$ is a group mean. In our example, $\bar{Y}_k$ would be the average mood change experienced by those people given the k-th drug. So, instead of comparing individuals to the average of all people in the experiment, we're only comparing them to those people in the the same group. As a consequence, you'd expect the value of $SS_w$ to be smaller than the total sum of squares, because it's completely ignoring any group differences, i.e., whether the drugs will have different effects on people's moods

Next, we can define a third notion of variation which captures only the differences between groups. We do this by looking at the differences between the group means $\bar{Y}_k$ and grand mean $\bar{Y}$. [^13-comparing-several-means-one-way-anova-4]

[^13-comparing-several-means-one-way-anova-4]: In order to quantify the extent of this variation, what we do is calculate the between-group sum of squares $$ \begin{aligned} SS_{b} &= \sum_{k=1}^{G} \sum_{i=1}^{N_k} ( \bar{Y}_{k} - \bar{Y} )^2 \\ &= \sum_{k=1}^{G} N_k ( \bar{Y}_{k} - \bar{Y} )^2 \end{aligned} $$

It's not too difficult to show that the total variation among people in the experiment ($SS_{tot}$ is actually the sum of the differences between the groups $SS_b$ and the variation inside the groups $SS_w$. That is,

$$SS_w+SS_b=SS_{tot}$$ Yay.

Okay, so what have we found out? We've discovered that the total variability associated with the outcome variable ($SS_{tot}$) can be mathematically carved up into the sum of "the variation due to the differences in the sample means for the different groups" ($SS_b$) plus "all the rest of the variation" ($SS_w$) [^13-comparing-several-means-one-way-anova-5].

How does that help me find out whether the groups have different population means? Um. Wait. Hold on a second. Now that I think about it, this is exactly what we were looking for. If the null hypothesis is true then you'd expect all the sample means to be pretty similar to each other, right? And that would imply that you'd expect $SS_b$ to be really small, or at least you'd expect it to be a lot smaller than "the variation associated with everything else", $SS_w$. Hmm. I detect a hypothesis test coming on.

[^13-comparing-several-means-one-way-anova-5]: SS_w is also referred to in an independent ANOVA as the error variance, or $SS_{error}$

--->

### 離均差平方和與F檢定

前一節我們已經了解ANOVA運算的核心思想是比較$SS_b$ 和 $SS_w$，若是組間離均差平方和$SS_b$是相對大於組內離均差平方和$SS_w$，就有理由懷疑各組的母群平均值並不相等。為了轉化為可操作的假設檢定程序，我們要進行一些“微調”。我們先來認識如何計算檢驗統計值——**F值(F ratio)**，然後再來討論要計算F值的原因。

為了將離均差平方和轉換為F值，首先要計算$SS_b$ 和 $SS_w$的**自由度**。通常自由度是指為了計算估計值，需要貢獻的“資料點”數量，減去滿足“要估計”的參數數量。組內離均差平方和的計算元素是$N$筆個別觀察值與$G$ 個分組平均值之間的變異；而組間離均差平方和的計算元素是$G$ 個分組平均值與唯一一個總體平均值之間的變異。所以有兩個自由度：

$$df_b=G-1$$ $$df_w=N-G$$

這看起來很簡單，是吧。接著是將平方和轉換為“平方和的平均”，也就是各自除以自由度：

$$MS_b=\frac{SS_b}{df_b}$$ $$MS_w=\frac{SS_w}{df_w}$$

最後，將組間 MS 除以組內 MS 就能算出 F 值：

$$F=\frac{MS_b}{MS_w}$$

表面上來看，F統計值的運算相當直覺又好懂。F 值越大，就表示組間變異與組內變異之間的差異越大。所以F值起大，能反駁虛無假設的證據力就越強。但是 $F$ 要有多大才能確實拒絕 $H_0$？為了清楚理解，我們要更深入了解 ANOVA 是什麼，以及什麼是離均差平方和的平均？

這些問題在[實例演練]將有詳細討論，不過如果讀者對於詳細的回答不感興趣，這裡提供一個簡短的說明。為了完成假設檢定，分析人員需要知道虛無假設符合推測時的F值取樣分佈。這一點都不奇怪，因為由虛無假設生成的F統計值取樣分佈，必定是一個F分佈。回想 @sec-Introduction-to-probability 有關F 分佈的說明，$F$ 分佈的兩個參數各對應兩個自由度。第一個 $df_1$ 對應組間自由度 $df_b$，第二個 $df_2$ 對應組內自由度 $df_w$。

<!---
As we saw in the last section, the qualitative idea behind ANOVA is to compare the two sums of squares values $SS_b$ and $SS_w$ to each other. If the between-group variation $SS_b$ is large relative to the within-group variation $SS_w$ then we have reason to suspect that the population means for the different groups aren't identical to each other. In order to convert this into a workable hypothesis test, there's a little bit of "fiddling around" needed. What I'll do is first show you what we do to calculate our test statistic, the **F ratio**, and then try to give you a feel for why we do it this way.

In order to convert our SS values into an F-ratio the first thing we need to calculate is the **degrees of freedom** associated with the $SS_b$ and $SS_w$ values. As usual, the degrees of freedom corresponds to the number of unique "data points" that contribute to a particular calculation, minus the number of "constraints" that they need to satisfy. For the within-groups variability what we're calculating is the variation of the individual observations ($N$ data points) around the group means ($G$ constraints). In contrast, for the between groups variability we're interested in the variation of the group means (G data points) around the grand mean (1 constraint). Therefore, the degrees of freedom here are:

$$df_b=G-1$$ $$df_w=N-G$$

Okay, that seems simple enough. What we do next is convert our summed squares value into a "mean squares" value, which we do by dividing by the degrees of freedom:

$$MS_b=\frac{SS_b}{df_b}$$ $$MS_w=\frac{SS_w}{df_w}$$

Finally, we calculate the F-ratio by dividing the between-groups MS by the within-groups MS:

$$F=\frac{MS_b}{MS_w}$$

At a very general level, the intuition behind the F statistic is straightforward. Bigger values of F means that the between-groups variation is large relative to the within-groups variation. As a consequence, the larger the value of F the more evidence we have against the null hypothesis. But how large does $F$ have to be in order to actually reject $H_0$? In order to understand this, you need a slightly deeper understanding of what ANOVA is and what the mean squares values actually are.

The next section discusses that in a bit of detail, but for readers that aren't interested in the details of what the test is actually measuring I'll cut to the chase. In order to complete our hypothesis test we need to know the sampling distribution for F if the null hypothesis is true. Not surprisingly, the sampling distribution for the F <u>statistic</u> under the null hypothesis is an $F$ distribution. If you recall our discussion of the F distribution in @sec-Introduction-to-probability, the $F$ <u>distribution</u> has two parameters, corresponding to the two degrees of freedom involved. The first one $df_1$ is the between groups degrees of freedom $df_b$, and the second one $df_2$ is the within groups degrees of freedom $df_w$. --->

```{r}
#| label: tbl-tab12-2
#| tbl-cap: 組織所有變異數分析計算過程所產生的關鍵計數，構成的“標準化” 變異數分析報表。此表展示所有關鍵計數的公式，除了 p 值，因為公式非常複雜，沒有計算機的話，算起來會非常困難。
#All of the key quantities involved in an ANOVA organised into a 'standard' ANOVA table. The formulas for all quantities (except the p-value which has a very ugly formula and would be nightmarishly hard to calculate without a computer) are shown
huxtabs[[13]][[2]]
```

@tbl-tab12-2 摘要所有單因子變異數計算過程所產生的關鍵計數，包括各項計數的計算公式。

[額外的技術細節 [^13-comparing-several-means-one-way-anova-6]]

[^13-comparing-several-means-one-way-anova-6]: 追根究底來說，ANOVA 就是兩種不同的統計模型，$H_0$和$H_1$，的對決過程。這個單元一開始提到虛無假設和對立假設所用描述方式，其實不夠精確。在此要做點補救，儘管這樣會讓一些讀者感到厭煩。回憶一下，這個單元設定的虛無假設是各分組平均值彼此相等。若是如此，拆解結果變項 $Y_{ik}$ 的方式應該是將個別數值當成唯一的母群平均值$\mu$，加上因為測量方式，實際數值與母群平均值之間的偏差，通常會用$\epsilon_{ik}$表示，學術界習慣稱為誤差或殘差。不過請小心用詞，如同“顯著”這個詞義的歷史演變，“誤差”的詞義在統計學的場域不完全等於日常生活的模糊含義。日常用語的“誤差”暗示某種錯誤，但是統計學所指的不完全是任何一種錯誤。因此在統計學場域用“殘差”，會比“誤差”不易讓人誤會。這兩個詞都表示“剩餘變異”，也就是模型無法解釋的“部分”。不論是那種稱呼，將虛無假設寫成統計模型的話，看起來就是 $$Y_{ik}=\mu+\epsilon_{ik}$$ 本書稍後會討論到，通常會設定各分組的殘差值 $\epsilon_{ik}$皆符合平均值為 $0$，標準差為 $\sigma$的常態分佈。運用從[機率入門](@sec-Introduction-to-probability)學到的符號，殘差的數學模型可以寫成 $$\epsilon_{ik} \sim Normal(0,\sigma^2)$$ 那要如何設定對立假設 $H_1$ 呢？虛無假設和對立假設的唯一區別是，研究者認為各組的母群平均值並不相等。所以只要設定$\mu_k$ 表示第 k 組的母群平均值，$H_1$ 的統計模型就是 $$Y_{ik}=\mu_k+\epsilon_{ik}$$ 同樣地，其中的分組殘差也都是平均值為 $0$，標準差為 $\sigma$的常態分佈。也就是說，對立假設還帶上 $\epsilon_{ik} \sim Normal(0,\sigma^2)$ 這個條件。<br/> 現在$H_0$ 和 $H_1$的統計模型都正式登場，可以清楚說明如何評估離均差平方和平均，以及如何解釋$F$的意思。這裡不需要做任何數學證明，我們只要知道，組內離均差平方和平均 $MS_w$ 可以當成各組殘差的變異數估計值。組間離均差平方和平均$MS_b$也是一組估計值，除了各組殘差的變異數估計值，還有各組平均值之間的差異值。以$Q$代表這項差異值，就能將F統計數的公式改寫為 $^a$ $$F=\frac{\hat{Q}+\hat{\sigma}^2}{\hat{\sigma}^2}$$ 若是虛無假設的推測成立，$Q = 0$；若是對立假設的推測成立，$Q < 0$(請參考 @Hays1994 ，ch. 10)<br/>這就是為什麼在變異數分析的狀況，$F$ *值必須大於* 1，是拒絕虛無假設的基本條件。讀者要注意的是，這不是說F 值不可能小於 1。嚴格地說，如果虛無假設的推測成立，估計值的取樣分佈會逼近期望值是1的F分佈 $^b$，所以F 值必須要大於 1，才能安全地拒絕虛無假設。<br/> 從上一段的F值公式可知，$MS_b$和$MS_w$，都有殘差 $\epsilon_{ik}$ 變異數的估計值，如果虛無假設的推測成立，兩者就只有殘差變異數的估計值。若殘差符合常態分佈，根據 @sec-Other-useful-distributions 學過的卡方分佈，讀者會想到$\epsilon_{ik}$的變異數估計值其實應該符合卡方分佈。這就是卡方分佈的真正面貌：無數個符合常態分佈的隨機變數平方後，累加形成的機率分佈。F分佈則是兩件符合卡方分佈的隨機變數之比值，集合形成的機率分佈。當然，以上說明省略許多細節，不過這是至此介紹過的各種統計檢定方法，所依據的取樣分佈來源。<br /> --- <br />  $^a$ 如果讀者已經讀過 @sec-Factorial-ANOVA ，學到如何用 $\alpha_k$ 定義因子內水準 k 的「處理效應」（參考 @sec-Factorial-ANOVA-balanced-n-interaction 及 @sec-Factorial-ANOVA-balanced-w-interaction ），會知道 $Q$ 是處理效應平方的加權平均值，$Q = \frac{(\sum_{k=1}^{G}N_k \alpha_k^2)}{(G-1)}$ <br /> $^b$ 或者是更精確的F分佈期望值 $1+\frac{2}{df_2-2}$。

<!---
A summary of all the key quantities involved in a one-way ANOVA, including the formulas showing how they are calculated, is shown in @tbl-tab12-2.

[Additional technical detail [^13-comparing-several-means-one-way-anova-6]]

[^13-comparing-several-means-one-way-anova-6]: At a fundamental level ANOVA is a competition between two different statistical models, $H_0$ and $H_1$. When I described the null and alternative hypotheses at the start of the section, I was a little imprecise about what these models actually are. I'll remedy that now, though you probably won't like me for doing so. If you recall, our null hypothesis was that all of the group means are identical to one another. If so, then a natural way to think about the outcome variable $Y_{ik}$ is to describe individual scores in terms of a single population mean µ, plus the deviation from that population mean. This deviation is usually denoted $\epsilon_{ik}$ and is traditionally called the error or residual associated with that observation. Be careful though. Just like we saw with the word "significant", the word "error" has a technical meaning in statistics that isn't quite the same as its everyday English definition. In everyday language, "error" implies a mistake of some kind, but in statistics it doesn't (or at least, not necessarily). With that in mind, the word "residual" is a better term than the word "error". In statistics both words mean "leftover variability", that is "stuff" that the model can't explain. In any case, here's what the null hypothesis looks like when we write it as a statistical model $$Y_{ik}=\mu+\epsilon_{ik}$$ where we make the assumption (discussed later) that the residual values $\epsilon_{ik}$ are normally distributed, with mean $0$ and a standard deviation $\sigma$ that is the same for all groups. To use the notation that we introduced in the [Introduction to probability] we would write this assumption like this $$\epsilon_{ik} \sim Normal(0,\sigma^2)$$ What about the alternative hypothesis, $H_1$? The only difference between the null hypothesis and the alternative hypothesis is that we allow each group to have a different population mean. So, if we let $\mu_k$ denote the population mean for the k-th group in our experiment, then the statistical model corresponding to $H_1$ is $$Y_{ik}=\mu_k+\epsilon_{ik}$$ where, once again, we assume that the error terms are normally distributed with mean 0 and standard deviation $\sigma$. That is, the alternative hypothesis also assumes that $\epsilon \sim Normal(0,\sigma^2)$ Okay, now that we've described the statistical models underpinning $H_0$ and $H_1$ in more detail, it's now pretty straightforward to say what the mean square values are measuring, and what this means for the interpretation of $F$. I won't bore you with the proof of this but it turns out that the within-groups mean square, $MS_w$, can be viewed as an estimator of the error variance $\sigma^2$ . The between-groups mean square $MS_b$ is also an estimator, but what it estimates is the error variance plus a quantity that depends on the true differences among the group means. If we call this quantity $Q$, then we can see that the F-statistic is basically$^a$ $$F=\frac{\hat{Q}+\hat{\sigma}^2}{\hat{\sigma}^2}$$ where the true value $Q = 0$ if the null hypothesis is true, and Q < 0 if the alternative hypothesis is true (e.g., @Hays1994, ch. 10). Therefore, at a bare minimum the $F$ *value must be larger than* 1 to have any chance of rejecting the null hypothesis. Note that this doesn't mean that it's impossible to get an F-value less than 1. What it means is that if the null hypothesis is true the sampling distribution of the F ratio has a mean of 1,[\^b] and so we need to see F-values larger than 1 in order to safely reject the null. To be a bit more precise about the sampling distribution, notice that if the null hypothesis is true, both MSb and MSw are estimators of the variance of the residuals $\epsilon_{ik}$. If those residuals are normally distributed, then you might suspect that the estimate of the variance of $\epsilon_{ik}$ is chi-square distributed, because (as discussed in the @sec-Other-useful-distributions) that's what a chi-square distribution is: it's what you get when you square a bunch of normally-distributed things and add them up. And since the F distribution is (again, by definition) what you get when you take the ratio between two things that are $\chi^2$ distributed, we have our sampling distribution. Obviously, I'm glossing over a whole lot of stuff when I say this, but in broad terms, this really is where our sampling distribution comes from. <br /> --- <br />  $^a$ If you read ahead to @sec-Factorial-ANOVA and look at how the "treatment effect" at level k of a factor is defined in terms of the $\alpha_k$ values (see section on Factorial ANOVA 2: balanced designs, interactions allowed]), it turns out that $Q$ refers to a weighted mean of the squared treatment effects, $Q = \frac{(\sum_{k=1}^{G}N_k \alpha_k^2)}{(G-1)}$ <br /> $^b$ Or, if we want to be sticklers for accuracy, $1+ \frac{2}{df_2-2}$

--->

### 實例演練

前一節的說明相當抽象且有點技術性，因此這裡採用範例的計算做個完整的說明。我們再回到一開始介紹的[獨立樣本變異數分析示範資料]，這份臨床試驗資料已經有描述統計表，我們知道各組平均值：安慰劑的情緒改善平均分數是 $0.45$，Anxifree 是 $0.72$，Joyzepam 是 $1.48$。有了這些資訊和計算公式，我們可以辦個1899年的統計趴[^13-comparing-several-means-one-way-anova-7]，純粹用鉛筆和紙做計算。不過這裡只做前5筆資料的計算，因為現在不是沒有計算機的1899年，而且原作者本人相當懶惰。首先從計算組內離均差平方和$SS_w$ 開始，我們要畫一張像 @tbl-tab12-3 的表格來協助計算。


[^13-comparing-several-means-one-way-anova-7]: 或者更確切描述是像 "1899年的統計專家那樣熱衷計算，當時我們沒有朋友，也沒有比算術更有趣的事情可做，因為直到 1920 年左右，ANOVA 並不存在於世上。"

<!--- The previous discussion was fairly abstract and a little on the technical side, so I think that at this point it might be useful to see a worked example. For that, let's go back to the clinical trial data that I introduced at the start of the chapter. The descriptive statistics that we calculated at the beginning tell us our group means: an average mood gain of $0.45$ for the placebo, $0.72$ for Anxifree, and $1.48$ for Joyzepam. With that in mind, let's party like it's 1899 [^13-comparing-several-means-one-way-anova-7] and start doing some pencil and paper calculations. I'll only do this for the first $5$ observations because it's not bloody $1899$ and I'm very lazy. Let's start by calculating $SS_w$, the within-group sums of squares. First, let's draw up a nice table to help us with our calculations (@tbl-tab12-3)

[^13-comparing-several-means-one-way-anova-7]: Or, to be precise, party like "it's 1899 and we've got no friends and nothing better to do with our time than do some calculations that wouldn't have made any sense in 1899 because ANOVA didn't exist until about the 1920s". --->

```{r}
#| label: tbl-tab12-3
#| tbl-cap: 實例演練第一步
#A worked example...1
huxtabs[[13]][[3]]
```

第一步的表格只有原始資料，也就是每位參與者服用藥物的分組變項，以及情緒改善狀況的結果變項。請注意，這個結果變項對應前面提到的$\bar{Y}_{ik}$。接下來是計算每位參與者所屬分組的分平均值，$\bar{Y}_k$。這個步驟並不困難，因為描述統計表裡都有了，加上去後就變成 @tbl-tab12-4 。

<!--- At this stage, the only thing I've included in the table is the raw data itself. That is, the grouping variable (i.e., drug) and outcome variable (i.e. mood.gain) for each person. Note that the outcome variable here corresponds to the $\bar{Y}_{ik}$ value in our equation previously. The next step in the calculation is to write down, for each person in the study, the corresponding group mean, $\bar{Y}_k$. This is slightly repetitive but not particularly difficult since we already calculated those group means when doing our descriptive statistics, see @tbl-tab12-4. --->

```{r}
#| label: tbl-tab12-4
#| tbl-cap: 實例演練第二步
#A worked example...2
huxtabs[[13]][[4]]
```

都算到這裡了，接著就能計算每位參與者的離均差，也就是$Y_{ik} - \bar{Y}_k$，也能順手把每個離均差平方，最後就得到 @tbl-tab12-5 



<!---Now that we've written those down, we need to calculate, again for every person, the deviation from the corresponding group mean. That is, we want to subtract $Y_{ik} - \bar{Y}_k$. After we've done that, we need to square everything. When we do that, here's what we get (@tbl-tab12-5) --->

```{r}
#| label: tbl-tab12-5
#| tbl-cap: 實例演練第三步
#A worked example...3
huxtabs[[13]][[5]]
```

計算組內離均差平方和就簡單啦，就是將所有離均差平方加起來：

$$
\begin{split}
SS_w & = 0.0025 + 0.0225 + 0.1225 + 0.0136 + 0.1003 \\
& = 0.2614
\end{split}
$$

當然，真正完整的計算是要將全部18筆觀察值進行以上四個計算步驟，而不是只算演練的五筆。讀者有心的話，可以繼續筆算，不過這麼做相當繁瑣。其實也可以用LibreOffice或Excel試算表軟體演練，試試看並不困難。讀者們可以自已在Excel開一個檔案，命名為clinicaltrial_anova.xls。完成這裡示範的四個步驟，就能得到組內離均差平方和的值是$1.39$。

到這裡已經算出組內離均差平方和$SS_w$的值，接下來就是處理組間離均差平方和$SS_b$ 。其實計算步驟相當類似，差異是要改成計算各分組平均值 $\bar{Y}_k$ 與總平均值 $\bar{Y}$的差異，計算表格就變成 @tbl-tab12-6 ，得到的值是 $0.88$。

<!---

The last step is equally straightforward. In order to calculate the within-group sum of squares we just add up the squared deviations across all observations:

$$
\begin{split}
SS_w & = 0.0025 + 0.0225 + 0.1225 + 0.0136 + 0.1003 \\
& = 0.2614
\end{split}
$$

Of course, if we actually wanted to get the right answer we'd need to do this for all 18 observations in the data set, not just the first five. We could continue with the pencil and paper calculations if we wanted to, but it's pretty tedious. Alternatively, it's not too hard to do this in a dedicated spreadsheet programme such as OpenOffice or Excel. Try and do it yourself. The one that I did, in Excel, is in the file clinicaltrial_anova.xls. When you do it you should end up with a within-group sum of squares value of $1.39$.

Okay. Now that we've calculated the within groups variation, $SS_w$, it's time to turn our attention to the between-group sum of squares, $SS_b$. The calculations for this case are very similar. The main difference is that instead of calculating the differences between an observation Yik and a group mean $\bar{Y}_k$ for all of the observations, we calculate the differences between the group means $\bar{Y}_k$ and the grand mean $\bar{Y}$ (in this case $0.88$) for all of the groups (@tbl-tab12-6).

--->

```{r}
#| label: tbl-tab12-6
#| tbl-cap: 實例演練第4步
huxtabs[[13]][[6]]
```

不過因為是計算組間的平方和，還要將每個離均差平方先乘以 $N_k$，也就是各組的觀察值數量。這樣做是因為同組的$N_k$個觀察值，都與組間差異有關。安慰劑組有六筆資料，而安慰劑組的平均值與總平均值相差 $0.19$，因此六位參與者的組間離均差平方加權總和是$6 \times 0.19 = 1.14$。所以計算表格還要擴展成 @tbl-tab12-7 。

<!---
However, for the between group calculations we need to multiply each of these squared deviations by $N_k$, the number of observations in the group. We do this because every observation in the group (all $N_k$ of them) is associated with a between group difference. So if there are six people in the placebo group and the placebo group mean differs from the grand mean by $0.19$, then the total between group variation associated with these six people is $6 \times 0.19 = 1.14$. So we have to extend our little table of calculations (@tbl-tab12-7). --->

```{r}
#| label: tbl-tab12-7
#| tbl-cap: 實例演練第5步
huxtabs[[13]][[7]]
```

接著就可以將所有“加權的離均差平方”加起來，得到組間離均差平方和：

$$\begin{aligned} SS_b & = 1.14 + 0.18 + 2.16 \\ &= 3.48 \end{aligned}$$

正如讀者看到的，這次計算離均差平方和的步驟比較少 [^13-comparing-several-means-one-way-anova-8]。即然己經算出$SS_b$ 和 $SS_w$的值，ANOVA剩下的工作就就相當簡單了。接下來是計算自由度。由於知道 $G = 3$ 個分組以及 $N = 18$ 個觀察值，自由度用簡單的減法就可以計算：

[^13-comparing-several-means-one-way-anova-8]: 使用 Excel 計算完整的$SS_b$，會因為四捨五入得到不大一樣的值，可能是 $3.45$。

$$
\begin{split}
df_b & = G-1 = 2 \\
df_w & = N-G = 15
\end{split}
$$

有了離均差平方和和自由度的值，只要以前者除以後者，就能算出組內與組間變異數，也就是離均差平方和的平均：

$$
\begin{split}
MS_b & = \frac{SS_b}{df_b} = \frac{3.48}{2} = 1.74 \\
MS_w & = \frac{SS_w}{df_w} = \frac{1.39}{15} = 0.09
\end{split}
$$

快要完成了。有了兩個平均值，就能計算最想知道的F值。只要將$MS_b$除以$MS_w$就能得到。

$$
\begin{split}
F & = \frac{MS_b}{MS_w}  = \frac{1.74}{0.09} \\
& = 19.3
\end{split}
$$

我們真的完成了，很令人高興對吧！有了檢定統計值，最後就是判斷這個統計值是否代表結果是顯著的。如同在 @sec-Hypothesis-testing 討論過的手作方法，有心的讀者可以翻開任何一本統計教科書的附錄，查找其中有關F檢定的表，只要找到指定 $\alpha$值所對應的閾值，例如 $0.05$，$0.01$ 或 $0.001$，搭配 自由度2 和15。設定$\alpha$為 $0.001$ 的話，會查到F的閾值是$11.34$。因為小於最後算出的F值，可以宣稱$p < 0.001$。但這是時代的眼淚，今天各式各樣的統計軟體能為我們算出精確的p值。這個範例的p值是 $0.000071$。除非我們對型一錯誤率採取非常謹慎的立場，我們幾乎 可以結論這樣的研究結果能拒絕虛無假設。

至此己經完成了ANOVA的基本計算，將以上步驟算出的數值，整理成如 @tbl-tab-12-1 的報表，是傳統的變異數分析報告規範。完整的ANOVA報表請見 @tbl-tab12-8 。

<!---
And so now our between group sum of squares is obtained by summing these "weighted squared deviations" over all three groups in the study:

$$\begin{aligned} SS_b & = 1.14 + 0.18 + 2.16 \\ &= 3.48 \end{aligned}$$

As you can see, the between group calculations are a lot shorter[^13-comparing-several-means-one-way-anova-8]. Now that we've calculated our sums of squares values, $SS_b$ and $SS_w$, the rest of the ANOVA is pretty painless. The next step is to calculate the degrees of freedom. Since we have $G = 3$ groups and $N = 18$ observations in total our degrees of freedom can be calculated by simple subtraction:

[^13-comparing-several-means-one-way-anova-8]: In the Excel *clinicaltrial-anova.xls*  the value for SSb worked out to be very slightly different, $3.45$, than that shown in the text above (rounding errors!)

$$
\begin{split}
df_b & = G-1 = 2 \\
df_w & = N-G = 15
\end{split}
$$

Next, since we've now calculated the values for the sums of squares and the degrees of freedom, for both the within-groups variability and the between-groups variability, we can obtain the mean square values by dividing one by the other:

$$
\begin{split}
MS_b & = \frac{SS_b}{df_b} = \frac{3.48}{2} = 1.74 \\
MS_w & = \frac{SS_w}{df_w} = \frac{1.39}{15} = 0.09
\end{split}
$$

We're almost done. The mean square values can be used to calculate the F-value, which is the test statistic that we're interested in. We do this by dividing the between-groups MS value by the within-groups MS value.

$$
\begin{split}
F & = \frac{MS_b}{MS_w}  = \frac{1.74}{0.09} \\
& = 19.3
\end{split}
$$

Woohooo! This is terribly exciting, yes? Now that we have our test statistic, the last step is to find out whether the test itself gives us a significant result. As discussed in @sec-Hypothesis-testing back in the "old days" what we'd do is open up a statistics textbook or flick to the back section which would actually have a huge lookup table and we would find the threshold $F$ value corresponding to a particular value of alpha (the null hypothesis rejection region), e.g. $0.05$, $0.01$ or $0.001$, for 2 and 15 degrees of freedom. Doing it this way would give us a threshold F value for an alpha of $0.001$ of $11.34$. As this is less than our calculated $F$ value we say that $p < 0.001$. But those were the old days, and nowadays fancy stats software calculates the exact p-value for you. In fact, the exact p-value is $0.000071$. So, unless we're being *extremely* conservative about our Type I error rate, we're pretty much guaranteed to reject the null hypothesis.

At this point, we're basically done. Having completed our calculations, it's traditional to organise all these numbers into an ANOVA table like the one in Table 13.1. For our clinical trial data, the ANOVA table would look like @tbl-tab12-8. --->

```{r}
#| label: tbl-tab12-8
#| tbl-cap: 完整的變異數分析報表
#The ANOVA results table
huxtabs[[13]][[8]]
```

到這裡，讀者應該不大想靠純手工計算整理出這樣的報表，幾乎所有專業統計軟體，包括 jamovi，都能將ANOVA 的結果統整成像 @tbl-tab12-8 的表格，所以最好習慣一下。儘管軟體能輸出完整的 ANOVA 報表，我們從未有需要在報告裡置放整份表格，現代學術寫作規範所建議的標準格式是類似以下的句子：

> *單因子變異數分析顯示，測試的藥物對情緒改善有顯著影響，F(2,15) = 19.3，p < .001。*

我的老天！做了這麼多事，只為了寫這一行短句。

<!--- These days, you'll probably never have much reason to want to construct one of these tables yourself, but you will find that almost all statistical software (jamovi included) tends to organise the output of an ANOVA into a table like this, so it's a good idea to get used to reading them. However, although the software will output a full ANOVA table, there's almost never a good reason to include the whole table in your write up. A pretty standard way of reporting the stats block for this result would be to write something like this:

> *One-way ANOVA showed a significant effect of drug on mood gain (F(2,15) = 19.3, p < .001).*

Sigh. So much work for one short sentence. --->

## jamovi的變異數分析模組 {#running-an-anova-in-jamovi}

我相當確定在讀完上一節之後，您在想什麼，特別是如果您按照我的建議，用鉛筆和紙（即在試算表中）自己完成所有這些工作。自己做 ANOVA 計算很糟糕。沿途我們需要做相當多的計算，如果每次想做 ANOVA 都要一次又一次地做這些計算，會讓人厭煩。

<!-- I'm pretty sure I know what you're thinking after reading the last section, especially if you followed my advice and did all of that by pencil and paper (i.e., in a spreadsheet) yourself. Doing the ANOVA calculations yourself sucks. There's quite a lot of calculations that we needed to do along the way, and it would be tedious to have to do this over and over again every time you wanted to do an ANOVA. --->

### 使用jamovi完成變異數分析

為了讓您的生活更輕鬆，jamovi 可以做 ANOVA... 哈拉！ 轉到「ANOVA」-「ANOVA」分析，將 mood.gain 變項移到「依賴變項」框中，然後將 drug 變項移到「固定因子」框中。這樣應該會得到 @fig-fig12-3 中所示的結果。[^13-comparing-several-means-one-way-anova-9] 注意我還勾選了 'Effect Size'選項下的 $\eta^2$ 复选框，念作“ eta 平方”，這也顯示在結果表格上。稍後我們將回到效應大小。



<!--- To make life easier for you, jamovi can do ANOVA...hurrah! Go to the 'ANOVA' - 'ANOVA' analysis, and move the mood.gain variable across so it is in the 'Dependent Variable' box, and then move the drug variable across so it is in the 'Fixed Factors' box. This should give the results as shown in @fig-fig12-3. [^13-comparing-several-means-one-way-anova-9] Note I have also checked the $\eta^2$ checkbox, pronounced "eta" squared, under the 'Effect Size' option and this is also shown on the results table. We will come back to effect sizes a bit later. --->

```{r}
#| label: fig-fig12-3
#| classes: .enlarge-image
#| fig-cap: jamovi的結果表格，用於根據施用的藥物進行情緒增益的 ANOVA。
#jamovi results table for ANOVA of mood gain by drug administered
knitr::include_graphics("images/fig13-3.png")
```

[^13-comparing-several-means-one-way-anova-9]: 與上文中的數字相比，jamovi 的結果更為準確，這是由於四捨五入誤差。

jamovi 的結果表格顯示了平方和值、自由度以及我們現在並不真正感興趣的其他一些數量。然而，請注意，jamovi 不使用「組間」和「組內」這兩個名稱。 相反，它嘗試分配更有意義的名稱。 在我們的特定示例中，組間方差對應於藥物對結果變項的影響，組內方差對應於“剩餘”的可變性，因此它將其稱為殘差。 如果我們將這些數字與 [A worked example] 中我手工計算的數字進行比較，可以看到它們或多或少是相同的，除了四捨五入誤差。組間平方和為 $SS_b = 3.45$，組內平方和為 $SS_w = 1.39$，各自的自由度為 $2$ 和 $15$。我們還得到了 F 值和 p 值，同樣，這些數字與我們在手工計算時的數字差不多相同，只是四捨五入誤差。

<!--- 
[^13-comparing-several-means-one-way-anova-9]: The jamovi results are more accurate than the ones in the text above, due to rounding errors.

The jamovi results table shows you the sums of squares values, the degrees of freedom, and a couple of other quantities that we're not really interested in right now. Notice, however, that jamovi doesn't use the names "between-group" and "within-group". Instead, it tries to assign more meaningful names. In our particular example, the between groups variance corresponds to the effect that the drug has on the outcome variable, and the within groups variance corresponds to the "leftover" variability so it calls that the residuals. If we compare these numbers to the numbers that I calculated by hand in [A worked example], you can see that they're more or less the same, apart from rounding errors. The between groups sums of squares is $SS_b = 3.45$, the within groups sums of squares is $SS_w = 1.39$, and the degrees of freedom are $2$ and $15$ respectively. We also get the F-value and the p-value and, again, these are more or less the same, give or take rounding errors, to the numbers that we calculated ourselves when doing it the long and tedious way. --->

## 效果量

有幾種不同的方法可以衡量 ANOVA 中的效應大小，但最常用的衡量指標是 $\eta^2$（eta 平方）和偏 $\eta^2$。對於單因素變異數分析，它們彼此相同，所以目前我只解釋 $\eta^2$。$\eta^2$ 的定義實際上非常簡單：

$$\eta^2=\frac{SS_b}{SS_{tot}}$$

就是這樣。所以當我查看 @fig-fig12-3 中的 ANOVA 表時，我看到 $SS_b = 3.45$ 和 $SS_tot = 3.45 + 1.39 = 4.84$。因此，我們得到一個 $\eta^2$ 值：

$$\eta^2=\frac{3.45}{4.84}=0.71$$

$\eta^2$ 的解釋同樣直接。它表示可以根據預測變項（藥物）解釋的結果變項（mood.gain）可變性的比例。$\eta^2=0$ 表示兩者之間完全沒有關係，而 $\eta^2=1$ 表示關係是完美的。更好的是，$\eta^2$ 值與 @sec-The-R2-value 中討論的 $R^2$ 關係非常密切，並具有等效的解釋。儘管許多統計教科書建議在 ANOVA 中使用 $\eta^2$ 作為默認的效應大小衡量指標，但 Daniel Lakens 的一篇有趣的<a href="https://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html" target="_blank">博客文章</a>表明，eta 平方在實際數據分析中可能不是最好的效應大小衡量指標，因為它可能是一個有偏估計量。有用的是，jamovi 中還有一個選項可以指定 ω 平方（$\omega^2$），它與 η 平方相比偏差較小。

<!--- There's a few different ways you could measure the effect size in an ANOVA, but the most commonly used measures are $\eta^2$ (eta squared) and partial $\eta^2$. For a one way analysis of variance they're identical to each other, so for the moment I'll just explain $\eta^2$ . The definition of $\eta^2$ is actually really simple

$$\eta^2=\frac{SS_b}{SS_{tot}}$$

That's all it is. So when I look at the ANOVA table in @fig-fig12-3, I see that $SS_b = 3.45$ and $SS_tot = 3.45 + 1.39 = 4.84$. Thus we get an $\eta^2$ value of

$$\eta^2=\frac{3.45}{4.84}=0.71$$

The interpretation of $\eta^2$ is equally straightforward. It refers to the proportion of the variability in the outcome variable (mood.gain) that can be explained in terms of the predictor (drug). A value of $\eta^2=0$ means that there is no relationship at all between the two, whereas a value of $\eta^2=1$ means that the relationship is perfect. Better yet, the $\eta^2$ value is very closely related to $R^2$, as discussed previously in @sec-The-R2-value, and has an equivalent interpretation. Although many statistics text books suggest $\eta^2$ as the default effect size measure in ANOVA, there's an interesting <a href="https://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html" target="_blank">blog post</a> by Daniel Lakens suggesting that eta-squared is perhaps not the best measure of effect size in real world data analysis, because it can be a biased estimator. Usefully, there is also an option in jamovi to specify omega-squared ($\omega^2$), which is less biased, alongside eta-squared. --->

## 多重比較與事後檢定

每當您對多於兩個組進行 ANOVA，並得到顯著效應時，您可能首先想問的是哪些組之間實際上存在差異。在我們的藥物示例中，我們的零假設是所有三種藥物（安慰劑、Anxifree 和 Joyzepam）對情緒的影響完全相同。但是如果你仔細想一想，實際上零假設一次聲稱了三個不同的事情。具體來說，它聲稱：

- 您的競爭對手的藥物（Anxifree）並不比安慰劑更好（即，$\mu_A = \mu_P$ ）
- 您的藥物（Joyzepam）並不比安慰劑更好（即，$\mu_J = \mu_P$ ）
- Anxifree 和 Joyzepam 同樣有效（即，$\mu_J = \mu_A$）

如果上述三個聲稱中的任何一個是偽的，那麼零假設也是偽的。因此，現在我們已經拒絕了我們的零假設，我們認為至少有一件事是不正確的。但哪些呢？所有三個命題都很有趣。既然您肯定想知道您的新藥 Joyzepam 是否比安慰劑更好，那麼了解它與現有商業替代品（即 Anxifree）的比較如何就變得很重要了。甚至有用的是檢查 Anxifree 與安慰劑的表現。即使 Anxifree 已經被其他研究人員廣泛地與安慰劑進行了對照測試，但檢查您的研究是否產生了與早期工作相似的結果仍然非常有用。

當我們根據這三個不同的命題來描述零假設時，我們需要區分的八種可能的“世界狀態”變得清晰了（ @tbl-tab12-9 ）。



<!---
Any time you run an ANOVA with more than two groups and you end up with a significant effect, the first thing you'll probably want to ask is which groups are actually different from one another. In our drugs example, our null hypothesis was that all three drugs (placebo, Anxifree and Joyzepam) have the exact same effect on mood. But if you think about it, the null hypothesis is actually claiming three different things all at once here. Specifically, it claims that:

- Your competitor's drug (Anxifree) is no better than a placebo (i.e., $\mu_A = \mu_P$ )
- Your drug (Joyzepam) is no better than a placebo (i.e., $\mu_J = \mu_P$ )
- Anxifree and Joyzepam are equally effective (i.e., $\mu_J = \mu_A$)

If any one of those three claims is false, then the null hypothesis is also false. So, now that we've rejected our null hypothesis, we're thinking that at least one of those things isn't true. But which ones? All three of these propositions are of interest. Since you certainly want to know if your new drug Joyzepam is better than a placebo, it would be nice to know how well it stacks up against an existing commercial alternative (i.e., Anxifree). It would even be useful to check the performance of Anxifree against the placebo. Even if Anxifree has already been extensively tested against placebos by other researchers, it can still be very useful to check that your study is producing similar results to earlier work.

When we characterise the null hypothesis in terms of these three distinct propositions, it becomes clear that there are eight possible "states of the world" that we need to distinguish between (@tbl-tab12-9). --->

```{r}
#| label: tbl-tab12-9
#| tbl-cap: 虛無假設與八種可能的"現實世界"
#The null hypothesis and eight possible 'states of the world'
huxtabs[[13]][[9]]
```

通過拒絕零假設，我們已經決定我們不相信 #1 是真實的世界狀態。下一個問題是，我們認為其他七個可能性中的哪一個*是對的？面對這種情況，通常最好先看看數據。例如，如果我們查看 @fig-fig12-1 中的繪圖，我們很容易得出 Joyzepam 優於安慰劑和 Anxifree，但 Anxifree 和安慰劑之間沒有實際差別的結論。然而，如果我們想對此得到更清晰的答案，則可能需要進行一些測試。

<!--- By rejecting the null hypothesis, we've decided that we don't believe that #1 is the true state of the world. The next question to ask is, which of the other seven possibilities *do* we think is right? When faced with this situation, its usually helps to look at the data. For instance, if we look at the plots in @fig-fig12-1, it's tempting to conclude that Joyzepam is better than the placebo and better than Anxifree, but there's no real difference between Anxifree and the placebo. However, if we want to get a clearer answer about this, it might help to run some tests. --->

### 成對t檢定

我們如何解決問題？考慮到我們需要比較三對不同的平均值（安慰劑對 Anxifree，安慰劑對 Joyzepam，和 Anxifree 對 Joyzepam），我們可以執行三個單獨的 t 檢驗，看看會發生什麼。在 jamovi 中這很容易做到。轉到 ANOVA 的 'Post Hoc Tests'（事後檢驗）選項，將 'drug'（藥物）變項移到右側的活動框中，然後單擊 'No correction'（無校正）複選框。這將產生一個整齊的表格，顯示藥物變項的三個水平之間的所有成對 t 檢驗比較，如 @fig-fig12-4 中所示。


<!--- 
How might we go about solving our problem? Given that we've got three separate pairs of means (placebo versus Anxifree, placebo versus Joyzepam, and Anxifree versus Joyzepam) to compare, what we could do is run three separate t-tests and see what happens. This is easy to do in jamovi. Go to the ANOVA 'Post Hoc Tests' options, move the 'drug' variable across into the active box on the right, and then click on the 'No correction' checkbox. This will produce a neat table showing all the pairwise t-test comparisons amongst the three levels of the drug variable, as in @fig-fig12-4 --->

```{r}
#| label: fig-fig12-4
#| classes: .enlarge-image
#| fig-cap: 未經校正的成對 t 檢驗作為 jamovi 中的事後比較。
#Uncorrected pairwise t-tests as post hoc comparisons in jamovi
knitr::include_graphics("images/fig13-4.png")
```

### 多重檢定的校正

在上一節中，我暗示了執行大量 t 檢驗存在問題。我們擔心的是，在執行這些分析時，我們正在進行一個「捕魚之旅」。我們在沒有太多理論指導的情況下執行了大量測試，希望其中一些測試顯示出顯著性。這種對團體差異的無理論基礎的搜索被稱為**事後分析**（"post hoc" 是拉丁語，意為 "after this"）。[^13-comparing-several-means-one-way-anova-10]

[^13-comparing-several-means-one-way-anova-10]：如果您*確實*有一些理論基礎，希望研究某些比較而不是其他比較，那就是另一回事了。在這種情況下，您實際上並不是在執行「事後分析」，而是在進行「預先計劃的比較」。我確實在本書後面談到了這種情況- @sec-The-method-of-planned-comparisons ，但現在我想保持簡單。

進行事後分析是可以的，但需要非常小心。例如，在上一節中進行的分析應該避免，因為每個單獨的 t 檢驗都設計為 5% 的第一型錯誤率（即 $\alpha = .05$），而我執行了其中的三個檢驗。想象一下，如果我的 ANOVA 涉及 10 個不同的組，我決定執行 45 個「事後」t 檢驗，試圖找出哪些組之間存在顯著差異，那麼僅憑機會就會出現 2 到 3 個顯著結果。正如我們在 @sec-Hypothesis-testing 中看到的那樣，虛無假設檢驗背後的核心組織原則是控制我們的第一型錯誤率，但是現在，由於我同時執行了大量 t 檢驗以確定 ANOVA 結果的來源，整個試驗家族的實際第一型錯誤率已經完全失控。

解決這個問題的常用方法是對 p 值進行調整，目的是控制整個試驗家族的總誤差率（參見 @Shaffer1995）。這種調整通常（但不總是）應用於事後分析，通常被稱為**多重比較校正**，儘管有時也被稱為「同時推斷」。無論如何，進行這種調整的方法有很多。我將在本節和下一章節 @sec-Post-hoc-tests 中討論其中的一些方法，但您應該意識到還有很多其他方法（例如，參見 @Hsu1996 ）。

<!---
In the previous section I hinted that there's a problem with just running lots and lots of t-tests. The concern is that, when running these analyses, what we're doing is going on a "fishing expedition". We're running lots and lots of tests without much theoretical guidance in the hope that some of them come up significant. This kind of theory-free search for group differences is referred to as **post hoc analysis** ("post hoc" being Latin for "after this").[^13-comparing-several-means-one-way-anova-10]

[^13-comparing-several-means-one-way-anova-10]: If you *do* have some theoretical basis for wanting to investigate some comparisons but not others, it's a different story. In those circumstances you're not really running "post hoc" analyses at all, you're making "planned comparisons". I do talk about this situation later in the book - @sec-The-method-of-planned-comparisons, but for now I want to keep things simple.

It's okay to run post hoc analyses, but a lot of care is required. For instance, the analysis that I ran in the previous section should be avoided, as each individual t-test is designed to have a 5% Type I error rate (i.e., $\alpha = .05$) and I ran three of these tests. Imagine what would have happened if my ANOVA involved 10 different groups, and I had decided to run 45 "post hoc" t-tests to try to find out which ones were significantly different from each other, you'd expect 2 or 3 of them to come up significant by chance alone. As we saw in @sec-Hypothesis-testing, the central organising principle behind null hypothesis testing is that we seek to control our Type I error rate, but now that I'm running lots of t-tests at once in order to determine the source of my ANOVA results, my actual Type I error rate across this whole family of tests has gotten completely out of control.

The usual solution to this problem is to introduce an adjustment to the p-value, which aims to control the total error rate across the family of tests (see @Shaffer1995). An adjustment of this form, which is usually (but not always) applied because one is doing post hoc analysis, is often referred to as a **correction for multiple comparisons**, though it is sometimes referred to as "simultaneous inference". In any case, there are quite a few different ways of doing this adjustment. I'll discuss a few of them in this section and in @sec-Post-hoc-tests in the next chapter, but you should be aware that there are many other methods out there (see, e.g., @Hsu1996). --->

### Bonferroni校正

這些調整中最簡單的一種被稱為**邦弗隆尼校正**[@Dunn1961]，它確實非常簡單。假設我的事後分析包括 m 個單獨的檢驗，我希望確保出現*任何*第一型錯誤的總概率最多為 $\alpha$。[^13-comparing-several-means-one-way-anova-11] 如果是這樣，那麼邦弗隆尼校正只是說「將所有原始 p 值乘以 m」。如果讓 $p$ 表示原始 p 值，讓 $p_j^{'}$ 表示經過校正的值，那麼邦弗隆尼校正告訴我們：

[^13-comparing-several-means-one-way-anova-11]：順便值得一提的是，並非所有調整方法都試圖這樣做。我在這裡描述的是一種用於控制「家族式第一型錯誤率」的方法。然而，還有其他事後檢驗試圖控制「偽發現率」，這是一個有點不同的概念。

$$p_j^{'}=m \times p$$

因此，如果您使用邦弗隆尼校正，則在 $p_j^{'} < \alpha$ 的情況下拒絕零假設。這種校正背後的邏輯非常簡單。我們正在進行 m 個不同的檢驗，因此，如果我們安排使每個檢驗的第一型錯誤率至多為 $\frac{\alpha}{m}$，那麼這些檢驗的*總*第一型錯誤率不能大於 $\alpha$。這很簡單，簡單到在原始論文中，作者寫道：

>在這裡給出的方法如此簡單，而且如此通用，我確信它肯定已經被使用過了。然而，我沒有找到它，所以只能得出一個結論：也許正是它的極簡單讓統計學家意識不到它在某些情況下是一個非常好的方法（@Dunn1961，第52-53頁）。

要在 jamovi 中使用邦弗隆尼校正，只需單擊「校正」選項中的「邦弗隆尼」復選框，您將在 ANOVA 結果表中看到另一列，顯示邦弗隆尼校正的調整後 p 值（ @tbl-tab12-8 ）。如果我們將這三個 p 值與未校正的成對 t 檢驗的 p 值進行比較，很明顯 jamovi 所做的唯一事情就是將它們乘以 $3$。

<!---

The simplest of these adjustments is called the **Bonferroni correction** [@Dunn1961], and it's very very simple indeed. Suppose that my post hoc analysis consists of m separate tests, and I want to ensure that the total probability of making *any* Type I errors at all is at most $\alpha$.[^13-comparing-several-means-one-way-anova-11] If so, then the Bonferroni correction just says "multiply all your raw p-values by m". If we let $p$ denote the original p-value, and let $p_j^{'}$ be the corrected value, then the Bonferroni correction tells that:

[^13-comparing-several-means-one-way-anova-11]: It's worth noting in passing that not all adjustment methods try to do this. What I've described here is an approach for controlling "family wise Type I error rate". However, there are other post hoc tests that seek to control the "false discovery rate", which is a somewhat different thing.

$$p_j^{'}=m \times p$$

And therefore, if you're using the Bonferroni correction, you would reject the null hypothesis if $p_j^{'} < \alpha$. The logic behind this correction is very straightforward. We're doing m different tests, so if we arrange it so that each test has a Type I error rate of at most $\frac{\alpha}{m}$, then the *total* Type I error rate across these tests cannot be larger than $\alpha$. That's pretty simple, so much so that in the original paper, the author writes:

>The method given here is so simple and so general that I am sure it must have been used before this. I do not find it, however, so can only conclude that perhaps its very simplicity has kept statisticians from realizing that it is a very good method in some situations (@Dunn1961, pp 52-53).

To use the Bonferroni correction in jamovi, just click on the 'Bonferroni' checkbox in the 'Correction' options, and you will see another column added to the ANOVA results table showing the adjusted p-values for the Bonferroni correction (@tbl-tab12-8). If we compare these three p-values to those for the uncorrected, pairwise t-tests, it is clear that the only thing that jamovi has done is multiply them by $3$.

--->

### Holm校正

雖然邦弗隆尼校正是最簡單的調整方法，但它通常不是最好的選擇。經常使用的另一種方法是**霍爾姆校正**（Holm correction）[@Holm1979]。霍爾姆校正背後的思路是假設您正在按順序進行測試，從最小（原始）的 p 值開始，然後移動到最大的 p 值。對於第 j 大的 p 值，調整是*以下兩者之一*

$$p_j^{'}=j \times p_j$$

（即最大的 p 值保持不變，第二大的 p 值翻倍，第三大的 p 值翻三倍，依此類推），或者

$$p_j^{'}=p_{j+1}^{'}$$

其中較<u>大</u>者。這可能聽起來有點困惑，所以讓我們慢慢解釋。霍爾姆校正的工作原理如下。首先，您按順序對所有 p 值進行排序，從最小到最大。對於最小的 p 值，您只需將其乘以 $m$，然後就完成了。然而，對於其他所有的 p 值，這是一個兩階段的過程。例如，當您移動到第二小的 p 值時，首先將其乘以 $m - 1$。如果這產生的數字大於您上次得到的調整後的 p 值，那麼保留它。但如果它比上一個小，那麼您將複製上一個 p 值。為了說明這是如何工作的，請考慮 @tbl-tab12-10 ，該表顯示了五個 p 值的霍爾姆校正計算。

<!---
Although the Bonferroni correction is the simplest adjustment out there, it's not usually the best one to use. One method that is often used instead is the **Holm correction** [@Holm1979]. The idea behind the Holm correction is to pretend that you're doing the tests sequentially, starting with the smallest (raw) p-value and moving onto the largest one. For the j-th largest of the p-values, the adjustment is *either*

$$p_j^{'}=j \times p_j$$

(i.e., the biggest p-value remains unchanged, the second biggest p-value is doubled, the third biggest p-value is tripled, and so on), or

$$p_j^{'}=p_{j+1}^{'}$$

whichever one is <u>larger</u>. This might sound a little confusing, so let's go through it a little more slowly. Here's what the Holm correction does. First, you sort all of your p-values in order, from smallest to largest. For the smallest p-value all you do is multiply it by $m$, and you're done. However, for all the other ones it's a two-stage process. For instance, when you move to the second smallest p value, you first multiply it by $m - 1$. If this produces a number that is bigger than the adjusted p-value that you got last time, then you keep it. But if it's smaller than the last one, then you copy the last p-value. To illustrate how this works, consider @tbl-tab12-10 which shows the calculations of a Holm correction for a collection of five p-values. --->

```{r}
#| label: tbl-tab12-10
#| tbl-cap: 經過霍爾姆校正計算的p值
#Holm corrected p values
huxtabs[[13]][[10]]
```

希望這能讓事情變得清晰。

雖然計算起來稍微困難一些，但霍爾姆校正具有一些非常好的特性。它比邦弗隆尼更具威力（即具有更低的 Type II 錯誤率），但是，儘管可能令人反直覺，它具有相同的 Type I 錯誤率。因此，在實踐中，沒有理由使用更簡單的邦弗隆尼校正，因為它總是被稍微複雜一點的霍爾姆校正所超越。正因為如此，霍爾姆校正應該是您的*首選*多重比較校正。 @fig-fig12-4 還顯示了霍爾姆校正後的 p 值，如您所見，最大的 p 值（對應於 Anxifree 和安慰劑之間的比較）沒有改變。它的值為 .15，與我們最初在完全不做校正時得到的值完全相同。相比之下，最小的 p 值（Joyzepam 與安慰劑）已乘以三。

<!---
Hopefully that makes things clear.

Although it's a little harder to calculate, the Holm correction has some very nice properties. It's more powerful than Bonferroni (i.e., it has a lower Type II error rate) but, counter-intuitive as it might seem, it has the same Type I error rate. As a consequence, in practice there's never any reason to use the simpler Bonferroni correction since it is always outperformed by the slightly more elaborate Holm correction. Because of this, the Holm correction should be your *go to* multiple comparison correction. @fig-fig12-4 also shows the Holm corrected p-values and, as you can see, the biggest p-value (corresponding to the comparison between Anxifree and the placebo) is unaltered. At a value of .15, it is exactly the same as the value we got originally when we applied no correction at all. In contrast, the smallest p-value (Joyzepam versus placebo) has been multiplied by three.

--->

### 事後檢定的報告格式

最後，在執行事後分析以確定哪些組別之間的差異顯著之後，您可以這樣寫出結果：

> *事後檢驗（使用霍爾姆校正來調整 p 值）表明，與 Anxifree（p = .001）和安慰劑（$（p = 9.0 \times{10^{-5}}$）相比，Joyzepam 產生了顯著更大的心情變化。我們沒有發現 Anxifree 表現優於安慰劑的證據（$p = .15$）。*

或者，如果您不喜歡報告精確的 p 值，那麼分別將這些數字更改為 $p < .01$、$p < .001$ 和 $p > .05$。無論哪種方式，關鍵是要表明您使用了霍爾姆的校正來調整 p 值。當然，我假設在撰寫的其他部分，您已經包括了相關的描述性統計資料（即組平均值和標準差），因為這些 p 值本身並不是很有信息量。

<!---
Finally, having run the post hoc analysis to determine which groups are significantly different to one another, you might write up the result like this:

> *Post hoc tests (using the Holm correction to adjust p) indicated that Joyzepam produced a significantly larger mood change than both Anxifree (p = .001) and the placebo ($(p = 9.0 \times{10^{-5}}$). We found no evidence that Anxifree performed better than the placebo ($p = .15$).*

Or, if you don't like the idea of reporting exact p-values, then you'd change those numbers to $p < .01$, $p < .001$ and $p > .05$ respectively. Either way, the key thing is that you indicate that you used Holm's correction to adjust the p-values. And of course, I'm assuming that elsewhere in the write up you've included the relevant descriptive statistics (i.e., the group means and standard deviations), since these p-values on their own aren't terribly informative. --->

## 單因子變異數分析的適用條件

像任何統計檢驗一樣，變異數分析依賴於關於數據（特別是殘差）的一些假設。您需要了解三個關鍵假設：正態性、方差同質性和獨立性。

[額外的技術細節 [^13-comparing-several-means-one-way-anova-12]]

[^13-comparing-several-means-one-way-anova-12]：如果您記得回到[一個實例]，我希望您至少瀏覽了一遍，即使您沒有讀完整篇文章，我以這種方式描述了支撐ANOVA的統計模型：$$H_0:Y_{ik}=\mu + \epsilon_{ik}$$ $$H_1:Y_{ik}=\mu_k + \epsilon_{ik}$$在這些等式中，$\mu$指的是對所有組別都相同的單個總群體均值，µk是第k個組的群體均值。到目前為止，我們主要關心的是我們的數據是最好用單個總均值（零假設）來描述，還是用不同的特定組均值（替代假設）來描述。當然，這是有道理的，因為這實際上是重要的研究問題！然而，我們所有的檢驗過程都是在一個關於殘差 $\epsilon_{ik}$ 的具體假設下進行的，即：$$\epsilon_{ik} \sim Normal(0,\sigma^2)$$如果沒有這部分，所有的數學都不能正常工作。或者，確切地說，您仍然可以進行所有計算，最終得到一個F統計量，但是您無法保證這個F統計量實際上衡量了您認為它衡量的內容，因此您可能基於F檢驗得出的任何結論都可能是錯誤的。

那麼，我們如何檢查對殘差的假設是否準確呢？嗯，正如我上面所指出的，這個陳述中隱含了三個不同的主張，我們將分別考慮它們。

- **方差同質性**。注意到我們只有一個群體標準差的值（即，$\sigma$），而不是讓每個組都有它自己的值（即，$\sigma_k$）。這被稱為方差同質性（有時稱為等方差性）假設。ANOVA假定所有組的群體標準差相同。我們將在[檢查方差同質性假設]部分詳細論述這一點。
- **正態性**。假定殘差呈正態分布。正如我們在 @sec-Checking-the-normality-of-a-sample 中看到的，我們可以通過查看QQ圖（或運行Shapiro-Wilk檢驗）來評估這一點。我將在[檢查正態性假設]部分中更多地討論這個問題。
- **獨立性**。獨立性假設有點棘手。它基本上的意思是，了解一個殘差對於了解任何其他殘差都沒有幫助。所有的 $\epsilon_{ik}$ 值都被假定是在不考慮或與其他任何值無關的情況下生成的。對於這一點，沒有顯而易見或簡單的檢驗方法，但有些情況是明顯違反這一假設的。例如，如果您有一個重複測量設計，每個參與者在研究中出現在多個條件下，那麼獨立性就不成立了。在這種情況下，某些觀察之間存在特殊關係，即對應於同一個人的觀察！當這種情況發生時，您需要使用類似[重複測量單因子ANOVA]的方法。

<!---
Like any statistical test, analysis of variance relies on some assumptions about the data, specifically the residuals. There are three key assumptions that you need to be aware of: normality, homogeneity of variance and independence.

[Additional technical detail [^13-comparing-several-means-one-way-anova-12]]

[^13-comparing-several-means-one-way-anova-12]: If you remember back to [A worked example], which I hope you at least skimmed even if you didn't read the whole thing, I described the statistical models underpinning ANOVA in this way: $$H_0:Y_{ik}=\mu + \epsilon_{ik}$$ $$H_1:Y_{ik}=\mu_k + \epsilon_{ik}$$ In these equations $\mu$ refers to a single grand population mean which is the same for all groups, and µk is the population mean for the k-th group. Up to this point we've been mostly interested in whether our data are best described in terms of a single grand mean (the null hypothesis) or in terms of different group-specific means (the alternative hypothesis). This makes sense, of course, as that's actually the important research question! However, all of our testing procedures have, implicitly, relied on a specific assumption about the residuals, $\epsilon\_{ik}$, namely that $$\epsilon_{ik} \sim Normal(0,\sigma^2)$$ None of the maths works properly without this bit. Or, to be precise, you can still do all the calculations and you'll end up with an F-statistic, but you have no guarantee that this F-statistic actually measures what you think it's measuring, and so any conclusions that you might draw on the basis of the F test might be wrong.

So, how do we check whether the assumption about the residuals is accurate? Well, as I indicated above, there are three distinct claims buried in this one statement, and we'll consider them separately.

- **Homogeneity of variance**. Notice that we've only got the one value for the population standard deviation (i.e., $\sigma$), rather than allowing each group to have it's own value (i.e., $\sigma_k$). This is referred to as the homogeneity of variance (sometimes called homoscedasticity) assumption. ANOVA assumes that the population standard deviation is the same for all groups. We'll talk about this extensively in the [Checking the homogeneity of variance assumption] section.
- **Normality**. The residuals are assumed to be normally distributed. As we saw in @sec-Checking-the-normality-of-a-sample, we can assess this by looking at QQ plots (or running a Shapiro-Wilk test. I'll talk about this more in an ANOVA context in the [Checking the normality assumption] section.
- **Independence**. The independence assumption is a little trickier. What it basically means is that, knowing one residual tells you nothing about any other residual. All of the $\epsilon_{ik}$ values are assumed to have been generated without any "regard for" or "relationship to" any of the other ones. There's not an obvious or simple way to test for this, but there are some situations that are clear violations of this. For instance, if you have a repeated measures design, where each participant in your study appears in more than one condition, then independence doesn't hold. There's a special relationship between some observations, namely those that correspond to the same person! When that happens, you need to use something like a [Repeated measures one-way ANOVA].

--->

### 同質性檢核 {#sec-Checking-the-homogeneity-of-variance-assumption}

> *要進行方差的初步檢驗，就像乘坐划艇出海，看看海面條件是否足夠平靜，讓一艘大型遊輪離港！* \
> -- 喬治·博克斯 [@Box1953]

俗話說，殺貓有很多方法，檢驗方差同質性假設也有很多方法（不過出於某種原因，沒有人把它變成一句俗話）。在文獻中，我見過的最常用的檢驗方法是Levene檢驗[@Levene1960]，以及與之密切相關的Brown-Forsythe檢驗[@BrownForsythe1974]。

無論您是進行標準Levene檢驗還是Brown-Forsythe檢驗，檢驗統計量（有時表示為$F$，但也有時表示為$W$），都是按照計算常規ANOVA中的F-統計量的方式，只是使用$Z_{ik}$而不是$Y_{ik}$。有了這個思路，我們可以繼續看看如何在jamovi中運行檢驗。

[額外的技術細節[^13-comparing-several-means-one-way-anova-13]]

[^13-comparing-several-means-one-way-anova-13]：Levene檢驗非常簡單。假設我們有結果變項$Y_{ik}$。我們所要做的就是定義一個新變項，我將其稱為$Z_{ik}$，表示與組均值的絕對偏差：$$Z_{ik}=Y_{ik}-\bar{Y}_{k}$$好吧，這對我們有什麼好處呢？那麼，讓我們花一點時間來思考一下$Z_{ik}$到底是什麼以及我們要檢驗什麼。$Z_{ik}$的值是度量第$i$次觀測在第$k$個組中與其組平均值的偏差程度。我們的零假設是所有組的方差都相同，即所有組平均值的總偏差相同！因此，Levene檢驗中的零假設是所有組的$Z$的母體平均值相同。嗯。那麼我們現在需要的是一個統計檢驗來檢驗所有組均值相同的零假設。我們在哪裡見過這個檢驗？哦對了，這就是ANOVA，所以Levene檢驗所做的就是對新變項$Z_{ik}$進行ANOVA。Brown-Forsythe檢驗呢？它有做什麼特別不同的事情嗎？不，與Levene檢驗唯一的不同是它以稍微不同的方式構建轉換變項Z，使用組中位數的偏差而不是組平均值的偏差。也就是說，對於Brown-Forsythe檢驗：$$Z_{ik}=Y_{ik}-median_k(Y)$$其中，$median_k(Y)$是第k組的中位數。

<!---

> *To make the preliminary test on variances is rather like putting to sea in a rowing boat to find out whether conditions are sufficiently calm for an ocean liner to leave port!* \
> -- George Box [@Box1953]

There's more than one way to skin a cat, as the saying goes, and more than one way to test the homogeneity of variance assumption, too (though for some reason no-one made a saying out of that). The most commonly used test for this that I've seen in the literature is the Levene test [@Levene1960], and the closely related Brown-Forsythe test [@BrownForsythe1974].

Regardless of whether you're doing the standard Levene test or the Brown-Forsythe test, the test statistic, which is sometimes denoted $F$ but also sometimes written as $W$, is calculated in exactly the same way that the F-statistic for the regular ANOVA is calculated, just using a $Z_{ik}$ rather than $Y_{ik}$. With that in mind, we can go on to look at how to run the test in jamovi.

[Additional technical detail [^13-comparing-several-means-one-way-anova-13]]

[^13-comparing-several-means-one-way-anova-13]: The Levene test is shockingly simple. Suppose we have our outcome variable $Y_{ik}$. All we do is define a new variable, which I'll call $Z_{ik}$, corresponding to the absolute deviation from the group mean $$Z_{ik}=Y_{ik}-\bar{Y}_{k}$$ Okay, what good does this do us? Well, let's take a moment to think about what $Z_{ik}$ actually is and what we're trying to test. The value of $Z_{ik}$ is a measure of how the $i$-th observation in the $k$-th group deviates from its group mean. And our null hypothesis is that all groups have the same variance, i.e., the same overall deviations from the group means! So the null hypothesis in a Levene test is that the population means of $Z$ are identical for all groups. Hmm. So what we need now is a statistical test of the null hypothesis that all group means are identical. Where have we seen  that before? Oh right, that's what ANOVA is, and so all that the Levene test does is run an ANOVA on the new variable $Z_{ik}$. What about the Brown-Forsythe test? Does that do anything particularly different? Nope. The only change from the Levene test is that it constructs the transformed variable Z in a slightly different way, using deviations from the group medians rather than deviations from the group means. That is, for the Brown-Forsythe test: $$Z_{ik}=Y_{ik}-median_k(Y)$$ where $median_k(Y)$ is the median for group k.
--->

### jamovi的Levene檢定

好的，那麼我們該如何進行Levene檢驗呢？其實很簡單 - 在ANOVA的"假設檢查"選項下，只需點擊"變異數同質性檢驗"複選框。如果我們查看 @fig-fig12-5 中的輸出，我們可以看到檢驗結果並無顯著差異（$F_{2,15} = 1.45, p = .266$），所以變異數同質性假設看起來沒有問題。然而，外表可能會讓人受騙！如果您的樣本量相當大，那麼即使變異數同質性假設沒有被違反到影響ANOVA的穩健性，Levene檢驗也可能顯示出顯著效應（即p < .05）。這正是George Box在上面引述中所指出的觀點。同樣地，如果您的樣本量相當小，那麼變異數同質性假設可能不被滿足，而Levene檢驗可能不顯著（即p > .05）。這意味著，在對假設是否被滿足進行任何統計檢驗的同時，您應該總是繪製每個分組/類別的均值周圍的標準差......只是為了看看它們是否看起來相當相似（即變異數同質性）或不相似。



<!---
Okay, so how do we run the Levene test? Simple really - under the ANOVA 'Assumption Checks' option, just click on the 'Homogeneity tests' checkbox. If we look at the output, shown in @fig-fig12-5, we see that the test is non-significant ($F_{2,15} = 1.45, p = .266$), so it looks like the homogeneity of variance assumption is fine. However, looks can be deceptive! If your sample size is pretty big, then the Levene test could show up a significant effect (i.e. p < .05) even when the homogeneity of variance assumption is not violated to an extent which troubles the robustness of ANOVA. This was the point George Box was making in the quote above. Similarly, if your sample size is quite small, then the homogeneity of variance assumption might not be satisfied and yet a Levene test could be non-significant (i.e. p > .05). What this means is that, alongside any statistical test of the assumption being met, you should always plot the standard deviation around the means for each group / category in the analysis...just to see if they look fairly similar (i.e. homogeneity of variance) or not. --->

```{r}
#| label: fig-fig12-5
#| fig-cap: jamovi中單因素ANOVA的Levene檢驗輸出
#Levene test output for one-way ANOVA in jamovi
knitr::include_graphics("images/fig13-5.png")
```

### 校正異質性的分析結果

在我們的示例中，變異數同質性假設被證明是相當可靠的：Levene檢驗結果並無顯著差異（儘管我們還應該查看標準差的圖形），因此我們可能不需要擔心。然而，在現實生活中，我們並非總是如此幸運。當變異數同質性假設被違反時，我們該如何拯救我們的ANOVA呢？如果您回想一下我們對t檢驗的討論，我們之前遇到過這個問題。Student t檢驗假設等方差，所以解決方法是使用不需要等方差假設的Welch t檢驗。實際上， @Welch1951 還展示了我們如何解決ANOVA的這個問題（**Welch單因素檢驗**）。它在jamovi中使用One-Way ANOVA分析實現。這是一種專為單因素ANOVA設計的分析方法，要在我們的示例中執行Welch單因素ANOVA，我們將按照之前的方式重新運行分析，但這次使用jamovi的ANOVA - One Way ANOVA分析命令，並選擇Welch檢驗的選項（參見 @fig-fig12-6 ）。為了理解這裡發生了什麼，讓我們將這些數字與我們在[最初在jamovi中運行ANOVA]時得到的數字進行比較。為了省去您回顧的麻煩，上次我們得到的是：$F(2, 15) = 18.611, p = .00009$，這也顯示為 @fig-fig12-6 中One-Way ANOVA的Fisher檢驗。

<!---

In our example, the homogeneity of variance assumption turned out to be a pretty safe one: the Levene test came back non-significant (notwithstanding that we should also look at the plot of standard deviations), so we probably don't need to worry. However, in real life we aren't always that lucky. How do we save our ANOVA when the homogeneity of variance assumption is violated? If you recall from our discussion of t-tests, we've seen this problem before. The Student t-test assumes equal variances, so the solution was to use the Welch t-test, which does not. In fact, @Welch1951 also showed how we can solve this problem for ANOVA too (the **Welch one-way test**). It's implemented in jamovi using the One-Way ANOVA analysis. This is a specific analysis approach just for one-way ANOVA, and to run the Welch one-way ANOVA for our example, we would re-run the analysis as previously, but this time use the jamovi ANOVA - One Way ANOVA analysis command, and check the option for Welch's test (see @fig-fig12-6). To understand what's happening here, let's compare these numbers to what we got earlier when [Running an ANOVA in jamovi] originally. To save you the trouble of flicking back, this is what we got last time: $F(2, 15) = 18.611, p = .00009$, also shown as the Fisher's test in the One-Way ANOVA shown in @fig-fig12-6.

--->

```{r}
#| label: fig-fig12-6
#| classes: .enlarge-image
#| fig-cap: Welch檢驗作為jamovi中One Way ANOVA分析的一部分
#Welch's test as part of the One Way ANOVA analysis in jamovi
knitr::include_graphics("images/fig13-6.png")
```



好的，最初我們的ANOVA結果是$F(2, 15) = 18.6$，而Welch單因素檢驗給出的是$F(2, 9.49) = 26.32$。換句話說，Welch檢驗將組內自由度從15降低到了9.49，而F值從18.6上升到了26.32。

<!---Okay, so originally our ANOVA gave us the result $F(2, 15) = 18.6$, whereas the Welch one way test gave us $F(2, 9.49) = 26.32$. In other words, the Welch test has reduced the within-groups degrees of freedom from 15 to 9.49, and the F-value has increased from 18.6 to 26.32. --->

### 常態性檢核 {#sec-Checking-the-normality-assumption}

檢驗正態性假設相對簡單。我們在 @sec-Checking-the-normality-of-a-sample 中介紹了大部分你需要了解的內容。我們真正需要做的只是繪製一個QQ圖，並在可行的情況下，運行Shapiro-Wilk檢驗。QQ圖顯示在 @fig-fig12-7 ，對我來說看起來相當正常。如果Shapiro-Wilk檢驗不顯著（即$p > .05$），那麼這表明正態性假設沒有被違反。然而，與Levene檢驗一樣，如果樣本量很大，那麼顯著的Shapiro-Wilk檢驗實際上可能是偽陽性，也就是說，正態性假設在實質上沒有對分析造成任何問題。同樣地，非常小的樣本量可能會產生偽陰性。這就是為什麼視覺檢查QQ圖很重要。




<!--- Testing the normality assumption is relatively straightforward. We covered most of what you need to know in @sec-Checking-the-normality-of-a-sample. The only thing we really need to do is draw a QQ plot and, in addition if it is available, run the Shapiro-Wilk test. The QQ plot is shown in @fig-fig12-7 and it looks pretty normal to me. If the Shapiro-Wilk test is not significant (i.e. $p > .05$) then this indicates that the assumption of normality is not violated. However, as with Levene's test, if the sample size is large then a significant Shapiro-Wilk test may in fact be a false positive, where the assumption of normality is not violated in any substantive problematic sense for the analysis. And, similarly, a very small sample can produce false negatives. That's why a visual inspection of the QQ plot is important. --->

```{r}
#| label: fig-fig12-7
#| fig-cap: jamovi中One Way ANOVA分析的QQ圖
#QQ plot in the One Way ANOVA analysis in jamovi
knitr::include_graphics("images/fig13-7.png")
```

除了檢查QQ圖中是否有偏離正態性的情況外，我們的數據的Shapiro-Wilk檢驗確實顯示出非顯著效應，p = 0.6053（見 @fig-fig12-6 ）。因此，這支持了QQ圖的評估；兩個檢查都沒有發現正態性被違反的跡象。

<!--- Alongside inspecting the QQ plot for any deviations from normality, the Shapiro-Wilk test for our data does show a non-significant effect, with p = 0.6053 (see @fig-fig12-6. This therefore supports the QQ plot assessment; both checks find no indication that normality is violated. --->

### 排除非常態性的分析結果

現在我們已經了解了如何檢查正態性，我們自然會問可以採取哪些措施來解決正態性的違反。在單因素ANOVA的背景下，最簡單的解決方案可能是轉向非參數檢驗（即不依賴於任何特定的分佈假設的檢驗）。在 @sec-Comparing-two-means 中，我們之前已經介紹過非參數檢驗。當你只有兩個組別時，Mann-Whitney或Wilcoxon檢驗可以提供你所需的非參數替代方法。當你有三個或更多組別時，你可以使用**Kruskal-Wallis秩和檢驗**[@KruskalWallis1952]。接下來我們將講解這個檢驗。

<!--- Now that we've seen how to check for normality, we are led naturally to ask what we can do to address violations of normality. In the context of a one-way ANOVA, the easiest solution is probably to switch to a non-parametric test (i.e., one that doesn't rely on any particular assumption about the kind of distribution involved). We've seen non-parametric tests before, in @sec-Comparing-two-means. When you only have two groups, the Mann-Whitney or the Wilcoxon test provides the non-parametric alternative that you need. When you've got three or more groups, you can use the **Kruskal-Wallis rank sum test** [@KruskalWallis1952]. So that's the test we'll talk about next. --->

###  Kruskal-Wallis檢定的邏輯

Kruskal-Wallis檢驗在某些方面與ANOVA驚人地相似。在ANOVA中，我們從$Y_{ik}$開始，對於第k個組中的第i個人，這是結果變項的值。對於Kruskal-Wallis檢驗，我們要做的是對所有的$Y_{ik}$值進行排序，並對排名數據進行分析。[^13-comparing-several-means-one-way-anova-14]

[^13-comparing-several-means-one-way-anova-14]: 那麼，讓R\_{ik}表示給第k個組的第i個成員的排名。現在，讓我們計算$\bar{R}_k$，即第k個組觀察值的平均排名： $$\bar{R}_k=\frac{1}{N_k}\sum_i R_{ik}$$，讓我們也計算$\bar{R}$，即總平均排名：$$\bar{R}=\frac{1}{N}\sum_i\sum_k R_{ik}$$ 現在我們已經做了這些，我們可以計算與總平均排名$\bar{R}$的平方偏差。當我們對個別分數進行這種計算時，即如果我們計算$(R_{ik} - \bar{R})^2$，那麼我們得到的是一個“非參數”的度量，用於表示第ik個觀察值與總平均排名的偏差程度。當我們計算組均值與總均值的平方偏差時，即如果我們計算$(R_{ik} - \bar{R})^2$，那麼我們得到的是一個非參數度量，用於表示該組與總平均排名的偏差程度。考慮到這一點，我們將遵循與ANOVA相同的邏輯，並定義我們的排名平方和度量，就像我們之前所做的那樣。首先，我們有我們的“總排名平方和”$$RSS_{tot}=\sum_k\sum_i (R_{ik}-\bar{R})^2$$，我們可以像這樣定義“組間排名平方和” $$\begin{aligned} RSS_{b}& =\sum{k}\sum_{i}(\bar{R}_{k}-\bar{R})^2 \\ &= \sum_{k} N_k (\bar{R}_{k}-\bar{R})^2 \end{aligned}$$ 因此，如果虛無假設成立，且根本沒有真正的組差異，則您會期望組間排名和$RSS_b$非常小，遠小於總排名和$RSS_{tot}$。從質量上看，這與我們在構建ANOVA F-統計量時發現的非常相似，但出於技術原因，Kruskal-Wallis檢驗統計量通常表示為K，其構建方式略有不同，$$K=(N-1) \times \frac{RSS_b}{RSS_{tot}}$$ 如果虛無假設成立，那麼K的抽樣分布近似為自由度為$G-1$的卡方分布（其中$G$為組的數量）。 K的值越大，數據與虛無假設的一致性就越小，因此這是一個單邊檢驗。當K足夠大時，我們拒絕$H_0$。

<!---
The Kruskal-Wallis test is surprisingly similar to ANOVA, in some ways. In ANOVA we started with $Y_{ik}$, the value of the outcome variable for the ith person in the kth group. For the Kruskal Wallis test what we'll do is rank order all of these $Y_{ik}$ values and conduct our analysis on the ranked data. [^13-comparing-several-means-one-way-anova-14]

[^13-comparing-several-means-one-way-anova-14]: So let's let R\_{ik} refer to the ranking given to the ith member of the kth group. Now, let's calculate $\bar{R}_k$, the average rank given to observations in the kth group $$\bar{R}_k=\frac{1}{N_k}\sum_i R_{ik}$$ and let's also calculate $\bar{R}$, the grand mean rank $$\bar{R}=\frac{1}{N}\sum_i\sum_k R_{ik}$$ Now that we've done this, we can calculate the squared deviations from the grand mean rank $\bar{R}$. When we do this for the individual scores, i.e., if we calculate $(R_{ik} - \bar{R})^2$ , what we have is a "nonparametric" measure of how far the ik-th observation deviates from the grand mean rank. When we calculate the squared deviation of the group means from the grand means, i.e., if we calculate $(R_{ik} - \bar{R})^2$, then what we have is a nonparametric measure of how much the group deviates from the grand mean rank. With this in mind, we'll follow the same logic that we did with ANOVA and define our ranked sums of squares measures, much like we did earlier. First, we have our "total ranked sums of squares" $$RSS_{tot}=\sum_k\sum_i (R_{ik}-\bar{R})^2$$ and we can define the "between groups ranked sums of squares" like this $$\begin{aligned} RSS_{b}& =\sum{k}\sum_{i}(\bar{R}_{k}-\bar{R})^2 \\ &= \sum_{k} N_k (\bar{R}_{k}-\bar{R})^2 \end{aligned}$$ So, if the null hypothesis is true and there are no true group differences at all, you'd expect the between group rank sums $RSS_b$ to be very small, much smaller than the total rank sums $RSS_{tot}$. Qualitatively this is very much the same as what we found when we went about constructing the ANOVA F-statistic, but for technical reasons the Kruskal-Wallis test statistic, usually denoted K, is constructed in a slightly different way, $$K=(N-1) \times \frac{RSS_b}{RSS_{tot}}$$ and if the null hypothesis is true, then the sampling distribution of K is approximately chi square with $G-1$ degrees of freedom (where $G$ is the number of groups). The larger the value of K, the less consistent the data are with the null hypothesis, so this is a one-sided test. We reject $H_0$ when K is sufficiently large.--->

### 更多分析細節

上一節的描述說明了Kruskal-Wallis檢驗背後的邏輯。從概念上講，這是考慮測試如何工作的正確方法。[^13-comparing-several-means-one-way-anova-15]

[^13-comparing-several-means-one-way-anova-15]：然而，從純粹的數學角度來看，這是不必要的複雜。我不會向您展示推導，但您可以使用一些代數技巧$^b$來顯示K的方程式可以是$$K=\frac{12}{N(N-1)}\sum_k N_k \bar{R}_k^2 -3(N+1)$$ 最後一個方程式有時給出了K的值。這比我在上一節中描述的版本要容易得多，但問題是對實際人類完全沒有意義。將K視為基於排名的ANOVA類比可能是最好的方式。但請記住，計算出來的檢驗統計量與我們最初用於ANOVA的統計量有很大不同。<br>---<br> $b$就是一些數學運算術語。

但等等，還有更多！天啊，為什麼總是有更多呢？到目前為止，我講的故事實際上只在原始數據中沒有相同數值的情況下才成立。也就是說，如果沒有兩個觀測值具有完全相同的值。如果有相同的值，那麼我們必須引入一個校正因子來進行這些計算。在這一點上，我假設即使是最勤奮的讀者也已經不再關心（或者至少形成了繫結校正因子不需要他們立即關注的看法）。因此，我將非常快速地告訴您如何計算它，並省略為什麼以這種方式進行的繁瑣細節。假設我們為原始數據構建一個頻率表，讓fj表示具有第j個唯一值的觀測值的數量。這聽起來可能有點抽象，因此我們將從*clinicaltrials.csv*數據集中的mood.gain頻率表（ @tbl-tab12-11 ）給出一個具體的例子。



<!--- The description in the previous section illustrates the logic behind the Kruskal-Wallis test. At a conceptual level, this is the right way to think about how the test works.[^13-comparing-several-means-one-way-anova-15]

[^13-comparing-several-means-one-way-anova-15]: However, from a purely mathematical perspective it's needlessly complicated. I won't show you the derivation, but you can use a bit of algebraic jiggery-pokery$^b$ to show that the equation for K can be $$K=\frac{12}{N(N-1)}\sum_k N_k \bar{R}_k^2 -3(N+1)$$ It's this last equation that you sometimes see given for K. This is way easier to calculate than the version I described in the previous section, but it's just that it's totally meaningless to actual humans. It's probably best to think of K the way I described it earlier, as an analogue of ANOVA based on ranks. But keep in mind that the test statistic that gets calculated ends up with a rather different look to it than the one we used for our original ANOVA. <br>---<br> $b$ A technical term

But wait, there's more! Dear lord, why is there always more? The story I've told so far is only actually true when there are no ties in the raw data. That is, if there are no two observations that have exactly the same value. If there are ties, then we have to introduce a correction factor to these calculations. At this point I'm assuming that even the most diligent reader has stopped caring (or at least formed the opinion that the tie-correction factor is something that doesn't require their immediate attention). So I'll very quickly tell you how it's calculated, and omit the tedious details about why it's done this way. Suppose we construct a frequency table for the raw data, and let fj be the number of observations that have the j-th unique value. This might sound a bit abstract, so here's a concrete example from the frequency table of mood.gain from the *clinicaltrials.csv* data set (@tbl-tab12-11) --->

```{r}
#| label: tbl-tab12-11
#| tbl-cap: 數據中*clinicaltrials.csv*心情增益的次數表
#Frequency table of mood gain from the *clinicaltrials.csv* data
huxtabs[[13]][[11]]
```

觀察此表，請注意頻率表中的第三個條目值為2。由於這對應於心情增益為0.3，因此此表告訴我們有兩個人的心情增加了0.3。[^13-comparing-several-means-one-way-anova-16]

[^13-comparing-several-means-one-way-anova-16]：更重要的是，在我上面介紹的數學表示法中，這告訴我們$f_3 = 2$。耶。那麼，現在我們知道了這一點，繫結校正因子（TCF）是：$$TCF=1-\frac{\sum_j f_j^3 - f_j}{N^3 - N}$$通過將K值除以這個數量，可以得到Kruskal-Wallis統計量的繫結校正值。這是jamovi計算的繫結校正版本。

因此，jamovi使用繫結校正因子來計算繫結校正的Kruskall-Wallis統計量。最後，我們實際上已經完成了Kruskal-Wallis檢驗的理論。我確信你們都對我治愈了你們在意識到你們不知道如何計算Kruskal-Wallis檢驗的繫結校正因子時自然產生的存在焦慮感到非常寬慰。對吧？

<!--- Looking at this table, notice that the third entry in the frequency table has a value of 2. Since this corresponds to a mood.gain of 0.3, this table is telling us that two people's mood increased by 0.3. [^13-comparing-several-means-one-way-anova-16]

[^13-comparing-several-means-one-way-anova-16]: More to the point, in the mathematical notation I introduced above, this is telling us that $f_3 = 2$. Yay. So, now that we know this, the tie correction factor (TCF) is: $$TCF=1-\frac{\sum_j f_j^3 - f_j}{N^3 - N}$$ The tie-corrected value of the Kruskal-Wallis statistic is obtained by dividing the value of K by this quantity. It is this tie-corrected version that jamovi calculates.

And so jamovi uses a tie-correction factor to calculate the tie-corrected Kruskall-Wallis statistic. And at long last, we're actually finished with the theory of the Kruskal-Wallis test. I'm sure you're all terribly relieved that I've cured you of the existential anxiety that naturally arises when you realise that you don't know how to calculate the tie-correction factor for the Kruskal-Wallis test. Right? --->

### 使用jamovi完成Kruskal-Wallis檢定

儘管我們在努力理解Kruskal Wallis檢驗實際上做了什麼方面經歷了恐懼，但事實證明，進行該檢驗相當無痛，因為jamovi在ANOVA分析集中有一個名為「非參數」-「單因子ANOVA（Kruskall-Wallis）」的分析。大多數時候，你將擁有像*clinicaltrial.csv*這樣的數據集，其中包含你的結果變項mood.gain和一個分組變項drug。如果是這樣，你可以直接在jamovi中運行分析。這給我們提供了一個Kruskal-Wallis $\chi^2 =12.076, df = 2, p = 0.00239$，如 @fig-fig12-8 所示。


<!--- Despite the horror that we've gone through in trying to understand what the Kruskal Wallis test actually does, it turns out that running the test is pretty painless, since jamovi has an analysis as part of the ANOVA analysis set called 'Non-Parametric' - 'One Way ANOVA (Kruskall-Wallis)' Most of the time you'll have data like the *clinicaltrial.csv*  data set, in which you have your outcome variable mood.gain and a grouping variable drug. If so, you can just go ahead and run the analysis in jamovi. What this gives us is a Kruskal-Wallis $\chi^2 =12.076, df = 2, p = 0.00239$, as in @fig-fig12-8 --->

```{r}
#| label: fig-fig12-8
#| classes: .enlarge-image
#| fig-cap: jamovi中的Kruskall-Wallis單因子非參數ANOVA
#Kruskall-Wallis one-way non-parametric ANOVA in jamovi
knitr::include_graphics("images/fig13-8.png")
```

## 單因子重覆量數變異數分析 {#sec-oneway-repeated-measure}

單因子重覆量數變數分析檢驗是一種統計方法，用於檢驗三個或更多組之間的顯著差異，其中每個組都使用相同的參與者（或者每個參與者與其他實驗組的參與者密切匹配）。因此，每個實驗組中應該始終具有相等數量的分數（數據點）。這種類型的設計和分析也可以稱為「相關ANOVA」或「內部主題ANOVA」。

重覆量數變數分析的邏輯與獨立ANOVA（有時稱為「間題」ANOVA）非常相似。您可能還記得，我們之前顯示在一個間題ANOVA總變異性可以分為組間變異性（$SS_b$）和組內變異性（$SS_w$），在將每個變異性除以相應的自由度後得到MSb和MSw（見表13.1），F比值計算為：

$$F=\frac{MS_b}{MS_w}$$

在重覆量數變數分析中，F比值的計算方式類似，但是在獨立ANOVA中，組內變異性（$SS_w$）被用作$MS_w$的分母，而在重覆量數變數分析中，$SS_w$被劃分為兩部分。由於我們在每個組中都使用相同的受試者，因此可以從組內變異性中移除受試者間個別差異（稱為SSsubjects）的變異性。我們不會深入討論這是如何實現的，但本質上，每個受試者都成為名為受試者的因子的一個水平。然後以與任何間題因子相同的方式計算此內部受試者因子中的變異性。然後我們可以將SSsubjects從$SS_w$中減去，以提供一個較小的SSerror項：

$$\text{獨立ANOVA: } SS_{error} = SS_w$$ $$\text{重覆量數變數分析: } SS_{error} = SS_w - SS_{subjects}$$
這個$SS_{error}$項的變化通常會導致統計檢驗更加強大，但這確實取決於$SS_{error}$的減少是否超過了誤差項自由度的減少（因為自由度從$(n - k)$[^13-comparing-several-means-one-way-anova-17]變為$(n - 1)(k - 1)$（請記住，獨立ANOVA設計中的受試者更多）。

[^13-comparing-several-means-one-way-anova-17]:（n-k）：（受試者數量-組別數量）

<!--- The one-way repeated measures ANOVA test is a statistical method of testing for significant differences between three or more groups where the same participants are used in each group (or each participant is closely matched with participants in other experimental groups). For this reason, there should always be an equal number of scores (data points) in each experimental group. This type of design and analysis can also be called a 'related ANOVA' or a 'within subjects ANOVA'.

The logic behind a repeated measures ANOVA is very similar to that of an independent ANOVA (sometimes called a 'between-subjects' ANOVA). You'll remember that earlier we showed that in a between-subjects ANOVA total variability is partitioned into between-groups variability ($SS_b$) and within-groups variability ($SS_w$), and after each is divided by the respective degrees of freedom to give MSb and MSw (see Table 13.1) the F-ratio is calculated as:

$$F=\frac{MS_b}{MS_w}$$ 

In a repeated measures ANOVA, the F-ratio is calculated in a similar way, but whereas in an independent ANOVA the within-group variability ($SS_w$) is used as the basis for the $MS_w$ denominator, in a repeated measures ANOVA the $SS_w$ is partioned into two parts. As we are using the same subjects in each group, we can remove the variability due to the individual differences between subjects (referred to as SSsubjects) from the within-groups variability. We won't go into too much technical detail about how this is done, but essentially each subject becomes a level of a factor called subjects. The variability in this within-subjects factor is then calculated in the same way as any between-subjects factor. And then we can subtract SSsubjects from $SS_w$ to provide a smaller SSerror term:

$$\text{Independent ANOVA: } SS_{error} = SS_w$$ $$\text{Repeated Measures ANOVA: } SS_{error} = SS_w - SS_{subjects}$$
This change in $SS_{error}$ term often leads to a more powerful statistical test, but this does depend on whether the reduction in the $SS_{error}$ more than compensates for the reduction in degrees of freedom for the error term (as degrees of freedom go from $(n - k)$ [^13-comparing-several-means-one-way-anova-17] to $(n - 1)(k - 1)$ (remembering that there are more subjects in the independent ANOVA design).

[^13-comparing-several-means-one-way-anova-17]: (n - k) : (number of subjects - number of groups) --->

### jamovi的重覆量數變異數分析

首先，我們需要一些數據。 @Geschwind1972 表示，患者在中風後語言缺陷的確切性質可以用來診斷已受損的大腦特定區域。一位研究人員關心的是確定六位患有Broca失語症（中風後常見的語言缺陷）的患者所經歷的具體交流困難（ @tbl-tab12-12 ）。



<!--- First, we need some data. @Geschwind1972 has suggested that the exact nature of a patient's language deficit following a stroke can be used to diagnose the specific region of the brain that has been damaged. A researcher is concerned with identifying the specific communication difficulties experienced by six patients suffering from Broca's Aphasia (a language deficit commonly experienced following a stroke) (@tbl-tab12-12). --->

```{r}
#| label: tbl-tab12-12
#| tbl-cap: 中風患者單詞識別作業分數
#Word recognition task scores in stroke patients
huxtabs[[13]][[12]]
```

患者需要完成三個單詞識別任務。在第一個（言語生成）任務中，患者需要重複研究者大聲朗讀的單詞。在第二個（概念性）任務中，旨在測試單詞理解能力，患者需要將一系列圖片與其正確名稱匹配。在第三個（語法）任務中，旨在測試正確單詞順序的知識，要求患者對語法不正確的句子進行重新排序。每位患者都完成了所有三個任務。患者嘗試任務的順序在參與者之間進行了平衡。每個任務包括一系列10次嘗試。每位患者成功完成的嘗試次數如 @tbl-tab12-11 所示。將這些數據輸入jamovi以進行分析（或者使用捷徑加載*broca.csv*文件）。

要在jamovi中執行一個單因素相關ANOVA，打開一個單因素重覆量數變數分析對話框，如 @fig-fig12-9 中所示，通過ANOVA - Repeated Measures ANOVA進行。


<!--- The patients were required to complete three word recognition tasks. On the first (speech production) task, patients were required to repeat single words read out aloud by the researcher. On the second (conceptual) task, designed to test word comprehension, patients were required to match a series of pictures with their correct name. On the third (syntax) task, designed to test knowledge of correct word order, patients were asked to reorder syntactically incorrect sentences. Each patient completed all three tasks. The order in which patients attempted the tasks was counterbalanced between participants. Each task consisted of a series of 10 attempts. The number of attempts successfully completed by each patient are shown in @tbl-tab12-11. Enter these data into jamovi ready for analysis (or take a short-cut and load up the *broca.csv* file).

To perform a one-way related ANOVA in jamovi, open the one-way repeated measures ANOVA dialogue box, as in @fig-fig12-9, via ANOVA - Repeated Measures ANOVA. --->

```{r}
#| label: fig-fig12-9
#| fig-cap: jamovi中的重覆量數變數分析對話框
#Repeated measures ANOVA dialogue box in jamovi
knitr::include_graphics("images/fig13-9.png")
```

然後：

- 輸入一個重複測量因子名稱。這應該是您選擇的標籤，用於描述所有參與者重複的條件。例如，要描述所有參與者完成的語音、概念和語法任務，一個合適的標籤是“任務”。請注意，這個新的因子名稱代表了分析中的自變項。
- 在重複測量因子文本框中添加第三個級別，因為有三個級別代表三個任務：語音、概念和語法。相應地更改級別的標籤。
- 然後將每個級別變項移動到重複測量單元文本框中。
- 最後，在“假設檢查”選項下，選中“球形性檢查”文本框。

jamovi輸出一個單因素重覆量數變數分析，如 @fig-fig12-10 至 @fig-fig12-13 所示。我們應該首先查看的是Mauchly球形性檢驗，該檢驗測試各條件之間的差異方差是否相等（意味著研究條件之間的差異得分的分佈大致相同）。在 @fig-fig12-10 中，Mauchly檢驗的顯著性水平為$p = .720$。如果Mauchly檢驗的結果不顯著（即p > .05，正如此分析中的情況），那麼我們有理由得出差異的方差並無顯著差異（即它們大致相等，可以假定球形性。）。



<!--- Then:

- Enter a Repeated Measures Factor Name. This should be a label that you choose to describe the conditions repeated by all participants. For example, to describe the speech, conceptual and syntax tasks completed by all participants a suitable label would be 'Task'. Note that this new factor name represents the independent variable in the analysis.
- Add a third level in the Repeated Measures Factors text box, as there are three levels representing the three tasks: speech, conceptual and syntax. Change the labels of the levels accordingly.
- Then move each of the levels variables across to the Repeated Measures Cells text box.
- Finally, under the Assumption Checks option, tick the "Sphericity checks" text box.

jamovi output for a one-way repeated measures ANOVA is produced as shown in @fig-fig12-10 to @fig-fig12-13. The first output we should look at is Mauchly's Test of Sphericity, which tests the hypothesis that the variances of the differences between the conditions are equal (meaning that the spread of difference scores between the study conditions is approximately the same). In @fig-fig12-10 Mauchly's test significance level is $p = .720$. If Mauchly's test is non-significant (i.e. p > .05, as is the case in this analysis) then it is reasonable to conclude that the variances of the differences are not significantly different (i.e. they are roughly equal and sphericity can be assumed.). --->

```{r}
#| label: fig-fig12-10
#| classes: .enlarge-image
#| fig-cap: 單因子重覆量數變數分析輸出 - Mauchly球形性檢驗
#One-way repeated measures ANOVA output - Mauchly's Test of Sphericity
knitr::include_graphics("images/fig13-10.png")
```

如果另一方面，Mauchly檢驗顯著（p < .05），那麼我們將得出差異方差之間存在顯著差異，並且未滿足球形性要求。在這種情況下，我們應該對單因素相關ANOVA分析中獲得的F值進行修正：

-   如果"球形性檢驗"表中的Greenhouse-Geisser值> .75，那麼您應該使用Huynh-Feldt修正
-   但如果Greenhouse-Geisser值< .75，那麼您應該使用Greenhouse-Geisser修正。

這兩個修正過的F值都可以在“假設檢查”選項下的球形性修正復選框中指定，修正過的F值將顯示在結果表中，如 @fig-fig12-11 所示。



<!--- If, on the other hand, Mauchly's test had been significant (p < .05) then we would conclude that there are significant differences between the variance of the differences, and the requirement of sphericity has not been met. In this case, we should apply a correction to the F-value obtained in the one-way related ANOVA analysis:

-   If the Greenhouse-Geisser value in the "Tests of Sphericity" table is > .75 then you should use the Huynh-Feldt correction
-   But if the Greenhouse-Geisser value is < .75, then you should use the Greenhouse-Geisser correction.

Both these corrected F-values can be specified in the Sphericity Corrections check boxes under the Assumption Checks options, and the corrected F-values are then shown in the results table, as in @fig-fig12-11 . --->

```{r}
#| label: fig-fig12-11
#| classes: .enlarge-image
#| fig-cap: 單因素重覆量數變數分析輸出 - 內部受試者效應檢驗
#One-way repeated measures ANOVA output - Tests of Within-Subjects Effects
knitr::include_graphics("images/fig13-11.png")
```

在我們的分析中，我們發現Mauchly的球形性檢驗的顯著性為p = .720（即p > 0.05）。因此，這意味著我們可以假設已滿足球形性要求，因此無需對F值進行修正。因此，我們可以使用'無'球形性修正輸出值用於重複測量"任務"：$F = 6.93$，$df = 2$，$p = .013$，我們可以得出結論，語言任務中成功完成的測試次數確實會根據任務是語音、理解還是語法為基礎而顯著不同（$F(2, 10) = 6.93$，$p = .013$）。

在jamovi中，與獨立ANOVA相同，也可以為重覆量數變數分析指定事後檢驗。結果顯示在 @fig-fig12-12 。這些表明語音和語法之間存在顯著差異，但其他級別之間沒有差異。

<!--- In our analysis, we saw that the significance of Mauchly's Test of Sphericity was p = .720 (i.e. p > 0.05). So, this means we can assume that the requirement of sphericity has been met so no correction to the F-value is needed. Therefore, we can use the 'None' Sphericity Correction output values for the repeated measure 'Task': $F = 6.93$, $df = 2$, $p = .013$, and we can conclude that the number of tests successfully completed on each language task did vary significantly depending on whether the task was speech, comprehension or syntax based ($F(2, 10) = 6.93$, $p = .013$).

Post-hoc tests can also be specified in jamovi for repeated measures ANOVA in the same way as for independent ANOVA. The results are shown in @fig-fig12-12. These indicate that there is a significant difference between Speech and Syntax, but not between other levels. --->

```{r}
#| label: fig-fig12-12
#| classes: .enlarge-image
#| fig-cap: 重覆量數變數分析中jamovi的事後檢驗
#Post-hoc tests in repeated measures ANOVA in jamovi
knitr::include_graphics("images/fig13-12.png")
```

描述性統計（邊際均值）可以用於幫助解釋結果，在jamovi輸出中生成，如 @fig-fig12-13 。通過比較參與者成功完成試驗的平均次數，可以看出布洛卡失語症患者在語音產生（平均= 7.17）和語言理解（平均= 6.17）任務上表現相對較好。然而，他們在語法任務上的表現明顯較差（平均= 4.33），事後檢驗中語音和語法任務表現之間存在顯著差異。


<!--- Descriptive statistics (marginal means) can be reviewed to help interpret the results, produced in the jamovi output as in @fig-fig12-13. Comparison of the mean number of trials successfully completed by participants shows that Broca's Aphasics perform reasonably well on speech production (mean = 7.17) and language comprehension (mean = 6.17) tasks. However, their performance was considerably worse on the syntax task (mean = 4.33), with a significant difference in post-hoc tests between Speech and Syntax task performance. --->

```{r}
#| label: fig-fig12-13
#| classes: .enlarge-image
#| fig-cap: 單因子重覆量數變數分析輸出-描述性統計
#One-way repeated measures ANOVA output - Descriptive Statistics
knitr::include_graphics("images/fig13-13.png")
```

## Friedman無母數重覆量數變異數分析

Friedman檢驗是一元重覆量數變數分析的非參數版本，可以在測試三個或更多組之間的差異時使用，其中每個組中的參與者相同，或者每個參與者與其他條件中的參與者密切匹配。如果因變項是序數，或者未滿足正態性假設，則可以使用Friedman檢驗。

與Kruskall-Wallis檢驗一樣，基本數學知識很複雜，這裡不會介紹。對於本書的目的，僅需注意jamovi計算了Friedman檢驗的綁定修正版本，在 @fig-fig12-14 中有一個我們已經查看過的布洛卡失語症數據的示例。



<!--- The Friedman test is a non-parametric version of a repeated measures ANOVA and can be used instead of the Kruskall-Wallis test when testing for differences between three or more groups where the same participants are in each group, or each participant is closely matched with participants in other conditions. If the dependent variable is ordinal, or if the assumption of normality is not met, then the Friedman test can be used.

As with the Kruskall-Wallis test, the underlying mathematics is complicated, and won't be presented here. For the purpose of this book, it is sufficient to note that jamovi calculates the tie-corrected version of the Friedman test, and in @fig-fig12-14 there is an example using the Broca's Aphasia data we have already looked at. --->

```{r}
#| label: fig-fig12-14
#| classes: .enlarge-image
#| fig-cap: jamovi中的“重覆量數變數分析（非參數）”對話框和結果
#The 'Repeated Measures ANOVA (Non-parametric)' dialogue box and results in jamovi
knitr::include_graphics("images/fig13-14.png")
```

在jamovi中運行Friedman檢驗非常簡單。只需選擇分析 - ANOVA - 重覆量數變數分析（非參數），如 @fig-fig12-14 所示。然後將要比較的重複測量變項的名稱（語言、概念、語法）突顯並轉移到“測量：”文本框中。要為三個重複測量變項生成描述性統計（平均值和中位數），請單擊描述性按鈕。

jamovi結果顯示描述性統計、卡方值、自由度和p值（ @fig-fig12-14 ）。由於p值小於通常用於確定顯著性的水平（p < .05），我們可以得出結論，布洛卡失語症患者在語言生產（中位數= 7.5）和語言理解（中位數= 6.5）任務上表現相當好。然而，他們在語法任務上的表現明顯較差（中位數= 4.5），在事後檢驗中語言和語法任務表現之間存在顯著差異。

<!--- It's pretty straightforward to run a Friedman test in jamovi. Just select Analyses - ANOVA - Repeated Measures ANOVA (Non-parametric), as in @fig-fig12-14. Then highlight and transfer the names of the repeated measures variables you wish to compare (Speech, Conceptual, Syntax) into the 'Measures:' text box. To produce descriptive statistics (means and medians) for the three repeated measures variables, click on the Descriptives button

The jamovi results show descriptive statistics, chi-square value, degrees of freedom, and the p-value (@fig-fig12-14). Since the p-value is less than the level conventionally used to determine significance (p < .05), we can conclude that Broca's Aphasics perform reasonably well on speech production (median = 7.5) and language comprehension (median = 6.5) tasks. However, their performance was considerably worse on the syntax task (median = 4.5), with a significant difference in post-hoc tests between Speech and Syntax task performance. --->

## 變異數分析與t檢定的關聯 {#sec-On-the-relationship-between-ANOVA-and-the-Student-t-test}

在結束之前，我想指出的最後一點是，許多人對此感到驚訝，但了解它是很有價值的。具有兩個組別的ANOVA與學生t檢驗相同。不，真的。它們不僅相似，而且在每個有意義的方面實際上都是等效的。我不會試圖證明這總是成立，但我將給你展示一個具體的演示。假設，我們不對mood.gain \~ drug模型進行ANOVA，而是使用療法作為預測指標。如果我們運行此ANOVA，我們將得到一個F統計量 $F(1,16) = 1.71$，和一個 p值 = $0.21$。由於我們只有兩組，實際上我不需要求助於ANOVA，我可以選擇運行一個學生t檢驗。那麼，讓我們看看這樣做會發生什麼：我得到一個t統計量 $t(16) = -1.3068$ 和一個 $p值 = 0.21$。好奇的是，p值是相同的。再一次，我們得到一個值 $p = .21$。但是，檢驗統計量呢？運行t檢驗而不是ANOVA，我們得到了一個略有不同的答案，即 $t(16) = -1.3068$。然而，這裡有一個相當直接的關係。如果將t統計量平方，我們就會得到之前的F統計量：$-1.3068^{2} = 1.7077$

<!--- There's one last thing I want to point out before finishing. It's something that a lot of people find kind of surprising, but it's worth knowing about. An ANOVA with two groups is identical to the Student t-test. No, really. It's not just that they are similar, but they are actually equivalent in every meaningful way. I won't try to prove that this is always true, but I will show you a single concrete demonstration. Suppose that, instead of running an ANOVA on our mood.gain \~ drug model, let's instead do it using therapy as the predictor. If we run this ANOVA we get an F-statistic of $F(1,16) = 1.71$, and a p-value = $0.21$. Since we only have two groups, I didn't actually need to resort to an ANOVA, I could have just decided to run a Student t-test. So let's see what happens when I do that: I get a t-statistic of $t(16) = -1.3068$ and a $p-value = 0.21$. Curiously, the p-values are identical. Once again we obtain a value of $p = .21$. But what about the test statistic? Having run a t-test instead of an ANOVA, we get a somewhat different answer, namely $t(16) = -1.3068$. However, there is a fairly straightforward relationship here. If we square the t-statistic then we get the F-statistic from before: $-1.3068^{2} = 1.7077$ --->

## 這個單元小結

這一章份量不少，但是有一些細節我並未提到[^13-summary-1]。最明顯的是在此並未討論處理不只一個分組變項的資料，我們在下一章 @sec-Factorial-ANOVA 將學習其中一部分。這個單元的學習重點有：

- 理解[變異數分析的運作原理](13-Comparing-several-means-one-way-ANOVA.html#sec-How-ANOVA-works) 以及[使用jamovi完成變異數分析](13-Comparing-several-means-one-way-ANOVA.html#jamovi%E7%9A%84%E8%AE%8A%E7%95%B0%E6%95%B8%E5%88%86%E6%9E%90%E6%A8%A1%E7%B5%84) 
- 學習如何計算變異數分析的[效果量](13-Comparing-several-means-one-way-ANOVA.html#%E6%95%88%E6%9E%9C%E9%87%8F) 
- [多重比較與事後檢定](13-Comparing-several-means-one-way-ANOVA.html#%E5%A4%9A%E9%87%8D%E6%AF%94%E8%BC%83%E8%88%87%E4%BA%8B%E5%BE%8C%E6%AA%A2%E5%AE%9A)
- [單因子變異數分析的執行條件](13-Comparing-several-means-one-way-ANOVA.html#%E5%96%AE%E5%9B%A0%E5%AD%90%E8%AE%8A%E7%95%B0%E6%95%B8%E5%88%86%E6%9E%90%E7%9A%84%E5%9F%B7%E8%A1%8C%E6%A2%9D%E4%BB%B6)
- [同質性檢核](13-Comparing-several-means-one-way-ANOVA.html#sec-Checking-the-homogeneity-of-variance-assumption) 以及 [校正異質性的分析結果](13-Comparing-several-means-one-way-ANOVA.html#%E6%A0%A1%E6%AD%A3%E7%95%B0%E8%B3%AA%E6%80%A7%E7%9A%84%E5%88%86%E6%9E%90%E7%B5%90%E6%9E%9C)
- [常態性檢核](13-Comparing-several-means-one-way-ANOVA.html#sec-Checking-the-normality-assumption)以及[排除非常態性的分析結果](13-Comparing-several-means-one-way-ANOVA.html#%E6%8E%92%E9%99%A4%E9%9D%9E%E5%B8%B8%E6%85%8B%E6%80%A7%E7%9A%84%E5%88%86%E6%9E%90%E7%B5%90%E6%9E%9C)
- [單因子重覆量數變異數分析](13-Comparing-several-means-one-way-ANOVA.html#%E5%96%AE%E5%9B%A0%E5%AD%90%E9%87%8D%E8%A6%86%E9%87%8F%E6%95%B8%E8%AE%8A%E7%95%B0%E6%95%B8%E5%88%86%E6%9E%90) 以及其無母數版本[單因子重覆量數變異數分析](13-Comparing-several-means-one-way-ANOVA.html#friedman%E7%84%A1%E6%AF%8D%E6%95%B8%E9%87%8D%E8%A6%86%E9%87%8F%E6%95%B8%E8%AE%8A%E7%95%B0%E6%95%B8%E5%88%86%E6%9E%90)

[^13-summary-1]: 就像其他章節，這個單元內容有許多參考來源，其中原作者參考最多的專書是 @Sahai2000 。這本書對初學者來說偏難，不過如果學到這裡，想知道更多變異數分析的數學原理，這本書是不錯的參考資源。

<!---
There's a fair bit covered in this chapter, but there's still a lot missing [^13-summary-1]. Most obviously, I haven't discussed how to run an ANOVA when you are interested in more than one grouping variable, but that will be discussed in a lot of detail in @sec-Factorial-ANOVA. In terms of what we have discussed, the key topics were:

- The basic logic behind [How ANOVA works] and [Running an ANOVA in jamovi]
- How to compute an [Effect size] for an ANOVA.
- [Multiple comparisons and post hoc tests] for multiple testing.
- [The assumptions of one-way ANOVA]
- [Checking the homogeneity of variance assumption] and what to do if it is violated: [Removing the homogeneity of variance assumption]
- [Checking the normality assumption] and what to do if it is violated: [Removing the normality assumption]
- [Repeated measures one-way ANOVA] and the non-parametric equivalent, [The Friedman non-parametric repeated measures ANOVA test]

[^13-summary-1]: As with all of the chapters in this book, there are quite a few different sources that I've relied upon, but the one stand-out text that I've been most heavily influenced by @Sahai2000. It's not a good book for beginners, but it's an excellent book for more advanced readers who are interested in understanding the mathematics behind ANOVA.--->
