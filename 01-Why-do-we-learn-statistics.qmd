# 為什麼要學習統計 {#sec-why-do-we-learn-statistics}

```{r}
#| include: FALSE
source("header.R")
```

<!---- $$    $$ bug...need this here otherwise tables don't render latex in html output  --->

> 汝不可填答任何試卷  
> 或回答全球事務的試題,  
> 也不可順從接受任何考試。  
> 汝不可同意統計學家的意見,  
> 也不可順從任何社會科學主張。  
> -- W.H. 奧登[^01-why-do-we-learn-statistics-1]

[^01-why-do-we-learn-statistics-1]: 出自奧登在哈佛大學1946年的畢業典禮致詞中詩作『在哪張豎琴下：時代的反動手冊』。有興趣了解這段致詞的歷史背景，可參考這裡: <https://www.harvardmagazine.com/2007/11/a-poets-warning.html>

## 首先談談統計的心理學 {#sec-why-do-we-learn-statistics-begin}

先講許多第一次來上課的同學驚呆的現實，統計學在心理學課程佔有相當的份量。另外一個不令人意外的現實，是統計學很少被上過心理學課程的同學*推薦*。畢竟正常來說，如果是喜歡統計的同學，應該是去修統計系的課，而不是來上心理學系的課。不需要太正式的調查，正在上心理學課程的同學，有一大部分想必很不高興要學有這麼多統計。為了幫助同學渡過這段不適應，我想這本書先來談談一般人對於統計學的一些常見疑問。

<!---
To the surprise of many students, statistics is a fairly significant part of a psychological education. To the surprise of no-one, statistics is very rarely the *favourite* part of one's psychological education. After all, if you really loved the idea of doing statistics, you'd probably be enrolled in a statistics class right now, not a psychology class. So, not surprisingly, there's a pretty large proportion of the student base that isn't happy about the fact that psychology has so much statistics in it. In view of this, I thought that the right place to start might be to answer some of the more common questions that people have about stats.--->

這個問題的很大一部分與統計學的本質有關。統計學是什麼？統計學是做什麼用的？為什麼科學家如此迷戀統計？只要你能提出這些問題，都是值得好好回答的問題。我們先從最後一個問題開始談吧。科學家集體似乎想對每件事情進行統計分析，旁人看來近乎固執。科學家確實經常使用統計學，有時候甚至忘記向一般人解釋為什麽這樣做。這是科學家之間的一種信仰，尤其是社會科學家。任何科學家沒有完成統計之前，他的發現是不會被其他科學家信任的。(新鮮人)大學生看了，可能會認為這群人都是瘋子，因為沒有科學家會花時間向一般人回答這個非常簡單的問題：

<!---A big part of this issue at hand relates to the very idea of statistics. What is it? What's it there for? And why are scientists so bloody obsessed with it? These are all good questions, when you think about it. So let's start with the last one. As a group, scientists seem to be bizarrely fixated on running statistical tests on everything. In fact, we use statistics so often that we sometimes forget to explain to people why we do. It's a kind of article of faith among scientists -- and especially social scientists -- that your findings can't be trusted until you've done some stats. Undergraduate students might be forgiven for thinking that we're all completely mad, because no-one takes the time to answer one very simple question:--->

**為什麼當心理學家要會使用統計？為什麼科學家不能憑<u>生活常識</u>做研究？**


<!---
*Why do you do statistics? Why don't scientists just use* <u>common sense?</u> --->

在某些方面，這是一個天真的問題，但大多數好問題都是這樣開始的。對此問題已經有許多有意思的回答[^01-why-do-we-learn-statistics-2]，不過我心中最好的回答是一個大家都懂的人性現實：人類無法充分信任自己的判斷。正是因為了解人類本身，很容易受到各種偏見、誘惑和軟弱而影響個人的判斷。在很多情況，統計學提供一種基本保障。使用"生活常識"評估證據意味著信任直覺，依靠言語推論以及使用人類原生的推理能力找出正確答案。但是大多數科學家認為這種方法不太可靠。

[^01-why-do-we-learn-statistics-2]: 其中包含多數科學家缺乏常識的說法。 <!---Including the suggestion that common sense is in short supply among scientists.--->

<!---It's a naive question in some ways, but most good questions are. There's a lot of good answers to it,[^why-do-we-learn-statistics-2] but for my money, the best answer is a really simple one: we don't trust ourselves enough. We worry that we're human, and susceptible to all of the biases, temptations and frailties that humans suffer from. Much of statistics is basically a safeguard. Using "common sense" to evaluate evidence means trusting gut instincts, relying on verbal arguments and on using the raw power of human reason to come up with the right answer. Most scientists don't think this approach is likely to work.--->

其實好好地想一想，這很像是一個心理學家會研究的問題，既然我在心理學系工作，這似乎是個值得深入研究的好題目。真的有道理認為"靠常識"做出的研究是值得信賴的嗎？言語推論是用語言構建的，所有語言都帶有偏見 - 像是有些事情特別難說，並不一定是因為它們是錯的（例如，量子力學是一個很好的理論，但很難用言語解釋）。因為人類的"直覺"本能並不是用來解決科學問題，而是用來應付日常推論問題 - 由於生物演化速度比文化演化遲緩，我們應該說直覺是為了解決*不同於我們的生活經驗*的日常問題而設計的產物。科學研究的根本是理性推理，需要我們進行"歸納"，做出明智的猜测，超越用感官接收的證據，概括這個世界的樣貌。如果你認為有本事不受各種外界干擾進行理性推理，那麼我有份年薪百萬，請你去柬埔寨打工的機會想介紹給你[^01-why-do-we-learn-statistics-3]。哎呀，正如下一節我要說的，我们也無法解决不需要猜測的"演繹"問題，也就是那些不會受到預先存在的偏見所影響的問題。

[^01-why-do-we-learn-statistics-3]: 譯註\~原文"I have a bridge in London I'd like to sell you."是澳洲俚語，意指對方容易受騙上當，在此改寫為台灣人都知道的典故。

<!---In fact, come to think of it, this sounds a lot like a psychological question to me, and since I do work in a psychology department, it seems like a good idea to dig a little deeper here. Is it really plausible to think that this "common sense" approach is very trustworthy? Verbal arguments have to be constructed in language, and all languages have biases -- some things are harder to say than others, and not necessarily because they're false (e.g., quantum electrodynamics is a good theory, but hard to explain in words). The instincts of our "gut" aren't designed to solve scientific problems, they're designed to handle day to day inferences -- and given that biological evolution is slower than cultural change, we should say that they're designed to solve the day to day problems for a *different world* than the one we live in. Most fundamentally, reasoning sensibly requires people to engage in "induction", making wise guesses and going beyond the immediate evidence of the senses to make generalisations about the world. If you think that you can do that without being influenced by various distractors, well, I have a bridge in London I'd like to sell you. Heck, as the next section shows, we can't even solve "deductive" problems (ones where no guessing is required) without being influenced by our pre-existing biases. --->

### 信念偏誤的詛咒

大多數人類都很聰明。我們肯定比地球上其他物種要聰明得多（盡管可能很多人不這麽認為）。人類的思維能力是非常神奇的產物，我們似乎有能力思考和推理任何不可思議的事情。但是這並不意味著人類完美無缺。心理學家累積多年的研究已經表明，人類確實很難保持中立，公正地評估證據，而不會受到預期偏見的影響。有個很好的例子是邏輯推理中的信念偏差效應：如果你要求我判斷一個特定的論點是否在邏輯上是正確的（也就是說，如果前提是真實的，結論就是真實的），我常常會受到結論的可信度影響，即使我明知不該如此。以下是一段結論可信的有效邏輯論證：

> 所有香煙是昂貴的 (前提 1)\
> 有些會上癮的東西是便宜的 (前提 2)\
> 所以有些會上癮的東西不是香煙(結論)

再看這一段結論不可信的有效邏輯論證：

> 所有會上癮的東西是昂貴的 (前提 1)\
> 有些香煙是便宜的 (前提 2)\
> 所以有些香煙不是會上癮的(結論)

<!---People are mostly pretty smart. We're certainly smarter than the other species that we share the planet with (though many people might disagree). Our minds are quite amazing things, and we seem to be capable of the most incredible feats of thought and reason. That doesn't make us perfect though. And among the many things that psychologists have shown over the years is that we really do find it hard to be neutral, to evaluate evidence impartially and without being swayed by pre-existing biases. A good example of this is the **belief bias effect** in logical reasoning: if you ask people to decide whether a particular argument is logically valid (i.e., conclusion would be true if the premises were true), we tend to be influenced by the believability of the conclusion, even when we shouldn't.  For instance, here's a valid argument where the conclusion is believable:

> All cigarettes are expensive (Premise 1)\
> Some addictive things are inexpensive (Premise 2)\
> Therefore, some addictive things are not cigarettes (Conclusion)

And here's a valid argument where the conclusion is not believable:

> All addictive things are expensive (Premise 1)\
> Some cigarettes are inexpensive (Premise 2)\
> Therefore, some cigarettes are not addictive (Conclusion)--->


兩段論證的結構都是相同而且有效[^01-why-do-we-learn-statistics-4]。然而第二段的前提1有理由相信並不正確，所以有人會認為結論也不正確。其實無論前提的內容如何，論證的演繹有效性僅取決於前提與結論的結構。也就是說，有效論證不必然要包括真實的敘述。

[^01-why-do-we-learn-statistics-4]: 譯註\~ 請參考維基百科[直言三段論](https://zh.m.wikipedia.org/zh-tw/%E7%9B%B4%E8%A8%80%E4%B8%89%E6%AE%B5%E8%AE%BA)，此處的論證格式稱為2-AOO。

<!---The logical *structure* of argument #2 is identical to the structure of argument #1, and they're both valid. However, in the second argument, there are good reasons to think that premise 1 is incorrect, and as a result it's probably the case that the conclusion is also incorrect. But that's entirely irrelevant to the topic at hand; an argument is deductively valid if the conclusion is a logical consequence of the premises.That is, a valid argument doesn't have to involve true statements. --->

另一方面，無效的論證也能有讓人相信為真的結論，就像下一段論證：

<!---On the other hand, here's an invalid argument that has a believable conclusion:--->

> 所有會上癮的東西是昂貴的 (前提 1)\
> 有些香煙是便宜的 (前提 2)\
> 所以有些會上癮的東西不是香煙(結論)


<!---
> All addictive things are expensive (Premise 1)\
> Some cigarettes are inexpensive (Premise 2)\
> Therefore, some addictive things are not cigarettes (Conclusion)
--->

最後來看以下這段無效演繹且結論不可信的論證：

<!---
And finally, an invalid argument with an unbelievable conclusion:
--->

> 所有香煙是昂貴的 (前提 1)\
> 有些會上癮的東西是便宜的 (前提 2)\
> 所以有些香煙不是會上癮的(結論)

<!---
> All cigarettes are expensive (Premise 1)\
> Some addictive things are inexpensive (Premise 2)\
> Therefore, some cigarettes are not addictive (Conclusion)
--->

假設人類真的完全能夠放下對於敘述真實性的預期偏見，僅憑邏輯有效性評估論點是否合理。那麼我們可以設計實驗，測試看看是否所有人都會認為有效論證是正確的，沒有人會說無效論證是正確的。我把這樣的假設製成*表1.1* 。


<!---
Now, suppose that people really are perfectly able to set aside their pre-existing biases about what is true and what isn't, and purely evaluate an argument on its logical merits. We'd expect 100% of people to say that the valid arguments are valid, and 0% of people to say that the invalid arguments are valid. So if you ran an experiment looking at this, you'd expect to see data as in @tbl-tab1-1.


#| label: tbl-tab1-1
#| tbl-cap: 判斷人類能拋開偏見進行有效論證的假設結果
#huxtabs[[1]][[1]] |> set_contents(1, 1, "")
--->


```{=html}

<table width="50%" border="1" >
  <caption>表1.1 判斷人類能拋開偏見進行有效論證的假設結果</caption>
	<tr>
		<th> </th>
		<th>結論應該為真</th>
		<th>結論應該為假</th>
	</tr>
	<tr>
		<th>論證有效</th>
		<td>100\(\%\) 認為“有效”</td>
		<td>100\(\%\) 認為“有效”</td>
	</tr>
	<tr>
		<th>論證無效</th>
		<td>0\(\%\) 認為“有效”</td>
		<td>0\(\%\) 認為“有效”</td>
	</tr>
</table>
```


假如心理學研究結果就像表內的數值（或者只是接近這樣的數值），我們可能覺得完全靠人類的直覺就能做出結論。只要是像這樣的研究結果，科學家完全可以根據他們的常識評估結果數據，不用花時間處理那堆讓很多人看不懂什麼意思的統計分析。然而，你們已經至少修過心理學概論，對於這套實驗的真正結果應該略知一二。

@Evans1983 做了一系列探討人類如何進行邏輯推論的經典實驗。他們發現只有結論敘述符合多數人的預期偏誤(也就是信念)，實驗結果才會接近人類能做有效推論的假設(表1.2)。


```{=html}

<table width="50%" border="1" >
  <caption>表1.2 預期偏誤與論證有效性的實驗結果</caption>
	<tr>
		<th> </th>
		<th>結論應該為真</th>
		<th>結論應該為假</th>
	</tr>
	<tr>
		<th>論證有效</th>
		<td>92\(\%\) 認為“有效”</td>
		<td> </td>
	</tr>
	<tr>
		<th>論證無效</th>
		<td> </td>
		<td>8\(\%\) 認為“有效”</td>
	</tr>
</table>
```


<!---
If the psychological data looked like this (or even a good approximation to this), we might feel safe in just trusting our gut instincts. That is, it'd be perfectly okay just to let scientists evaluate data based on their common sense, and not bother with all this murky statistics stuff. However, you guys have taken psych classes, and by now you probably know where this is going.

In a classic study, @Evans1983 ran an experiment looking at exactly this. What they found is that when pre-existing biases (i.e., beliefs) were in agreement with the structure of the data, everything went the way you'd hope (@tbl-tab1-2).


#| label: tbl-tab1-2
#| tbl-cap:  預期偏誤與論證是否有效的實驗結果
#huxtabs[[1]][[2]] |> set_contents(1, 1, "")--->

雖然不夠完美，但是這樣的結果也算不錯了。不過看看另外兩個與一般人的直覺完全相反實驗情況，與表1.1的完美假設完全不同(表1.3)。


```{=html}

<table width="50%" border="1" >
  <caption>表1.3 直覺判斷與論證有效性的實驗結果</caption>
	<tr>
		<th> </th>
		<th>結論應該為真</th>
		<th>結論應該為假</th>
	</tr>
	<tr>
		<th>論證有效</th>
		<td>92\(\%\) 認為“有效”</td>
		<td><b>46\(\%\) 認為“有效”</b></td>
	</tr>
	<tr>
		<th>論證無效</th>
		<td><b>92\(\%\) 認為“有效”</b></td>
		<td>8\(\%\) 認為“有效”</td>
	</tr>
</table>
```

<!---Not perfect, but that's pretty good. But look what happens when our intuitive feelings about the truth of the conclusion run against the logical structure of the argument (@tbl-tab1-3):

#| label: tbl-tab1-3
#| tbl-cap:  以直覺判斷有效論證是否有效的結果
#huxtabs[[1]][[3]] |> set_contents(1, 1, "")--->


哎呀，這不是好解釋的結果。實驗結果顯示似乎向一般人講述一個與既有信念互相矛盾但有邏輯效力的論點時，人們很難相信這是一個強而有力的論點（只有 46% 的人會相信）。更糟的是，向一般人講述一個與既有偏見相符但沒有邏輯效力的的論點時，幾乎沒有人能看出這個論點無效（高達 92% 的人判斷錯誤！）。[^01-why-do-we-learn-statistics-5]

[^01-why-do-we-learn-statistics-5]: 這能解釋那些網路上令我感到憤怒的訊息，其中95%的成因。

如果仔細想想，這並不是很糟糕的結果。總體來看，一般人的表現比隨機亂猜好，大約有60％的人做出了正確的判斷（隨機亂猜應該是50％）。即使如此，如果你是一名專業的“證據鑑識人員”，有人送你一個可以提高正確決策的機率的神奇工具，比如說從 60% 到95% ，你應會欣然接受吧？幸好我們有一種工具可以做到這一點。這種工具不是魔法，而是統計學。這就是為什麼科學家喜歡使用統計的最主要原因。我們很容易「信任我們想要相信的」。所以如果我們要做到「信任資料」，就需要一些工具幫助我們控制個人偏見。而這就是統計學的用途，它能幫助我們保持推論的誠實。

<!---Oh dear, that's not as good. Apparently, when people are presented with a strong argument that contradicts our pre-existing beliefs, we find it pretty hard to even perceive it to be a strong argument (people only did so 46% of the time). Even worse, when people are presented with a weak argument that agrees with our pre-existing biases, almost no-one can see that the argument is weak (people got that one wrong 92% of the time!).[^01-why-do-we-learn-statistics-5]

[^01-why-do-we-learn-statistics-5]: In my more cynical moments I feel like this fact alone explains 95% of what I read on the internet.

If you think about it, it's not as if these data are horribly damning. Overall, people did do better than chance at compensating for their prior biases, since about 60% of people's judgements were correct (you'd expect 50% by chance). Even so, if you were a professional "evaluator of evidence", and someone came along and offered you a magic tool that improves your chances of making the right decision from 60% to (say) 95%, you'd probably jump at it, right? Of course you would. Thankfully, we actually do have a tool that can do this. But it's not magic, it's statistics. So that's reason #1 why scientists love statistics. It's just too easy for us to "believe what we want to believe". So instead, if we want to "believe in the data", we're going to need a bit of help to keep our personal biases under control. That's what statistics does, it helps keep us honest. --->

## 談一談辛普森悖論

接著來談一則真實故事(我想應該是真的)。1973年，美國加州大學柏克萊分校高層擔憂該年研究所的入學申請人數及錄取的狀況。更明白的說，他們覺得錄取的學生呈現性別不平等的狀況(見表1.4)。

```{=html}
<table width="50%" border="1" >
  <caption>表1.4 柏克萊男女新生報考人數及錄取比例</caption>
	<tr>
		<th> </th>
		<th>申請者人數</th>
		<th>通過比例</th>
	</tr>
	<tr>
		<th>男性</th>
		<td>8442</td>
		<td>44\(\%\)</td>
	</tr>
	<tr>
		<th>女性</th>
		<td>4321</td>
		<td>35\(\%\)</td>
	</tr>
</table>
```

<!--The following is a true story (I think!). In 1973, the University of California, Berkeley had some worries about the admissions of students into their postgraduate courses. Specifically, the thing that caused the problem was that the gender breakdown of their admissions (@tbl-tab1-4).

#| label: tbl-tab1-4
#| tbl-cap:  1973年伯克萊大學入學學生性別分佈
huxtabs[[1]][[4]] |> set_contents(1, 1, "")--->

當年的柏克萊校方擔心被申請入學的學生告上法院！由於將近有13,000名申請者，男女之間的錄取率相差9％，這樣的差距實在太大了，不可能是巧合。而且人數如此龐大，可說是鐵一般的事實。但是如果我對你說，這些數據實際上反映了對女性申請者些微的偏袒，你可能會認為我搞錯了或者有性別歧視。

<!---Given this, they were worried about being sued! Given that there were nearly 13,000 applicants, a difference of 9% in admission rates between males and females is just way too big to be a coincidence. Pretty compelling data, right? And if I were to say to you that these data *actually* reflect a weak bias in favour of women (sort of!), you'd probably think that I was either crazy or sexist.--->

<!---[^01-why-do-we-learn-statistics-6]: Earlier versions of these notes incorrectly suggested that they actually were sued. But that's not true. There's a nice commentary on this here: <https://www.refsmmat.com/posts/2016-05-08-simpsons-paradox-berkeley.html> A big thank you to Wilfried Van Hirtum for pointing this out to me.--->

然而，實際情況卻有點出人意料。仔細檢視錄取資料後，有人發現了另一個版本的故事[@Bickel1975]。具體地說，當校方按照學系逐一計算錄取率時，會看到多數學系的女性錄取率實際上略高於男性。表1.5 顯示了六個最多申請者的學系錄取情形（為了保障隱私，以下省略學系名稱）：

```{=html}
<table width="50%" border="1" >
  <caption>表1.5 1973年伯克萊大學六個學系錄取學生的性別分佈</caption>
	<tr>
		<th> </th>
		<th> 男性</th>
		<th> </th>
		<th> 女性</th>
		<th> </th>
	</tr>
	<tr>
		<th>學系</th>
		<th>申請者人數</th>
		<th>錄取比例</th>
		<th>申請者人數</th>
		<th>錄取比例</th>
	</tr>
	<tr>
		<th>A</th>
		<td>825</td>
		<td>62\(\%\)</td>
		<td>108</td>
		<td>82\(\%\)</td>
	</tr>
	<tr>
		<th>B</th>
		<td>560</td>
		<td>63\(\%\)</td>
		<td>25</td>
		<td>68\(\%\)</td>
	</tr>
	<tr>
		<th>C</th>
		<td>325</td>
		<td>37\(\%\)</td>
		<td>593</td>
		<td>34\(\%\)</td>
	</tr>
	<tr>
		<th>D</th>
		<td>417</td>
		<td>33\(\%\)</td>
		<td>375</td>
		<td>35\(\%\)</td>
	</tr>
	<tr>
		<th>E</th>
		<td>191</td>
		<td>28\(\%\)</td>
		<td>393</td>
		<td>24\(\%\)</td>
	</tr>
	<tr>
		<th>F</th>
		<td>272</td>
		<td>6\(\%\)</td>
		<td>341</td>
		<td>7\(\%\)</td>
	</tr>
</table>
```

<!---
Oddly, it's actually sort of true. When people started looking more carefully at the admissions data they told a rather different story [@Bickel1975]. Specifically, when they looked at it on a department by department basis, it turned out that most of the departments actually had a slightly *higher* success rate for female applicants than for male applicants. @tbl-tab1-5 shows the admission figures for the six largest departments (with the names of the departments removed for privacy reasons):

#| label: tbl-tab1-5
#| tbl-cap:  1973年伯克萊大學六個學系入學學生性別分佈
huxtabs[[1]][[5]] |>
  set_contents(1, 1, "") |>
  set_colspan(1, 2, 2) |>
  set_colspan(1, 4, 2)

--->

令人費解的是，大多數系所的女性錄取率都比男性高！但是整個大學的女性錄取率卻低於男性。這怎麼可能？這兩種說法怎麼可能同時成立？


<!---Remarkably, most departments had a *higher* rate of admissions for females than for males! Yet the overall rate of admission across the university for females was lower than for males. How can this be? How can both of these statements be true at the same time?--->

其中究竟發生了什麼事。首先，請留意各系的錄取率並不相同：某些學系，像是A系和B系，傾向錄取最多合格申請者，而其他學系則寧缺勿濫，像是F系，即使申請者資質不差，也傾向不錄取多數申請者。表1.5顯示的六個學系，A系是最好上榜的，其他五系錄取率依遞減。其次請注意，男生和女生申請的學系並不相同。以男性申請者人數排序，會看到六個系的錄取率排序是**A**\>**B**\>D\>C\>F\>E(粗體字是“最好上“的學系)。整體而言，男生偏好申請錄取率高的學系。接著比較一下各系女性申請者的分佈情況。以女生申請者人數排序，就會發現六個系錄取率的排序是C\>E\>D\>F\>**A**\>**B**。也就是說，申請人數似乎顯示多數女生申請"很硬"的學系。事實上，如果我們看一下圖1.1，會發現這樣的趨勢是系統性的，並且非常顯著。這種效應被稱為**辛普森悖論**。這種效應並不常見，但確實在現實世界曾經發生，大多數人第一次遇到這種現象都會非常驚訝，甚至許多人拒絕相信這是真實的現象。但是這種現象再真實不過。雖然其中有很多很微妙的統計教訓，但我想用這個例子指出一個更重要的教訓：每個研究都是困難的，往往隱藏很多很微妙，違反人類直覺的陷阱等著不謹慎的人掉進去。這也是科學家喜歡統計的第二個原因，也是為什麼這門課要教研究方法的原因。因為科學很難，而且真相有時會巧妙地隱藏在複雜數據的縫隙之間。

<!---Here's what's going on. Firstly, notice that the departments are not equal to one another in terms of their admission percentages: some departments (e.g., A, B) tended to admit a high percentage of the qualified applicants, whereas others (e.g., F) tended to reject most of the candidates, even if they were high quality. So, among the six departments shown above, notice that department A is the most generous, followed by B, C, D, E and F in that order. Next, notice that males and females tended to apply to different departments. If we rank the departments in terms of the total number of male applicants, we get **A**\>**B**\>D\>C\>F\>E (the "easy" departments are in bold). On the whole, males tended to apply to the departments that had high admission rates. Now compare this to how the female applicants distributed themselves. Ranking the departments in terms of the total number of female applicants produces a quite different ordering C\>E\>D\>F\>**A**\>**B**. In other words, what these data seem to be suggesting is that the female applicants tended to apply to "harder" departments. And in fact, if we look at Figure @fig-fig1-1 we see that this trend is systematic, and quite striking. This effect is known as **Simpson's paradox**. It's not common, but it does happen in real life, and most people are very surprised by it when they first encounter it, and many people refuse to even believe that it's real. It is very real. And while there are lots of very subtle statistical lessons buried in there, I want to use it to make a much more important point: doing research is hard, and there are lots of subtle, counter-intuitive traps lying in wait for the unwary. That's reason #2 why scientists love statistics, and why we teach research methods. Because science is hard, and the truth is sometimes cunningly hidden in the nooks and crannies of complicated data.--->

在結束這個主題之前，我想指出一些研究方法課程常常忽略的事情。那就是統計只解決了問題的一部分。記得我們一開始關注是伯克利大學的招生程序可能對女性申請者不公平。當我們檢視"聚合"的資料時，整體似乎指向柏克萊明顯歧視女性，但是當我們"分解"各個學系的資料並深入檢視男女生個人行為，其實資料顯示各學系招生狀況的差異。如果真的有偏見，其實是各系輕微偏好錄取女生。總錄取率的性別偏差其實是因為女生傾向選擇較難上榜的系所。從法律角度來看，大學高層並沒有任何責仼。要錄取誰當研究生，權責是在個別系所，並且每個系所都有充分的理由決定要怎麼做。在系所的層次，錄取決策幾乎是公平的（各系所偏好錄取女性偏好很微弱，並且不一致）。由於大學高層無法決定學生想申請哪些科系，並且決策權限在各系所，所以校方幾乎不能干預招生程序，也無需對任何偏見負起責任。


<!---Before leaving this topic entirely, I want to point out something else really critical that is often overlooked in a research methods class. Statistics only solves *part* of the problem. Remember that we started all this with the concern that Berkeley's admissions processes might be unfairly biased against female applicants. When we looked at the "aggregated" data, it did seem like the university was discriminating against women, but when we "disaggregate" and looked at the individual behaviour of all the departments, it turned out that the actual departments were, if anything, slightly biased in favour of women. The gender bias in total admissions was caused by the fact that women tended to self-select for harder departments. From a legal perspective, that would probably put the university in the clear. Postgraduate admissions are determined at the level of the individual department, and there are good reasons to do that. At the level of individual departments the decisions are more or less unbiased (the weak bias in favour of females at that level is small, and not consistent across departments). Since the university can't dictate which departments people choose to apply to, and the decision making takes place at the level of the department it can hardly be held accountable for any biases that those choices produce. --->

```{r}
#| label: fig-fig1-1
#| fig-align: left
#| fig-width: 100
#| fig-cap: 1973年柏克萊大學招生數據，取自 @Bickel1975 的圖1。圖中85個點分別代表至少接受一位女性申請入學的學系，依不分性別錄取率與女性申請入學比例繪圖。圓圈代表申請者超過40人的學系；圓圈面積代表該系申請人數佔全校申請人數的比例。十字代表申請者未達40人的學系。
knitr::include_graphics("images/fig1-1.png")
```

這是一開始我用輕鬆閒話介紹這個案例的真正原由，但故事沒這麼簡單，對吧？畢竟，如果從社會學和心理學的角度來看這個問題，我們更想知道*為什麼*各系申請者有這麼大的性別差異。為什麼工程科學系的男性申請者比女性多，而英語系則是相反呢？為什麼那些女性申請者較多的科系，錄取率比男性申請者較多的系別低呢？為什麽女性申請人數較多的科系錄取率偏低，而男性申請人數較多科系錄取率卻偏高？即使每個科系取才程序都是公平的，但這是否也是一種性別偏見？也許是吧。我們可以探討為何多數男生想唸“硬科學”領域的系所，而女生大都偏好“人文”領域。我們還能探討為何人文領域系所錄取率低？是因為政府部門給的補助不夠多嗎？例如博士級職缺與政府能給的專案補助經費額度有關。這些都是造成性別偏誤的條件嗎？還是人文領域的價值並未被重視？如果政府官員都覺得人文領域只是“沒什麼用處的小玩意”，動輒刪減相關經費。這樣是不是一種*公然的*性別歧視？至此討論的各種問題，都超出統計能解決的範圍，不過都能形成有意義的研究專案。若是你想了解造成性別歧視的整體結構因果關係，可能要"聚合"與“分解”的資料都要檢視。若是只想探討柏克萊校內負責招生的各級部門如何決策，只要檢討“分解”的資料就行。

<!---That was the basis for my somewhat glib remarks earlier, but that's not exactly the whole story, is it? After all, if we're interested in this from a more sociological and psychological perspective, we might want to ask *why* there are such strong gender differences in applications. Why do males tend to apply to engineering more often than females, and why is this reversed for the English department? And why is it the case that the departments that tend to have a female-application bias tend to have lower overall admission rates than those departments that have a male-application bias? Might this not still reflect a gender bias, even though every single department is itself unbiased? It might. Suppose, hypothetically, that males preferred to apply to "hard sciences" and females prefer "humanities". And suppose further that the reason for why the humanities departments have low admission rates is because the government doesn't want to fund the humanities (Ph.D. places, for instance, are often tied to government funded research projects). Does that constitute a gender bias? Or just an unenlightened view of the value of the humanities? What if someone at a high level in the government cut the humanities funds because they felt that the humanities are "useless chick stuff". That seems pretty blatantly gender biased. None of this falls within the purview of statistics, but it matters to the research project. If you're interested in the overall structural effects of subtle gender biases, then you probably want to look at both the aggregated and disaggregated data. If you're interested in the decision making process at Berkeley itself then you're probably only interested in the disaggregated data.That was the basis for my somewhat glib remarks earlier, but that's not exactly the whole story, is it? After all, if we're interested in this from a more sociological and psychological perspective, we might want to ask why there are such strong gender differences in applications. Why do males tend to apply to engineering more often than females, and why is this reversed for the English department? And why is it the case that the departments that tend to have a female-application bias tend to have lower overall admission rates than those departments that have a male-application bias? Might this not still reflect a gender bias, even though every single department is itself unbiased? It might. Suppose, hypothetically, that males preferred to apply to "hard sciences" and females prefer "humanities". And suppose further that the reason for why the humanities departments have low admission rates is because the government doesn't want to fund the humanities (Ph.D. places, for instance, are often tied to government funded research projects). Does that constitute a gender bias? Or just an unenlightened view of the value of the humanities? What if someone at a high level in the government cut the humanities funds because they felt that the humanities are "useless chick stuff". That seems pretty *blatantly* gender biased. None of this falls within the purview of statistics, but it matters to the research project. If you're interested in the overall structural effects of subtle gender biases, then you probably want to look at *both* the aggregated and disaggregated data. If you're interested in the decision making process at Berkeley itself then you're probably only interested in the disaggregated data.--->

簡而言之，有很多重要問題是無法只靠統計數據回答的，但是分析和解釋數據對於回答這些問題有相當巨大的作用。這就是為什麼你應該把統計學當成解析數據的工具，因為正好符合心理學等領域的需要。即使統計是一個非常好用的工具，人類在獲得謹慎思考的道路上並沒有捷徑。


<!---In short there are a lot of critical questions that you can't answer with statistics, but the answers to those questions will have a huge impact on how you analyse and interpret data. And this is the reason why you should always think of statistics as a tool to help you learn about your data. No more and no less. It's a powerful tool to that end, but there's no substitute for careful thought.--->

## 心理學中的統計

希望前面的討論能夠清楚解釋，為何各種科學領域都要使用統計。不過你應該還是會質疑學習心理學為何要學習統計，也會納悶為何許多心理學課程內容都與統計有關。以下是我常聽到來自學生的質疑，以及我的回應...

<!---I hope that the discussion above helped explain why science in general is so focused on statistics. But I'm guessing that you have a lot more questions about what role statistics plays in psychology, and specifically why psychology classes always devote so many lectures to stats. So here's my attempt to answer a few of them... --->

**為什麼學習心理學要學這麼多統計？**

<!---**Why does psychology have so much statistics?**--->

坦白說，有好幾個原因，其中有些原因比較值得談。最重要的原因是心理學是一門統計科學。我的意思是，我們研究的「對象」是人--真實的人是複雜的、美妙的、混亂的、還有偏激的人總令人憤怒。物理學研究的「對象」包括電子等物體，雖然物理學問題也有各種複雜的情況，但是電子沒有自己的思想。它們沒有個人意見，電子之間沒有奇怪而且任意的差異，在實驗中不會感到無聊，不會對實驗者發脾氣，然後故意搞爛實驗（我沒有做過這樣的事情唷！）。從基本面來說，心理學比物理學更難研究[^01-why-do-we-learn-statistics-7]。所以說，我們以心理學家的身份教你統計學，是因為你需要比物理學家更會掌握統計學。物理學裡有句老生常談，意思是"如果你的實驗要用到統計學，那應該要設計一個更好的實驗"。他們確實有底氣這樣說，因為物理學研究對象的混亂程度與社會科學家面對的相比，是令人妒恨的簡單。而且不只是心理學。大多數社會科學都非常依賴統計學。不是因為心理學家是糟糕的實驗設計者，而是因為心理學面對的多數問題很難只靠實驗設計解決。學習統計學是因為你真的真的需要它。

[^01-why-do-we-learn-statistics-7]: 這也許可以解釋為什麼物理學作為一門科學，比心理學略微先進。<!---Which might explain why physics is just a teensy bit further advanced as a science than we are.--->

<!---To be perfectly honest, there's a few different reasons, some of which are better than others. The most important reason is that psychology is a statistical science. What I mean by that is that the "things" that we study are *people*. Real, complicated, gloriously messy, infuriatingly perverse people. The "things" of physics include objects like electrons, and while there are all sorts of complexities that arise in physics, electrons don't have minds of their own. They don't have opinions, they don't differ from each other in weird and arbitrary ways, they don't get bored in the middle of an experiment, and they don't get angry at the experimenter and then deliberately try to sabotage the data set (not that I've ever done that!). At a fundamental level psychology is harder than physics.[^why-do-we-learn-statistics-5] Basically, we teach statistics to you as psychologists because you need to be better at stats than physicists. There's actually a saying used sometimes in physics, to the effect that "if your experiment needs statistics, you should have done a better experiment". They have the luxury of being able to say that because their objects of study are pathetically simple in comparison to the vast mess that confronts social scientists. And it's not just psychology. Most social sciences are desperately reliant on statistics. Not because we're bad experimenters, but because we've picked a harder problem to solve. We teach you stats because you really, really need it.--->

**不能將統計外包給別人做嗎？**

<!---**Can't someone else do the statistics?**--->

在某些情況是可以這樣，但不能全部都交給別人做。你確實不必要成為一名受過完整訓練的統計學家，也可以研究心理學，但是你需要具備一定的統計能力。在我看來，有三個原因，每個心理學研究者都應該具備基本統計能力：

<!---To some extent, but not completely. It's true that you don't need to become a fully trained statistician just to do psychology, but you do need to reach a certain level of statistical competence. In my view, there's three reasons that every psychological researcher ought to be able to do basic statistics:--->

-   首先是最基本的原因：統計學與研究設計密不可分。如果你想成為設計心理學研究的專家，你至少需要了解統計學的基礎。(譯註：[第2章](docs/02-A-brief-introduction-to-research-design.html)就是談研究設計)
-   其次，如果你想成為研究心理學的專家，那麼你就需要有能夠讀懂心理學文獻的能力，對吧？但是幾乎每篇心理學論文都有報告統計分析結果。如果你真的想徹底搞懂心理學，你就需要理解報告作者對資料做了什麼分析。也就是說你需要了解一定程度的統計學。
-   第三，依靠別人做統計學有一個很實際問題：統計分析是件**價格昂貴的工作**。如果你曾經無聊到去查詢澳洲政府制定的大學學費標準，會發現一件有趣的事情：統計學被指定為"國家優先"項目，因此學費比任何其他學科都低得多。這是因為社會各界都需要統計學專家的協助。從心理學研究者的立場來看，我們面對的是供給遠少於需求的賣方市場！幾乎任何一個心理學研究室都能看到相同的殘酷現實，就是沒有足夠經費聘請統計專家。因此，經濟現實逼迫心理學家必須自立自強。

除此之外，這些原因不只適用於從事研究的人員。如果你想成為一名應用取向的心理學家，為了掌握最新的研究進展，能夠獨立閱讀充滿各種統計報告的科學文獻也有助職涯發展。

<!---
-   Firstly, there's the fundamental reason: statistics is deeply intertwined with research design. If you want to be good at designing psychological studies, you need to at the very least understand the basics of stats.
-   Secondly, if you want to be good at the psychological side of the research, then you need to be able to understand the psychological literature, right? But almost every paper in the psychological literature reports the results of statistical analyses. So if you really want to understand the psychology, you need to be able to understand what other people did with their data. And that means understanding a certain amount of statistics.
-   Thirdly, there's a big practical problem with being dependent on other people to do all your statistics: statistical analysis is *expensive*. If you ever get bored and want to look up how much the Australian government charges for university fees, you'll notice something interesting: statistics is designated as a "national priority" category, and so the fees are much, much lower than for any other area of study. This is because there's a massive shortage of statisticians out there. So, from your perspective as a psychological researcher, the laws of supply and demand aren't exactly on your side here! As a result, in almost any real life situation where you want to do psychological research, the cruel facts will be that you don't have enough money to afford a statistician. So the economics of the situation mean that you have to be pretty self-sufficient.

Note that a lot of these reasons generalise beyond researchers. If you want to be a practicing psychologist and stay on top of the field, it helps to be able to read the scientific literature, which relies pretty heavily on statistics.

--->

**我不打算從事與心理學有關的工作、研究或臨床實務。我還需要學嗎？**

<!---**I don't care about jobs, research, or clinical work. Do I need statistics?**--->

好吧，你快要難倒我了。總而言之，我相信統計學對你還是很重要的。對包括你在內的所有現代人類來說，統計學是很重要的基本知識。在21世紀的今天，隨處都是資料。老實說，今天要維持自已活得像現代人，基本的統計知識已經是必備生存工具了！下一節我繼續說給你聽。

<!---Okay, now you're just messing with me. Still, I think it should matter to you too. Statistics should matter to you in the same way that statistics should matter to *everyone*. We live in the 21st century, and data are *everywhere*. Frankly, given the world in which we live these days, a basic knowledge of statistics is pretty damn close to a survival tool! Which is the topic of the next section.--->

## 日常生活中的統計

> *"We are drowning in information,\
> *but we are starved for knowledge"\
> - Various authors, original probably John Naisbitt

當我撰寫統計學講義時，我從 ABC 新聞網站找了 20 篇當時最新的新聞報導。我判斷其中 8 篇文字內容有提到統計資訊，不過有 6 篇報導內容有誤。若你想知道有什麼錯誤，最常見的錯誤是沒有報告基礎數據（例如，報導提到某個情況能觀察到 5％的人具有某種特徵 ，但沒有說明找了多少人總計出這個百分比！）。我想說的不是記者的統計素養很糟糕（雖然多數記者的統計知識真的很糟糕），而是基本的統計知識真的非常有幫助，可以幫助你瞭解別人表達的錯誤，還有是不是隨便拿些數據製造謠言(**譯注**：本書翻譯工程始於2022年末，有經歷疫情的同學應該對這段時間的各種不實疫情報導有感受。)。事實上，充實統計知識後，為個人帶來的最大一種改變，就是讓你更常對報紙和網路的資訊感到憤怒。之後在 @sec-Descriptive-statistics 的 @sec-A-real-life-example ，你會看到實際例子。本書的後續更新版本，會繼續收集更多類似的錯誤報導。

```{=html}
<!---
When I started writing up my lecture notes I took the 20 most recent news articles posted to the ABC news website. Of those 20 articles, it turned out that 8 of them involved a discussion of something that I would call a statistical topic and 6 of those made a mistake. The most common error, if you're curious, was failing to report baseline data (e.g., the article mentions that 5% of people in situation X have some characteristic Y, but doesn't say how common the characteristic is for everyone else!). The point I'm trying to make here isn't that journalists are bad at statistics (though they almost always are), it's that a basic knowledge of statistics is very helpful for trying to figure out when someone else is either making a mistake or even lying to you. In fact, one of the biggest things that a knowledge of statistics does to you is cause you to get angry at the newspaper or the internet on a far more frequent basis. You can find a good example of this in @sec-A-real-life-example in @sec-Descriptive-statistics. In later versions of this book I'll try to include more anecdotes along those lines.--->
```
## 統計以外的研究方法

到這裡為止，討論的研究方法大部分都是與統計學有關，你有理由相信這門課只關心和統計學有關的研究方法主題。坦白說，這麼認為並非完全錯誤，但是研究方法是比統計學更廣泛的課題。大多數研究方法課程都會涵蓋研究設計相關的實用主題，特別是進行與人類有關的研究會遇到的問題。但是，約有 99% 的學生害怕課程中統計的部分。這本書之所以著重統計學，是希望我能讓你相信統計學很重要，更重要的是，統計並不可怕。這也就是為什麼，大多數初級研究方法課程都會提到統計學。但是不是因為教師都是壞蛋，其實恰恰相反。各種入門課程之所以重視統計學，是因為同學們需要在學習各種研究方法之前，要充分了解統計學。為什麼？因為你在任何課程的所有作業都要靠統計方法才能完成，比起其他方法學工具，作業中的統計使用頻率經常居冠。心理系的作業通常不需要你從頭開始設計自己的研究（若要從頭開始，就需要了解很多關於研究設計的知識），而是要你分析和解釋別人設計的研究所收集的數據（這是你需要統計學的狀況）。就作業安排的意義來說，為了幫助你在其他課程學得好，統計學是需要優先學習的課程。

但是要注意，"優先"與"重要"是不同的概念 - 雖然兩者都是關鍵。我想強調的是研究設計和數據分析同樣重要，本書確實花了相當多篇幅在這些主題。然而，雖然統計學具有某種普遍性，提供了一套對許多類型的心理學研究都有用的核心工具，但是不是所有研究方法都會運用統計。有些研究設計的一般原則是每個研究者都應該注意，但是許多研究設計非常特殊，並且只有在特定研究領域才會使用。基礎統計和研究方法課程考慮到細節的重要性，不一定會介紹這些特殊的研究設計。

```{=html}
<!---
So far, most of what I've talked about is statistics, and so you'd be forgiven for thinking that statistics is all I care about in life. To be fair, you wouldn't be far wrong, but research methodology is a broader concept than statistics. So most research methods courses will cover a lot of topics that relate much more to the pragmatics of research design, and in particular the issues that you encounter when trying to do research with humans. However, about 99% of student fears relate to the statistics part of the course, so I've focused on the stats in this discussion, and hopefully I've convinced you that statistics matters, and more importantly, that it's not to be feared. That being said, it's pretty typical for introductory research methods classes to be very stats-heavy. This is not (usually) because the lecturers are evil people. Quite the contrary, in fact. Introductory classes focus a lot on the statistics because you almost always find yourself needing statistics before you need the other research methods training. Why? Because almost all of your assignments in other classes will rely on statistical training, to a much greater extent than they rely on other methodological tools. It's not common for undergraduate assignments to require you to design your own study from the ground up (in which case you would need to know a lot about research design), but it *is* common for assignments to ask you to analyse and interpret data that were collected in a study that someone else designed (in which case you need statistics). In that sense, from the perspective of allowing you to do well in all your other classes, the statistics is more urgent.

But note that "urgent" is different from "important" -- they both matter. I really do want to stress that research design is just as important as data analysis, and this book does spend a fair amount of time on it. However, while statistics has a kind of universality, and provides a set of core tools that are useful for most types of psychological research, the research methods side isn't quite so universal. There are some general principles that everyone should think about, but a lot of research design is very idiosyncratic, and is specific to the area of research that you want to engage in. To the extent that it's the details that matter, those details don't usually show up in an introductory stats and research methods class.
--->
```
