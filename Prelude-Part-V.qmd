# 線性模型的學習取向 {.unnumbered}

在進入學習統計方法的各章節之前，我(譯者)想要向同學們介紹另一份由丹麥奧爾堡大學(Aalborg University)溝通與心理學系(Department of Communication and Psychology)的Jonas Lindeløv教授編寫的教程**基礎統計方法的線性模型學習取向**[^V-1]。在 決定翻譯本書之前，我一直有如何統整推論統計方法學習課表的苦惱。見到Lindeløv的教程，還有採用jamovi與JASP試編教材之後，發覺這是一套值得華文世界的學生們認識的教材。在Lindeløv的原版教程發表後不到一年來，就由世界各地有志一同的教師翻譯成各國語言的版本，簡体中文版已由著名的網路統計知識交流學習論壇[統計之都](https://cosx.org/)的網友翻譯
完成[^V-2]。由於簡体中文與繁體中文的統計學術語有別，而且Lindeløv的教程是以R語言為例，因此藉由翻譯這本**用jamovi上手統計學**，我將原來的第五部分章節重新排列，改成如同Lindeløv教程一樣的順序，並在適當的段落，置入Lindeløv教程的說明。在每一章的範例，都會附上一份以線性模型示範的omv檔。從 @sec-Correlation-and-linear-regression 到 @sec-Categorical-data-analysis 標示示範檔案的部分，我都會在增加的譯註內置入取得線性模型版的示範檔案，各章示範檔案的說明，都會集中於此。同學可根據學習進度，到了相關的部分，再回到這裡取得示範檔案及閱讀說明。


## 教程前言 {-}

> 本節改編自簡体中文版[^V-2]

大部分常見的統計檢定方法（t 檢定、相關性檢定、變異數分析（ANOVA）、卡方檢定等），本質都是線性模型的一種特例或者是非常逼近的模型。這種優雅的簡潔性意味著我們並不需要掌握太多的技巧就能學習。具體來說，所有模型的來源都是多數學生在高中時期就學過的一元一次線性模型：$y = a \cdot x + b$ 。然而，很多基礎統計課程是把各種檢定方法分開教，給學生和老師們增加了很多不必要的麻煩。在學習每一個檢定方法的基本假設時，如果不是從線性模型切入，而是每個檢定方法都死記硬背，這讓學習的複雜度倍增。因此，我認為先教線性模型，然後對線性模型的一些特殊形式更改名稱是一種優秀的教學策略，這有助於更深刻地理解假設檢定。線性模型在次數主義學派、貝氏學派和基於置換的U檢定的統計推論方法之間是互通的，對初學者而言，從線性模型開始比從認識什麼是*p*值、型I錯誤、貝氏因子或其它術語更為友好。

在入門課程教授到*無母數檢定*的時候，可以避開**自我欺騙**的手段，直接告訴學生無母數檢定其實就是參數本質是次序(rank)的檢定方法。對學生來說，接受向量的概念比相信你可以神奇地放棄各種假設好得多。實際上，在統計軟體如 JASP 裡，無母數檢定的貝氏等價模型就是使用潛在次序（Latent Rank）處理資料的。次數主義學派的無母數檢定在樣本量 N>15 的時非常準確。

<!---

（完成chapter 10~14的翻譯後，再回來整理）

## 教與學的建議 {#prelude-suggestions}

> 本節改編自簡体中文版[^V-2]

### 迴歸的基礎知識

1. 回憶高中學過的線性模型：$y = a \cdot x + b$，培養學生對斜率和截距的直覺。理解到這條公式能改寫成各種變項名稱。例如 `money = profit * time + starting_money`，或 $y = \beta_1x + \beta_2*1$，去除係數可寫成 `y ~ x + 1`。如果學生能接受的話，可以探索如何用[微分方程](https://magesblog.com/post/modelling-change)推道這些模型是，並了解 $y$ 是如何隨著 $x$ 的數值改變。
   
2. 擴展到多元迴歸模型。這部分有非常多可用的生活實例做為練習作業，讓這些概念很容易用直覺理解。加深同學如何使用這些簡潔的模型描述巨量資料集的印象。

3. 介紹如何將非數值型資料轉換為次序尺度，並進行各種練習。
   
4. 以三種前提假設規劃教學：資料的獨立性，殘差分佈的常態性，以及集中量數平方差的同質性（homoscedasticity）。
    
5. 參數的信賴（confidence）與可信（credible）區間。說明為何很難計算極大似然估計值（Maximum-Likelihood estimate），因此區間估計更為重要。
    
6. 對以上簡單的迴歸模型，簡要地認識 $R^2$。順便提及一下，這就是 [Pearson 和 Spearman 相關係數](#correlation)。

### 特殊情況 1：一個或兩個平均值（t 檢定、Wilcoxon 檢定、Mann-Whitney 檢定）

1. **單一平均值**：當只有一個變項 x 的時候，迴歸模型簡化為 $y = b$。如果 $y$ 不是連續變項，可以轉換為等比尺度。應用模型假設（只有一個 $x$，因此這些檢定方法不適用平方差的同質性）。順便提及一下，這些僅有截距的模型又名為*單一樣本 t 檢定*和 *Wilcoxon 符號次序檢定*。
    
2. **分組平均值**：如果我們把兩個變項放在 x 軸，兩者平均值的差異就是斜率。這樣就能用如同瑞士刀的線性模型來解決！應用模型的假設條件，檢查兩組平均值的平方差是否相等，相等即符合平方差的同質性。如此就能稱這個模型為**獨立 t 檢定**。試著創造一些虛擬資料，做一些練習，也許還能加上 Welch 檢定，再加上次序轉換，就能變成 Mann-Whitney U 檢定。
    
3. **相依樣本**：這種模型違反了獨立性假設。通過計算配對組的資料差異值，模型就會與 $y = b$ 等價，儘管這些方法另有專有名詞：**相依 t 檢定**和 **Wilcoxon 配對組檢定**。

### 特殊情況 2：三個或多個均值（方差分析（ANOVA））

1. **對類別轉化後的[示性變量](#dummy)：**類別的每一個取值範圍對應的迴歸係數，是如何通過乘以一個二元（binary）示性變量，來對每個取值範圍對應的截距來進行建模的。（How one regression coefficient for each level of a factor models an intercept for each level when multiplied by a binary indicator.）這只是我們為了使資料能用線性模型建模，而擴展了在 2.1 所做的事情而已。
    
2. **一個變量的均值：**[單因素方差分析（one-way ANOVA）](#anova1).
    
3. **兩個變量的均值：**[雙因素方差分析（two-way ANOVA）](#anova2).

### 特殊情況 3：三個或多個比率（卡方檢驗）

1. **對數變換：**通過對數變換，把“多元乘法”模型轉化成線性模型，從而可以對比率進行建模。關於對數線性模型和對比率的卡方檢驗的等價性，可以查閱這個非常優秀的介紹。此外，還需要介紹 (log-) odds ratio（一般翻譯為“比值比”或“優勢比”）。當“多元乘法”模型使用對數變換轉化為“加法”模型之後，我們僅加上來自 3.1 的示性變量技巧，就會在接下來發現模型等價於 3.2 和 3.3 的方差分析----除了係數的解釋發生了變化。

2. 單變量的比率：擬合優度檢驗.

3. 雙變量的比率：列聯表.

### 假設檢定

1. **視為模型比較的假設檢定：**假設檢驗用於全模型和某個參數固定了（通常為 0，也即從模型中去除）的模型進行比較，而不是對模型進行估計。比如說，在 [t 檢驗](#t2) 把兩個均值之一固定為零之後，我們探究單獨一個均值（[單樣本 t 檢驗](#t1)）對兩個組的數據的解釋程度。如果解釋程度比較好，那麼我們更傾向於這個單均值模型，而不是雙均值模型，因為前者更為簡單。假設檢驗其實是比較多個線性模型，來獲得更多的定量描述。單參數的檢驗，假設檢驗包含的信息更少。但是，同時對多個參數（如方差分析的類別變量）進行檢驗的話，模型比較就會變得沒有價值了。

2. **似然比：**似然比是一把瑞士軍刀，它適用於單樣本 t 檢驗到 GLMM 等情況。BIC 對模型複雜度進行懲罰。還有，加上先驗（prior）的話，你就能得到貝葉斯因子（Bayes Factor）。一個工具，就能解決所有問題。我在上文方差分析中使用了似然比檢驗。

--->

## 線型模型版本示範集合  {-}

### 相闗與線性迴歸 {-}




### 多因子變異數分析 {-}


------------------------------------------------------------------------


[^V-1]: [https://lindeloev.github.io/tests-as-linear/](https://lindeloev.github.io/tests-as-linear/)

[^V-2]: [https://cosx.org/2019/09/common-tests-as-linear-models/](https://cosx.org/2019/09/common-tests-as-linear-models/)
