<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-Hans" xml:lang="zh-Hans"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.427">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>用jamovi上手統計學 - 9&nbsp; 假設檢定</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Prelude-Part-V.html" rel="next">
<link href="./08-Estimating-unknown-quantities-from-a-sample.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "没有结果",
    "search-matching-documents-text": "匹配的文档",
    "search-copy-link-title": "复制搜索链接",
    "search-hide-matches-text": "隐藏其它匹配结果",
    "search-more-match-text": "更多匹配结果",
    "search-more-matches-text": "更多匹配结果",
    "search-clear-button-title": "清除",
    "search-detached-cancel-button-title": "取消",
    "search-submit-button-title": "提交",
    "search-label": "搜索"
  }
}</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['S$','S$'], ["\\[","\\]"] ]
      processEscapes: true
    }
  });
</script>
    

<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="用jamovi上手統計學 - 9&nbsp; 假設檢定">
<meta property="og:description" content="">
<meta property="og:image" content="https://scgeeker.github.io/lsj-book-zh_tw/images/tbl-9-1.png">
<meta property="og:site-name" content="用jamovi上手統計學">
<meta property="og:image:height" content="15">
<meta property="og:image:width" content="50">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="切换侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Prelude-Part-IV.html">統計理論</a></li><li class="breadcrumb-item"><a href="./09-Hypothesis-testing.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">假設檢定</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="切换侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">用jamovi上手統計學</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/SCgeeker/lsj-book-zh_tw/" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./用jamovi上手統計學.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="切换深色模式"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="切换阅读器模式">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="搜索"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">&nbsp;</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">前言</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">新手須知</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-Why-do-we-learn-statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">為什麼要學習統計</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-A-brief-introduction-to-research-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">研究設計入門</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">jamovi初體驗</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-Getting-started-with-jamovi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">與jamovi的第一次接觸</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">資料處理</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-Descriptive-statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">描述統計</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-Drawing-graphs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">繪製統計圖</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-Pragmatic-matters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">實務課題</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">統計理論</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Prelude-Part-IV.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">中場故事</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-Introduction-to-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">機率入門</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-Estimating-unknown-quantities-from-a-sample.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">運用樣本估計未知量數</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-Hypothesis-testing.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">假設檢定</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">統計方法</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Prelude-Part-V.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">線性模型的學習取向</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-Categorical-data-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">類別資料分析</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-Comparing-two-means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">比較單一與兩組平均值</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-Correlation-and-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">相關與線性迴歸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-Comparing-several-means-one-way-ANOVA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">比較多組平均值(單因子變異數分析)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-Factorial-ANOVA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">多因子變異數分析</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-Factor-Analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">因素分析</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
 <span class="menu-text">貝氏統計</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="切換部分">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-Bayesian-statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">貝氏統計</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Epilogue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">後記</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./References.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">參考資料</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目录</h2>
   
  <ul>
  <li><a href="#假設的層次" id="toc-假設的層次" class="nav-link active" data-scroll-target="#假設的層次"><span class="header-section-number">9.1</span> 假設的層次</a>
  <ul class="collapse">
  <li><a href="#研究假設還是統計假設" id="toc-研究假設還是統計假設" class="nav-link" data-scroll-target="#研究假設還是統計假設"><span class="header-section-number">9.1.1</span> 研究假設還是統計假設</a></li>
  <li><a href="#虛無假設與對立假設" id="toc-虛無假設與對立假設" class="nav-link" data-scroll-target="#虛無假設與對立假設"><span class="header-section-number">9.1.2</span> 虛無假設與對立假設</a></li>
  </ul></li>
  <li><a href="#兩種決策失誤" id="toc-兩種決策失誤" class="nav-link" data-scroll-target="#兩種決策失誤"><span class="header-section-number">9.2</span> 兩種決策失誤</a></li>
  <li><a href="#運用取樣分佈檢測統計值" id="toc-運用取樣分佈檢測統計值" class="nav-link" data-scroll-target="#運用取樣分佈檢測統計值"><span class="header-section-number">9.3</span> 運用取樣分佈檢測統計值</a></li>
  <li><a href="#sec-Hypothesis-testing-decision" id="toc-sec-Hypothesis-testing-decision" class="nav-link" data-scroll-target="#sec-Hypothesis-testing-decision"><span class="header-section-number">9.4</span> 統計推論的決策要素</a>
  <ul class="collapse">
  <li><a href="#棄卻域與臨界值" id="toc-棄卻域與臨界值" class="nav-link" data-scroll-target="#棄卻域與臨界值"><span class="header-section-number">9.4.1</span> 棄卻域與臨界值</a></li>
  <li><a href="#小心使用統計顯著" id="toc-小心使用統計顯著" class="nav-link" data-scroll-target="#小心使用統計顯著"><span class="header-section-number">9.4.2</span> 小心使用統計“顯著”</a></li>
  <li><a href="#sec-The-difference-between-one-sided-and-two-sided-tests" id="toc-sec-The-difference-between-one-sided-and-two-sided-tests" class="nav-link" data-scroll-target="#sec-The-difference-between-one-sided-and-two-sided-tests"><span class="header-section-number">9.4.3</span> 單側與雙側檢定的不同</a></li>
  </ul></li>
  <li><a href="#sec-The-p-value-of-a-test" id="toc-sec-The-p-value-of-a-test" class="nav-link" data-scroll-target="#sec-The-p-value-of-a-test"><span class="header-section-number">9.5</span> 統計檢定的<em>p</em>值</a>
  <ul class="collapse">
  <li><a href="#運用p值做決策的簡單理由" id="toc-運用p值做決策的簡單理由" class="nav-link" data-scroll-target="#運用p值做決策的簡單理由"><span class="header-section-number">9.5.1</span> 運用<em>p</em>值做決策的簡單理由</a></li>
  <li><a href="#獲得極端資料的機率" id="toc-獲得極端資料的機率" class="nav-link" data-scroll-target="#獲得極端資料的機率"><span class="header-section-number">9.5.2</span> 獲得極端資料的機率</a></li>
  <li><a href="#常見的錯誤解讀" id="toc-常見的錯誤解讀" class="nav-link" data-scroll-target="#常見的錯誤解讀"><span class="header-section-number">9.5.3</span> 常見的錯誤解讀</a></li>
  </ul></li>
  <li><a href="#假設檢定的報告格式" id="toc-假設檢定的報告格式" class="nav-link" data-scroll-target="#假設檢定的報告格式"><span class="header-section-number">9.6</span> 假設檢定的報告格式</a>
  <ul class="collapse">
  <li><a href="#一些爭議" id="toc-一些爭議" class="nav-link" data-scroll-target="#一些爭議"><span class="header-section-number">9.6.1</span> 一些爭議</a></li>
  <li><a href="#兩種實務建議" id="toc-兩種實務建議" class="nav-link" data-scroll-target="#兩種實務建議"><span class="header-section-number">9.6.2</span> 兩種實務建議</a></li>
  </ul></li>
  <li><a href="#假設檢定實作須知" id="toc-假設檢定實作須知" class="nav-link" data-scroll-target="#假設檢定實作須知"><span class="header-section-number">9.7</span> 假設檢定實作須知</a></li>
  <li><a href="#sec-Effect-size-sample-size-and-power" id="toc-sec-Effect-size-sample-size-and-power" class="nav-link" data-scroll-target="#sec-Effect-size-sample-size-and-power"><span class="header-section-number">9.8</span> 效果量、樣本量、考驗力</a>
  <ul class="collapse">
  <li><a href="#圖解考驗力" id="toc-圖解考驗力" class="nav-link" data-scroll-target="#圖解考驗力"><span class="header-section-number">9.8.1</span> 圖解考驗力</a></li>
  <li><a href="#估計考驗力的功用" id="toc-估計考驗力的功用" class="nav-link" data-scroll-target="#估計考驗力的功用"><span class="header-section-number">9.8.2</span> 估計考驗力的功用</a></li>
  <li><a href="#增加研究考驗力的方案" id="toc-增加研究考驗力的方案" class="nav-link" data-scroll-target="#增加研究考驗力的方案"><span class="header-section-number">9.8.3</span> 增加研究考驗力的方案</a></li>
  </ul></li>
  <li><a href="#值得繼續學習的主題" id="toc-值得繼續學習的主題" class="nav-link" data-scroll-target="#值得繼續學習的主題"><span class="header-section-number">9.9</span> 值得繼續學習的主題</a>
  <ul class="collapse">
  <li><a href="#尼曼與費雪" id="toc-尼曼與費雪" class="nav-link" data-scroll-target="#尼曼與費雪"><span class="header-section-number">9.9.1</span> 尼曼與費雪</a></li>
  <li><a href="#貝氏統計與次數主義統計" id="toc-貝氏統計與次數主義統計" class="nav-link" data-scroll-target="#貝氏統計與次數主義統計"><span class="header-section-number">9.9.2</span> 貝氏統計與次數主義統計</a></li>
  <li><a href="#決策陷阱" id="toc-決策陷阱" class="nav-link" data-scroll-target="#決策陷阱"><span class="header-section-number">9.9.3</span> 決策陷阱</a></li>
  </ul></li>
  <li><a href="#本章小結" id="toc-本章小結" class="nav-link" data-scroll-target="#本章小結"><span class="header-section-number">9.10</span> 本章小結</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/SCgeeker/lsj-book-zh_tw/edit/main/09-Hypothesis-testing.qmd" class="toc-action">编辑该页面</a></p><p><a href="https://github.com/SCgeeker/lsj-book-zh_tw/issues/new" class="toc-action">报告问题</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header">
<h1 class="title display-7"><span id="sec-Hypothesis-testing" class="quarto-section-identifier"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">假設檢定</span></span></h1>

</header>

<blockquote class="blockquote">
<p>歸納的過程就是假設一個能夠與我們的經驗調和的最簡單的法則。這個過程沒有邏輯基礎，只有心理基礎。很明顯，並沒有理由相信最簡單的事情就一定會發生。認為明天太陽會升起只是一個假說，這意味著我們不知道太陽是否會升起。 –路德維希·維根斯坦 <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</blockquote>
<p>前一章我們學習了推論統計的兩個“大主題”之一——<strong>估計</strong>。這一章要學習另一個大主題——<strong>假設檢定</strong>。從最抽象的角度來看，假設檢定實際上是一個非常簡單的概念。研究人員對世界有一些理論，想要確定數據是否真正支持這些理論。然而，細節非常麻煩，多數學生會發現假設檢定的理論是統計學中最令人沮喪的部分。這一章的結構如下。首先，我將詳細描述假設檢定的運作過程，我會使用一個簡單的範例來展示如何”建立”假設檢定。在這個過程中，我會盡量避免過於教條主義，並專注於解釋檢定程序的基本邏輯。<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>之後，我會花一些時間談論各種環繞假設檢定理論的教條、規則和異端邪說。</p>
<!--- > The process of induction is the process of assuming the simplest law that can be made to harmonize with our experience. This process, however, has no logical foundation but only a psychological one. It is clear that there are no grounds for believing that the simplest course of events will really happen. It is an hypothesis that the sun will rise tomorrow: and this means that we do not know whether it will rise.\
> -- Ludwig Wittgenstein [^09-hypothesis-testing-1]

[^09-hypothesis-testing-1]: The quote comes from Wittgenstein's (1922) text, *Tractatus Logico-Philosphicus.* 

In the last chapter I discussed the ideas behind estimation, which is one of the two "big ideas" in inferential statistics. It's now time to turn our attention to the other big idea, which is *hypothesis testing*. In its most abstract form, hypothesis testing is really a very simple idea. The researcher has some theory about the world and wants to determine whether or not the data actually support that theory. However, the details are messy and most people find the theory of hypothesis testing to be the most frustrating part of statistics. The structure of the chapter is as follows. First, I'll describe how hypothesis testing works in a fair amount of detail, using a simple running example to show you how a hypothesis test is "built". I'll try to avoid being too dogmatic while doing so, and focus instead on the underlying logic of the testing procedure.[^09-hypothesis-testing-2] Afterwards, I'll spend a bit of time talking about the various dogmas, rules and heresies that surround the theory of hypothesis testing.

[^09-hypothesis-testing-2]: A technical note. The description below differs subtly from the standard description given in a lot of introductory texts. The orthodox theory of null hypothesis testing emerged from the work of Sir Ronald Fisher and Jerzy Neyman in the early 20th century; but Fisher and Neyman actually had very different views about how it should work. The standard treatment of hypothesis testing that most texts use is a hybrid of the two approaches. The treatment here is a little more Neyman-style than the orthodox view, especially as regards the meaning of the p-value.--->
<section id="假設的層次" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="假設的層次"><span class="header-section-number">9.1</span> 假設的層次</h2>
<p>我們從一個原作者虛構的狂想開始談吧：<em>我認為每個人活得夠老，都會向瘋狂的想法屈服。我這輩子真正想做的研究，將在我升任正教授的那一天開始，因為我在象牙塔中會受到終身職的保障，那天我總算能夠拋棄理智，完全投入那個最沒有成效的心理研究領域：證實人類有超感官知覺（ESP）。</em><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p><em>假如這一天終於來臨了，我要做的第一項研究是一項簡單的透視力測試實驗。每個參與者坐在桌子前，由實驗者向他展示一張卡片。這張卡片的一面是黑色的，另一面是白色的。實驗者把卡片放在桌子上，接著帶領參與者到隔壁房間。在實驗者與參與者離開後，第二位實驗者會隨機地把卡片翻到黑面或白面朝上，然後第二位實驗者到隔壁房間，詢問參與者現在卡片的那一面朝上。這個實驗的參與者只會進行一次測試，每個人只會看到一張卡片，只回答一個問題，而參與者在回答問題前都不會與知道正確答案的第二位實驗者接觸。因此，我的資料紀錄非常簡單：我問了N個人的問題，其中有 <span class="math inline">\(X\)</span> 個人給了正確的答案。為了具體說明，若是這次實驗我測試了100個人，其中有62個人回答正確。這會是一個令人驚訝的大數字，但是這個數字是否足夠讓我聲稱發現了ESP的證據呢？</em>這就是檢驗假設有無效用的情況。然而，在我們談論如何檢驗假設之前，我們需要明白要如何設定這項實驗的假設。</p>

<!--- Eventually we all succumb to madness. For me, that day will arrive once I'm finally promoted to full professor. Safely ensconced in my ivory tower, happily protected by tenure, I will finally be able to take leave of my senses (so to speak) and indulge in that most thoroughly unproductive line of psychological research, the search for extrasensory perception (ESP).[^09-hypothesis-testing-3] 

[^09-hypothesis-testing-3]: My apologies to anyone who actually believes in this stuff, but on my reading of the literature on ESP it's just not reasonable to think this is real. To be fair, though, some of the studies are rigorously designed, so it's actually an interesting area for thinking about psychological research design. And of course it's a free country so you can spend your own time and effort proving me wrong if you like, but I wouldn't think that's a terribly practical use of your intellect.

Let's suppose that this glorious day has come. My first study is a simple one in which I seek to test whether clairvoyance exists. Each participant sits down at a table and is shown a card by an experimenter. The card is black on one side and white on the other. The experimenter takes the card away and places it on a table in an adjacent room. The card is placed black side up or white side up completely at random, with the randomisation occurring only after the experimenter has left the room with the participant. A second experimenter comes in and asks the participant which side of the card is now facing upwards. It's purely a one-shot experiment. Each person sees only one card and gives only one answer, and at no stage is the participant actually in contact with someone who knows the right answer. My data set, therefore, is very simple. I have asked the question of N people and some number $X$ of these people have given the correct response. To make things concrete, let's suppose that I have tested $N = 100$ people and $X = 62$ of these got the answer right. A surprisingly large number, sure, but is it large enough for me to feel safe in claiming I've found evidence for ESP? This is the situation where hypothesis testing comes in useful. However, before we talk about how to test hypotheses, we need to be clear about what we mean by hypotheses.--->
<section id="研究假設還是統計假設" class="level3" data-number="9.1.1">
<h3 data-number="9.1.1" class="anchored" data-anchor-id="研究假設還是統計假設"><span class="header-section-number">9.1.1</span> 研究假設還是統計假設</h3>
<p>首先需要清楚區別的是研究假設和統計假設之間的差別。在我設想的ESP研究中，我的整體科學目標是證實人類有透視能力。在這樣的場景，我有一個清晰的研究目標：我希望發現ESP的證據。在其他場景，我的想法可能會比較中立，也就是我可能會說我的研究目標是確定人類是否有透視能力。無論如何描述我的目標，我想傳達給各位同學的基本觀點是，制定研究假設是提出一個實際的、可測試的科學主張。如果你是一名心理學家，那麼你的研究假設基本上是關於心理學構念的。以下任何一種案例都可說是研究假設：</p>
<ul>
<li><em>聆聽音樂會降低你對其他事物的注意力能力。</em>這是一種關於兩個有心理學意義的構念之間有因果關係的主張（<strong>聆聽音樂</strong>和注意力），因此這是一個非常合理的研究假設。</li>
<li><em>智力與個性有關。</em>和前一個一樣，這個假設主張兩個有心理學意義的構念之間存在關係性（<strong>智力</strong>和<strong>個性</strong>），但這個主張立埸比較弱：探討相關性而不是因果關係。</li>
<li><em>智力是訊息處理速度。</em>這個假設與前面兩個很不一樣。實際上這並不是一個因果關係或關聯性的假設，而是關於智力基本特性的本體論主張（我相當確定是這樣的）。通常來說，設計實驗測試像是“<span class="math inline">\(X\)</span>是否影響<span class="math inline">\(Y\)</span>？”，比回答“<span class="math inline">\(X\)</span>是什麼？”這樣的問題要容易得多。在實際情況通常是你會找到方法，測試基本特性所形成的關聯性假設。例如，如果我相信智力的本質是大腦中訊息處理速度，我就會設計實驗探討智力和訊息處理之間的關係。因此，大多數日常生活中想到的研究問題雖然都與本質有關，但是通常是基於好奇關於自然界本體論問題的更深層動機。</li>
</ul>
<p>請注意在真實的實驗室，我會設定幾個互相重疊的研究假設。儘管我設計ESP實驗的終極目標是測試“人類有ESP”這樣的本體論主張，但是實際操作會限制自己只測試目標更狹窄的假設，像是“某些人可以用透視‘看見’物體”。話雖如此，有一些看似目標明確的主張，在任何意義上都不算是合適的研究假設：</p>
<ul>
<li><em>愛情就像戰場。</em>這個假設過於模糊，無法進行測試。雖然研究假設可以有一定程度的模糊性，但是必須能夠將理論觀念具體化。也許我不夠有創造力，想不到能將這個假設轉化為具體研究設計的方式。如果真的有辦法，那麼應該不是科學的研究假設，而是一首流行歌曲。這並不是說這樣的假設不有趣，而是要指出許多人能想到的深刻問題都是屬於這種類別。也許有一天科學家能夠構建關於愛情的可測試理論，或者測試上帝是否存在等等。但是現在的我們還做不到，我不會指望看到一個令人滿意的科學方法來解決這些問題。</li>
<li><em>套套邏輯俱樂部的第一條規則就是套套邏輯俱樂部的第一條規則。</em>這是不具備任何實質意義的主張，儘管形式上是符合邏輯的。因為在任何自然狀態都不能提出與此主張相反的看法，我們會說這是一個不可證偽的假設，因此這樣的主張不屬於科學研究的領域。在科學研究，無論你想研究的問題是什麼，你提出的主張都必須有可能是錯誤的。</li>
<li><em>在我的實驗裡，較多的參與者會說‘是’，而不是‘否’。</em>這並不是一個有意義的研究假設，因為重點的是資料本身而非心理學問題（當然，除非真正要研究的問題是關於多數人是不是有回答“是”的偏好！）。實際上，這個假設看起來更像是一個統計假設而非研究假設。</li>
</ul>
<p>正如同學所見，有的研究假設的主張可能會有些混亂，不過都是各樣科學主張的一種。<strong>統計假設</strong>則不是一種主張。統計假設必須具有數學精確性，並且必須對資料的生成機制（也就是“母群”）的特徵提出具體的條件。即便如此，統計假設的內在意圖必須有與真正的研究假設有一個明確的關係！例如，在我的ESP研究中，我的研究假設是有些人能夠透視牆壁看到隔壁的物體。我要做的是將這樣的研究假設<em>對應</em>到產生資料的方法陳述。因此，現在我們考慮一下要如何表達這樣的陳述。我感興趣的實驗數值是 <span class="math inline">\(P(correct)\)</span>，也就是實驗參與者正確回答問題的<em>理論上為真但未知之機率</em>。讓我們使用希臘字母<span class="math inline">\(\theta\)</span>（theta）來表示這項機率。以下是四種不同的統計假設：</p>
<ul>
<li>如果ESP不存在，而我的實驗設計沒有偏誤，那麼參與者的回答只是猜測。因此，我應該期望有一半參與者的回答是正確的，所以我的統計假設是，回答正確的理論機率是 <span class="math inline">\(\theta=0.5\)</span>。</li>
<li>或者，假設ESP存在並且參與者真的能夠看到卡片。如果實驗結果真的是這樣，參與者回答的正確率會高於只是猜測，所以統計假設是 <span class="math inline">\(\theta &gt; 0.5\)</span>。</li>
<li>第三種可能是ESP確實存在，但是參與者並沒有意識到透視看到的物體顏色是相反的（好吧，這有些荒謬，但我們永遠無法知道）。如果是這樣的實驗結果，我會期望參與者回答的正確率會低於只是猜測。所以統計假設是 <span class="math inline">\(\theta &lt; 0.5\)</span>。</li>
<li>最後，如果人類確實有ESP，但是我不知道參與者是否看到了正確的顏色。在這種情況下，我只能期望參與者回答的正確率不等於0.5。所以統計假設是 <span class="math inline">\(\theta \neq 0.5\)</span>。</li>
</ul>
<p>以上例子都是合乎科學研究目標的統計假設，因為每條陳述都有定義母群參數，並且緊密扣連我的實驗目的。</p>
<p>我希望這些例子可以讓同學清楚了解，當研究者要構建一個統計假設檢定程序時，實際上要考慮兩種不同層次的假設。首先，研究者要有一個研究假設（關於心理學的主張），能對應到一個統計假設（關於數據生成母群的主張）。以我的ESP實驗來說，會像 <a href="#tbl-tab9-1">表格&nbsp;<span>9.1</span></a> 的表達。</p>

<!---The first distinction that you need to keep clear in your mind is between research hypotheses and statistical hypotheses. In my ESP study my overall scientific goal is to demonstrate that clairvoyance exists. In this situation I have a clear research goal: I am hoping to discover evidence for ESP. In other situations I might actually be a lot more neutral than that, so I might say that my research goal is to determine whether or not clairvoyance exists. Regardless of how I want to portray myself, the basic point that I'm trying to convey here is that a research hypothesis involves making a substantive, testable scientific claim. If you are a psychologist then your research hypotheses are fundamentally about psychological constructs. Any of the following would count as **research hypotheses**:

- *Listening to music reduces your ability to pay attention to other things*. This is a claim about the causal relationship between two psychologically meaningful concepts (listening to music and paying attention to things), so it's a perfectly reasonable research hypothesis.
- *Intelligence is related to personality*. Like the last one, this is a relational claim about two psychological constructs (intelligence and personality), but the claim is weaker: correlational not causal
- *Intelligence is speed of information processing*. This hypothesis has a quite different character. It's not actually a relational claim at all. It's an ontological claim about the fundamental character of intelligence (and I'm pretty sure this one actually. It's usually easier to think about how to construct experiments to test research hypotheses of the form "does $X$ affect $Y$?" than it is to address claims like "what is $X$?" And in practice what usually happens is that you find ways of testing relational claims that follow from your ontological ones. For instance, if I believe that intelligence is speed of information processing in the brain, my experiments will often involve looking for relationships between measures of intelligence and measures of speed. As a consequence most everyday research questions do tend to be relational in nature, but they're almost always motivated by deeper ontological questions about the state of nature.

Notice that in practice, my research hypotheses could overlap a lot. My ultimate goal in the ESP experiment might be to test an ontological claim like "ESP exists", but I might operationally restrict myself to a narrower hypothesis like "Some people can 'see' objects in a clairvoyant fashion". That said, there are some things that really don't count as proper research hypotheses in any meaningful sense:

-   *Love is a battlefield*. This is too vague to be testable. Whilst it's okay for a research hypothesis to have a degree of vagueness to it, it has to be possible to operationalise your theoretical ideas. Maybe I'm just not creative enough to see it, but I can't see how this can be converted into any concrete research design. If that's true then this isn't a scientific research hypothesis, it's a pop song. That doesn't mean it's not interesting. A lot of deep questions that humans have fall into this category. Maybe one day science will be able to construct testable theories of love, or to test to see if God exists, and so on. But right now we can't, and I wouldn't bet on ever seeing a satisfying scientific approach to either.
-   *The first rule of tautology club is the first rule of tautology club*. This is not a substantive claim of any kind. It's true by definition. No conceivable state of nature could possibly be inconsistent with this claim. We say that this is an unfalsifiable hypothesis, and as such it is outside the domain of science. Whatever else you do in science your claims must have the possibility of being wrong.
-   *More people in my experiment will say "yes" than "no"*. This one fails as a research hypothesis because it's a claim about the data set, not about the psychology (unless of course your actual research question is whether people have some kind of "yes" bias!). Actually, this hypothesis is starting to sound more like a statistical hypothesis than a research hypothesis.

As you can see, research hypotheses can be somewhat messy at times and ultimately they are scientific claims. **Statistical hypotheses** are neither of these two things. Statistical hypotheses must be mathematically precise and they must correspond to specific claims about the characteristics of the data generating mechanism (i.e., the "population"). Even so, the intent is that statistical hypotheses bear a clear relationship to the substantive research hypotheses that you care about! For instance, in my ESP study my research hypothesis is that some people are able to see through walls or whatever. What I want to do is to "map" this onto a statement about how the data were generated. So let's think about what that statement would be. The quantity that I'm interested in within the experiment is $P(correct)$, the true-but-unknown probability with which the participants in my experiment answer the question correctly. Let's use the Greek letter $\theta$ (theta) to refer to this probability. Here are four different statistical hypotheses:

- If ESP doesn't exist and if my experiment is well designed then my participants are just guessing. So I should expect them to get it right half of the time and so my statistical hypothesis is that the true probability of choosing correctly is $\theta=0.5$ .
- Alternatively, suppose ESP does exist and participants can see the card. If that's true people will perform better than chance and the statistical hypothesis is that $\theta > 0.5$.
- A third possibility is that ESP does exist, but the colours are all reversed and people don't realise it (okay, that's wacky, but you never know). If that's how it works then you'd expect people's performance to be below chance. This would correspond to a statistical hypothesis that $\theta < 0.5$.
- Finally, suppose ESP exists but I have no idea whether people are seeing the right colour or the wrong one. In that case the only claim I could make about the data would be that the probability of making the correct answer is not equal to 0.5. This corresponds to the statistical hypothesis that $\theta \neq 0.5$.

All of these are legitimate examples of a statistical hypothesis because they are statements about a population parameter and are meaningfully related to my experiment.

What this discussion makes clear, I hope, is that when attempting to construct a statistical hypothesis test the researcher actually has two quite distinct hypotheses to consider. First, he or she has a research hypothesis (a claim about psychology), and this then corresponds to a statistical hypothesis (a claim about the data generating population). In my ESP example these might be as shown in @tbl-tab9-1.   --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="tbl-tab9-1" class="anchored">
<table class="lightable-paper table table-sm table-striped small" data-quarto-postprocess="true">
<caption>表格&nbsp;9.1: 原作者狂想的研究假設與統計假設</caption>
<thead>
<tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">研究假設</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">人類有超感官知覺</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">統計假設</td>
<td style="text-align: center;"><img src="images/tbl-9-1.png" class="img-fluid"></td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>小結一下兩種假設的差別。統計假設檢定的測試對象是統計假設，而非研究假設。假如你的研究設計不良，會造成研究假設和統計假設之間的斷裂。舉個有點荒謬的狀況，要是我的ESP研究是在參與者可以從窗戶反光看到卡片的環境裡進行，那麼我肯定能得到非常強的證據證明 <span class="math inline">\(\theta \neq 0.5\)</span>，但是這並不能告訴我們”人類真的有ESP”。</p>
<!--- And a key thing to recognise is this. A statistical hypothesis test is a test of the statistical hypothesis, not the research hypothesis. If your study is badly designed then the link between your research hypothesis and your statistical hypothesis is broken. To give a silly example, suppose that my ESP study was conducted in a situation where the participant can actually see the card reflected in a window. If that happens I would be able to find very strong evidence that $\theta \neq 0.5$, but this would tell us nothing about whether "ESP exists". --->
</section>
<section id="虛無假設與對立假設" class="level3" data-number="9.1.2">
<h3 data-number="9.1.2" class="anchored" data-anchor-id="虛無假設與對立假設"><span class="header-section-number">9.1.2</span> 虛無假設與對立假設</h3>
<p>到目前為止還算順利。我有一個研究假設，對應我想相信的世界，還有映射到一個對應於資料生成方式的統計假設。接下來我要創造一個新的統計假設（“虛無假設”，<span class="math inline">\(H_0\)</span>），這對很多人來說有些違反直覺。因為”虛無假設”對應與我想相信的事情完全相反，然後專注於驗證這條統計假設，並且忽略實際關心的事情（現在被稱為”對立假設”，<span class="math inline">\(H_1\)</span>）。在我的ESP研究裡，虛無假設是 <span class="math inline">\(\theta = 0.5\)</span>，因為如果人類沒有ESP，我會期望看到這個結果。當然，我期望ESP是真的，所以這個虛無假設對立的假設就是 <span class="math inline">\(\theta \neq 0.5\)</span>。實際上，我們是在將 <span class="math inline">\(\theta\)</span> 涵括的可能數值分成兩類：我真心期望不是真的那些數值（虛無假設），以及如果ESP被證實是存在的，我會很高興的那些數值（對立假設）。完成這些設定之後，需要意識到的關鍵是，假設檢定的真正目標不是證實對立假設（可能）是真的，而是證實虛無假設（可能）是假的。很多初學的同學會覺得這樣的邏輯很奇怪。</p>
<p>就我的學習經驗，最好的比喻是把假設檢定當作刑事法庭審判<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>。虛無假設就是被告，研究者就像檢察官，統計檢定程序是法官。像真正的刑事審判程序一樣，一開始我們要以無罪推定原則看待虛無假設，也就是說它的主張應被認為是真實的，直到位研究者能夠明確證實它的主張是錯的。研究者可以憑自由意志設計實驗（當然也要合理），目的就是要用可能性最大的資料證實虛無假設是錯的。然而，統計檢定(法官)設定了審判的規則，而這些規則是為了保護虛無假設而設計的，這些規則是要確保如果虛無假設的主張確實是真的，讓法官誤判的機會保持在很低的水準。這非常重要，畢竟虛無假設沒有律師幫忙辨護，而研究者卻在拼命地嘗試證實它的主張是錯的，所以必須有一方提供虛無假設一些保護。</p>
<!--- So far, so good. I have a research hypothesis that corresponds to what I want to believe about the world, and I can map it onto a statistical hypothesis that corresponds to what I want to believe about how the data were generated. It's at this point that things get somewhat counter-intuitive for a lot of people. Because what I'm about to do is invent a new statistical hypothesis (the "null" hypothesis, $H_0$ ) that corresponds to the exact opposite of what I want to believe, and then focus exclusively on that almost to the neglect of the thing I'm actually interested in (which is now called the "alternative" hypothesis, H1). In our ESP example, the null hypothesis is that $\theta = 0.5$, since that's what we'd expect if ESP didn't exist. My hope, of course, is that ESP is totally real and so the alternative to this null hypothesis is $\theta \neq 0.5$. In essence, what we're doing here is dividing up the possible values of $\theta$ into two groups: those values that I really hope aren't true (the null), and those values that I'd be happy with if they turn out to be right (the alternative). Having done so, the important thing to recognise is that the goal of a hypothesis test is not to show that the alternative hypothesis is (probably) true. The goal is to show that the null hypothesis is (probably) false. Most people find this pretty weird.

The best way to think about it, in my experience, is to imagine that a hypothesis test is a criminal trial[^09-hypothesis-testing-4], **the trial of the null hypothesis**. The null hypothesis is the defendant, the researcher is the prosecutor, and the statistical test itself is the judge. Just like a criminal trial, there is a presumption of innocence. The null hypothesis is deemed to be true unless you, the researcher, can prove beyond a reasonable doubt that it is false. You are free to design your experiment however you like (within reason, obviously!) and your goal when doing so is to maximise the chance that the data will yield a conviction for the crime of being false. The catch is that the statistical test sets the rules of the trial and those rules are designed to protect the null hypothesis, specifically to ensure that if the null hypothesis is actually true the chances of a false conviction are guaranteed to be low. This is pretty important. After all, the null hypothesis doesn't get a lawyer, and given that the researcher is trying desperately to prove it to be false someone has to protect it.

[^09-hypothesis-testing-4]: This analogy only works if you're from an adversarial legal system like UK/US/Australia. As I understand these things, the French inquisitorial system is quite different. --->
</section>
</section>
<section id="兩種決策失誤" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="兩種決策失誤"><span class="header-section-number">9.2</span> 兩種決策失誤</h2>
<p>在深入了解如何設定統計檢定程序之前，理解其哲學基礎是很有幫助的。我(原作者)曾經提過，虛無假設檢定和法庭審判之間的相似之處，不過現在要說得更清楚。最理想情況，我們希望每個檢定的結果都不會出錯。不幸的是，由於現實世界太複雜了，這是不可能達成的理想。有時候只是運氣不好，例如像是你測試擲一枚硬幣是否符合隨機，但是連續擲了10次，每次都是正面朝上。這似乎是表明硬幣不夠隨機的有力證據。然而，即使硬幣是完全公平的，出現這種結果的機率是1/1024。換句話說，在現實生活中，我們必須接受假設檢定出錯的可能性。因此，統計假設檢定的目標不是消除錯誤，而是儘可能減低錯誤的機率。</p>
<p>說到這裡，我們需要更精確地定義什麼是「錯誤」。首先要知道虛無假設最後會被判定為真或為假，會發生什麼狀況。也就是根據檢定，我們會保留或拒絕虛無假設<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>。如同 <a href="#tbl-tab9-2">表格&nbsp;<span>9.2</span></a> 所示，在我們進行檢定並做出選擇後，可能會發生的四種狀況：</p>
<!---Before going into details about how a statistical test is constructed it's useful to understand the philosophy behind it. I hinted at it when pointing out the similarity between a null hypothesis test and a criminal trial, but I should now be explicit. Ideally, we would like to construct our test so that we never make any errors. Unfortunately, since the world is messy, this is never possible. Sometimes you're just really unlucky. For instance, suppose you flip a coin 10 times in a row and it comes up heads all 10 times. That feels like very strong evidence for a conclusion that the coin is biased, but of course there's a 1 in 1024 chance that this would happen even if the coin was totally fair. In other words, in real life we always have to accept that there's a chance that we made a mistake. As a consequence the goal behind statistical hypothesis testing is not to eliminate errors, but to minimise them.

At this point, we need to be a bit more precise about what we mean by "errors". First, let's state the obvious. It is either the case that the null hypothesis is true or that it is false, and our test will either retain the null hypothesis or reject it.[^09-hypothesis-testing-5] So, as @tbl-tab9-2 illustrates, after we run the test and make our choice one of four things might have happened:

[^09-hypothesis-testing-5]: An aside regarding the language you use to talk about hypothesis testing. First, one thing you really want to avoid is the word "prove". A statistical test really doesn't prove that a hypothesis is true or false. Proof implies certainty and, as the saying goes, statistics means never having to say you're certain. On that point almost everyone would agree. However, beyond that there's a fair amount of confusion. Some people argue that you're only allowed to make statements like "rejected the null", "failed to reject the null", or possibly "retained the null". According to this line of thinking you can't say things like "accept the alternative" or "accept the null". Personally I think this is too strong. In my opinion, this conflates null hypothesis testing with Karl Popper's falsificationist view of the scientific process. Whilst there are similarities between falsificationism and null hypothesis testing, they aren't equivalent. However, whilst I personally think it's fine to talk about accepting a hypothesis (on the proviso that "acceptance" doesn't actually mean that it's necessarily true, especially in the case of the null hypothesis), many people will disagree. And more to the point, you should be aware that this particular weirdness exists so that you're not caught unawares by it when writing up your own results. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="tbl-tab9-2" class="anchored">
<table id="tab:tbl-tab9-2" class="huxtable table table-sm table-striped small" data-quarto-postprocess="true">
<caption>表格&nbsp;9.2: 圖解虛無假設檢定(NHST)的四種結果</caption>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: bold;"></td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: bold;">retain \( H_0 \)</td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: bold;">reject \( H_0 \)</td>
</tr>
<tr class="even">
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: normal;">\( H_0 \) is true</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">correct decision</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: normal;">error (type I)</td>
</tr>
<tr class="odd">
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: normal;">\( H_0 \) is false</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">error (type II)</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: normal;">correct decision</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>我們看到實際上有兩種不同的錯誤類型。如果我們拒絕了實際為真的虛無假設，那麼我們就是犯了<strong>型一錯誤</strong>。另一方面，當虛無假設實際上是錯的，我們仍然保留它，那麼我們就犯了<strong>型二錯誤</strong>。</p>
<p>還記得我之前說過統計檢定有點像法庭審判嗎？我這樣說是認真的。要認定被告有罪，審判長會要求你要提出「超越合理的懷疑」。所有關於證據的法律規定（至少在理論上），都是確保幾乎沒有人能錯誤地判定一個無辜的被告有罪。審判標準如此嚴格的目的是保護被告的權利，英國法官威廉·布萊克斯通曾說過「與其冤枉一個無辜的人，不如放過十個有罪的人。」換句話說，法庭裡審判長不會等價看待兩種類型的錯誤。因為冤枉無辜者的代價遠高於讓罪犯逍遙法外的代價。統計檢定基本上也是這樣。可靠的假設檢定最重要設計原則是控制「型一錯誤」的發生機率，講求控制在某個固定機率以下。這個機率通常以 <span class="math inline">\(\alpha\)</span> 表示，稱為檢定的<strong>顯著水準</strong>。我再強調一次，因為這是整個設計的核心，如果「型一錯誤率」不大於 <span class="math inline">\(\alpha\)</span>，那麼假設檢定的顯著水準就是 <span class="math inline">\(\alpha\)</span>。</p>
<p>那麼要怎麼處理型二錯誤率呢？我們也希望能控制在一定範圍內，通常用 <span class="math inline">\(\beta\)</span> 來表示型二錯誤的發生機率。不過更常見做法的是估計檢定力，也就是虛無假設為假時，拒絕虛無假設的機率，這個機率是 <span class="math inline">\(1 - \beta\)</span>。為了更好地理解，我們將 <a href="#tbl-tab9-2">表格&nbsp;<span>9.2</span></a> 改寫一下，並加入相關數字（見 <a href="#tbl-tab9-3">表格&nbsp;<span>9.3</span></a>）：</p>

<!--- As a consequence there are actually two different types of error here. If we reject a null hypothesis that is actually true then we have made a **type I error**. On the other hand, if we retain the null hypothesis when it is in fact false then we have made a **type II error**.

Remember how I said that statistical testing was kind of like a criminal trial? Well, I meant it. A criminal trial requires that you establish "beyond a reasonable doubt" that the defendant did it. All of the evidential rules are (in theory, at least) designed to ensure that there's (almost) no chance of wrongfully convicting an innocent defendant. The trial is designed to protect the rights of a defendant, as the English jurist William Blackstone famously said, it is "better that ten guilty persons escape than that one innocent suffer." In other words, a criminal trial doesn't treat the two types of error in the same way. Punishing the innocent is deemed to be much worse than letting the guilty go free. A statistical test is pretty much the same. The single most important design principle of the test is to control the probability of a type I error, to keep it below some fixed probability. This probability, which is denoted $\alpha$, is called the **significance level** of the test. And I'll say it again, because it is so central to the whole set-up, a hypothesis test is said to have significance level $\alpha$ if the type I error rate is no larger than $\alpha$.

So, what about the type II error rate? Well, we'd also like to keep those under control too, and we denote this probability by $\beta$. However, it's much more common to refer to the **power** of the test, that is the probability with which we reject a null hypothesis when it really is false, which is $1 - \beta$. To help keep this straight, here's the same table again but with the relevant numbers added (@tbl-tab9-3): --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="tbl-tab9-3" class="anchored">
<table id="tab:tbl-tab9-3" class="huxtable table table-sm table-striped small" data-quarto-postprocess="true">
<caption>表格&nbsp;9.3: 進一步解析虛無假設檢定(NHST)的四種結果</caption>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: bold;"></td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: bold;">retain \( H_0 \)</td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: bold;">reject \( H_0 \)</td>
</tr>
<tr class="even">
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: normal;">\( H_0 \) is true</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">1-\( \alpha \) (probability of correct retention)</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: normal;">\(\alpha\) (type I error rate)</td>
</tr>
<tr class="odd">
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: normal;">\( H_0 \) is false</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">\(\beta\) (type II error rate)</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: normal;">\(1 - \beta\) (power of the test)</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>一個「有力」的假設檢定是指保持最小 <span class="math inline">\(\beta\)</span> 值，同時保持 <span class="math inline">\(\alpha\)</span> 在預期的水準。依照領域慣例，科學家通常會使用三種 <span class="math inline">\(\alpha\)</span> 水準：<span class="math inline">\(0.05\)</span>、<span class="math inline">\(0.01\)</span> 和 <span class="math inline">\(0.001\)</span>。值得注意的是，兩者的控制強度有一種不對稱性：檢定的目的是確保 <span class="math inline">\(\alpha\)</span> 值如同預期的小，但是對於 <span class="math inline">\(\beta\)</span> 則不預其能控制到相應的水準。當然，我們也希望型二錯誤率能夠保持最小，並設計一些測試來實現，但這方面的控制需求通常不如型一錯誤率的迫切。倘若把布萊克斯通 的話換成統計學家的說法，那就是說“保留十個結論錯誤的虛無假設，總比拒絕一個真實的假設要好”。老實說，我不完全同意這種哲學觀點。在某些情況下，我認為這種觀點是有道理的，其他情況則不然。但是這不是重點，重點是這就是假設檢定的設計原則。</p>
<!--- A "powerful" hypothesis test is one that has a small value of $\beta$, while still keeping $\alpha$ fixed at some (small) desired level. By convention, scientists make use of three different $\alpha$ levels: $.05$, $.01$ and $.001$. Notice the asymmetry here; the tests are designed to ensure that the $\alpha$ level is kept small but there's no corresponding guarantee regarding $\beta$. We'd certainly like the type II error rate to be small and we try to design tests that keep it small, but this is typically secondary to the overwhelming need to control the type I error rate. As Blackstone might have said if he were a statistician, it is "better to retain 10 false null hypotheses than to reject a single true one". To be honest, I don't know that I agree with this philosophy. There are situations where I think it makes sense, and situations where I think it doesn't, but that's neither here nor there. It's how the tests are built. --->
</section>
<section id="運用取樣分佈檢測統計值" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="運用取樣分佈檢測統計值"><span class="header-section-number">9.3</span> 運用取樣分佈檢測統計值</h2>
<p>現在我們可以開始討論如何建立一個假設檢定的具體步驟，讓我們回到一開始提的靈異感知（ESP）研究題目。暫時不管我們實際獲得的資料，先專注於實驗設計。無論資料裡的數值是什麼，都是表示 <span class="math inline">\(N\)</span> 個人當中有 <span class="math inline">\(X\)</span> 個人正確地辨認出隱藏卡牌的顏色。此外，若是虛無假設（null hypothesis）確實是真的，也就是說靈異感知不存在，每個人正確辨認出卡牌顏色的真實機率 <span class="math inline">\(\theta\)</span> 等於 <span class="math inline">\(0.5\)</span>。在這種狀況，我們預期的資料是什麼樣子呢？很明顯，我們期望作出正確反應的人數比例接近 <span class="math inline">\(50%\)</span>。換言之，我們可以用更數學式的語言表達 <span class="math inline">\(\frac{X}{N}\)</span> 大約等於 <span class="math inline">\(0.5\)</span>。當然，我們不會預期真實的比例完全等於 <span class="math inline">\(0.5\)</span>。例如，如果我們測試了 <span class="math inline">\(N=100\)</span> 個人，其中有 <span class="math inline">\(X=53\)</span> 人回答正確，我們也許不得不承認這筆資料與虛無假設是相當一致的。另一方面，如果有 <span class="math inline">\(X=99\)</span> 個參與者回答正確，我們會非常有信心地認為虛無假設是錯的。同樣地，如果只有 <span class="math inline">\(X=3\)</span> 人回答正確，我們也會非常有信心地認為虛無假設是錯的。現在讓我們用更專業的方式描述這些推論：我們有一個數值 <span class="math inline">\(X\)</span> ，可以通過觀察資料計算出來。評估 <span class="math inline">\(X\)</span> 之後，我們就必須決定是相信虛無假設，還是拒絕虛無假設並接受另一種假設。用來幫助我們作出決策的數值就稱為<strong>統計檢定值</strong>。</p>
<p>選定了一個統計檢定值後，下一步是正式宣告那些統計值將導致我們拒絕虛無假設，那些統計值將導致我們接受虛無假設。為了做出決策，我們需要確定當實際結果符合虛無假設時，統計值的取樣分佈是什麼（不大記得的話，可以回到 <a href="08-Estimating-unknown-quantities-from-a-sample.html#sec-Sampling-distribution-of-the-mean"><span>章节&nbsp;8.3.1</span></a> 復習）。為什麼我們需要設定取樣分佈？因為這能告訴我們，如果虛無假設是正確的，我們可以預期會得到那些 <span class="math inline">\(X\)</span> 的數值。因此，我們可以使用這個分佈作為評估虛無假設與我們的資料是否一致的工具。</p>
<p>如何確定統計值的取樣分佈呢？對於大多數假設檢定程序來說，這個步驟通常相當複雜，甚至有些假設檢定原作者和譯者自己都不是很懂，稍後在本書中同學們會看到某些檢定程序的介紹會有些含糊其辭。不過在某些檢定程序，設定取樣分佈是非常簡單的。ESP研究案例所使用的檢定程序，剛好是最簡單的一種。這個案例的母群參數 <span class="math inline">\(\theta\)</span> 就是參與者們回答問題時的總機率，而統計值 <span class="math inline">\(X\)</span> 就等於所有參與者人數 <span class="math inline">\(N\)</span> 裡正確回答的人數。我們之前在 <a href="07-Introduction-to-probability.html#sec-The-binomial-distribution"><span>章节&nbsp;7.4</span></a> 這一節裡已經見過「二項分佈」，ESP案例的取樣分佈性質正好符合二項分佈！因此，為了使用二項分佈的符號和術語，我們會說虛無假設預測 <span class="math inline">\(X\)</span> 的分佈是二項分佈，數學式就寫作</p>
<!--- At this point we need to start talking specifics about how a hypothesis test is constructed. To that end, let's return to the ESP example. Let's ignore the actual data that we obtained, for the moment, and think about the structure of the experiment. Regardless of what the actual numbers are, the form of the data is that $X$ out of $N$ people correctly identified the colour of the hidden card. Moreover, let's suppose for the moment that the null hypothesis really is true, that ESP doesn't exist and the true probability that anyone picks the correct colour is exactly $\theta = 0.5$. What would we expect the data to look like? Well, obviously we'd expect the proportion of people who make the correct response to be pretty close to $50\%$. Or, to phrase this in more mathematical terms, we'd say that $\frac{X}{N}$ is approximately $0.5$. Of course, we wouldn't expect this fraction to be exactly $0.5$. If, for example, we tested $N = 100$ people and $X = 53$ of them got the question right, we'd probably be forced to concede that the data are quite consistent with the null hypothesis. On the other hand, if $X = 99$ of our participants got the question right then we'd feel pretty confident that the null hypothesis is wrong. Similarly, if only $X = 3$ people got the answer right we'd be similarly confident that the null was wrong. Let's be a little more technical about this. We have a quantity $X$ that we can calculate by looking at our data. After looking at the value of $X$ we make a decision about whether to believe that the null hypothesis is correct, or to reject the null hypothesis in favour of the alternative. The name for this thing that we calculate to guide our choices is a **test statistic**.

Having chosen a test statistic, the next step is to state precisely which values of the test statistic would cause is to reject the null hypothesis, and which values would cause us to keep it. In order to do so we need to determine what the **sampling distribution of the test statistic** would be if the null hypothesis were actually true (we talked about sampling distributions earlier in @sec-Sampling-distribution-of-the-mean. Why do we need this? Because this distribution tells us exactly what values of X our null hypothesis would lead us to expect. And, therefore, we can use this distribution as a tool for assessing how closely the null hypothesis agrees with our data.

How do we actually determine the sampling distribution of the test statistic? For a lot of hypothesis tests this step is actually quite complicated, and later on in the book you'll see me being slightly evasive about it for some of the tests (some of them I don't even understand myself). However, sometimes it's very easy. And, fortunately for us, our ESP example provides us with one of the easiest cases. Our population parameter $\theta$ is just the overall probability that people respond correctly when asked the question, and our test statistic $X$ is the count of the number of people who did so out of a sample size of N. We've seen a distribution like this before, in @sec-The-binomial-distribution, and that's exactly what the binomial distribution describes! So, to use the notation and terminology that I introduced in that section, we would say that the null hypothesis predicts that $X$ is binomially distributed, which is written --->
<p><span class="math display">\[X \sim Binomial(\theta,N)\]</span></p>
<p>既然虛無假設主張 <span class="math inline">\(\theta = 0.5\)</span>，而我們的實驗有 <span class="math inline">\(N=100\)</span> 位參與者 ，所以我們已經擁有所需要的取樣分佈。這個取樣分佈的視覺化如同 <a href="#fig-fig9-1">图&nbsp;<span>9.1</span></a> 。沒有什麼特別的，由視覺化繪圖可知，既然虛無假設說 <span class="math inline">\(X=50\)</span> 是最有可能的結果，那麼我們有很大的機會看到 <span class="math inline">\(40\)</span> 到 <span class="math inline">\(60\)</span> 個正確的回答。</p>
<!---Since the null hypothesis states that $\theta = 0.5$ and our experiment has $N = 100$ people, we have the sampling distribution we need. This sampling distribution is plotted in @fig-fig9-1. No surprises really, the null hypothesis says that $X = 50$ is the most likely outcome, and it says that we're almost certain to see somewhere between $40$ and $60$ correct responses. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="fig-fig9-1" class="quarto-figure quarto-figure-left anchored">
<figure class="figure">
<p><img src="images/fig9-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">图&nbsp;9.1: 這是當虛無假設為真時，我們測試統計值 <span class="math inline">\(X\)</span> 的取樣分佈。對於 ESP 的案例，取樣分佈會符合二項式分佈。因為虛無假設主張正確回答的機率是 <span class="math inline">\(\theta = 0.5\)</span>，所以取樣分佈顯示，100次測試裡有50次 正確回答，是最有可能發生的結果。大多數的機率質量(probability mass)分散在40次到60次之間。</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-Hypothesis-testing-decision" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="sec-Hypothesis-testing-decision"><span class="header-section-number">9.4</span> 統計推論的決策要素</h2>
<p>我們已經非常接近最後一步了。前一步設定了一個統計檢定值 <span class="math inline">\((X)\)</span>，並且選擇了我們相當有信心的檢定值數值。如果 <span class="math inline">\(X\)</span> 接近 <span class="math inline">\(\frac{N}{2}\)</span>，我們應該保留虛無假設，否則我們就應該拒絕虛無假設。剩下的問題是什麼呢？確切地說，我們應該設定那些統計檢定值是對應虛無假設，那些統計檢定值對應對立假設？以ESP研究案為例，假如我觀察到一個值 <span class="math inline">\(X=62\)</span>。我應該做出什麼決策呢？我應該相信虛無假設還是對立假設？</p>
<!---Okay, we're very close to being finished. We've constructed a test statistic $(X)$ and we chose this test statistic in such a way that we're pretty confident that if $X$ is close to $\frac{N}{2}$ then we should retain the null, and if not we should reject it. The question that remains is this. Exactly which values of the test statistic should we associate with the null hypothesis, and exactly which values go with the alternative hypothesis? In my ESP study, for example, I've observed a value of $X = 62$. What decision should I make? Should I choose to believe the null hypothesis or the alternative hypothesis? --->
<section id="棄卻域與臨界值" class="level3" data-number="9.4.1">
<h3 data-number="9.4.1" class="anchored" data-anchor-id="棄卻域與臨界值"><span class="header-section-number">9.4.1</span> 棄卻域與臨界值</h3>
<p>要回答這個問題，我需要向各位介紹統計檢定值 <span class="math inline">\(X\)</span> 的<strong>棄卻域（critical region）</strong>。檢定的棄卻域對應那些會讓我們拒絕虛無假設的 <span class="math inline">\(X\)</span> 數值集合（這就是為什麼棄卻域有時也被稱為拒絕域）。我們如何找到這個棄卻域呢？嗯，讓我們想一想已知的條件：</p>
<ul>
<li>為了拒絕虛無假設，<span class="math inline">\(X\)</span> 應該非常大或非常小</li>
<li>如果虛無假設為真，<span class="math inline">\(X\)</span> 的取樣分佈會是 <span class="math inline">\(Binomial(0.5, N)\)</span></li>
<li>如果 <span class="math inline">\(\alpha = .05\)</span>，則棄卻域必須包含這個取樣分佈的 5%。</li>
</ul>
<p>最後一點非常重要。棄卻域的範圍是指那些會導致我們拒絕虛無假設的 <span class="math inline">\(X\)</span> 數值範圍，而這個範圍是經由取樣分佈代換後的機率質量所決定的。如果我們選擇了一個其涵蓋 <span class="math inline">\(20%\)</span> 機率質量的棄卻域，且虛無假設是符合事實的，那麼拒絕虛無假設的錯誤機率就是 <span class="math inline">\(20%\)</span>。換言之，我們完成了一個顯著水準為 <span class="math inline">\(0.2\)</span> 的檢驗。如果我們要求顯著水準是 <span class="math inline">\(\alpha = .05\)</span>，那麼棄卻域只能涵蓋統計檢定量取樣分佈的 <span class="math inline">\(5%\)</span> 機率質量。</p>
<!--- 如果顯著水準是 $\alpha$，那麼棄卻域的範圍必須涵蓋 $100\alpha%$ 的機率質量。如果棄卻域涵蓋的機率質量太大，那麼我們會過於保守，導致無法拒絕虛無假設，反之，如果棄卻域太小，那麼我們會對拒絕虛無假設採取過於激進的行為。 --->
<p>我們在此總結解決完成假設檢定程序的三個要點。我們的棄卻域包括了機率分佈的最極端數值，也就是機率分佈的<strong>尾部</strong>。 <a href="#fig-fig9-2">图&nbsp;<span>9.2</span></a> 展示了這個概念的視覺化。如果我們希望 <span class="math inline">\(\alpha = .05\)</span>，那麼對應的棄卻域是 <span class="math inline">\(X \leq 40\)</span> 和 <span class="math inline">\(X \geq 60\)</span>。<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>也就是說，如果回答正確的人數在 41 到 59 之間，那麼我們應該保留虛無假設。如果回答正確的人數在 0 到 40 或 60 到 100 之間，那麼我們就應該拒絕虛無假設。數字 40 和 60 通常被稱為<strong>臨界值</strong>(critical values)，因為這些數值定義了棄卻域的邊界。</p>
<!--- To answer this question we need to introduce the concept of a **critical region** for the test statistic X. The critical region of the test corresponds to those values of X that would lead us to reject null hypothesis (which is why the critical region is also sometimes called the rejection region). How do we find this critical region? Well, let's consider what we know:

- $X$ should be very big or very small in order to reject the null hypothesis
- If the null hypothesis is true, the sampling distribution of $X$ is $Binomial(0.5, N)$
- If $\alpha = .05$, the critical region must cover 5% of this sampling distribution.

It's important to make sure you understand this last point. The critical region corresponds to those values of $X$ for which we would reject the null hypothesis, and the sampling distribution in question describes the probability that we would obtain a particular value of $X$ if the null hypothesis were actually true. Now, let's suppose that we chose a critical region that covers $20\%$ of the sampling distribution, and suppose that the null hypothesis is actually true. What would be the probability of incorrectly rejecting the null? The answer is of course $20\%$. And, therefore, we would have built a test that had an α level of $0.2$. If we want $\alpha = .05$, the critical region is only allowed to cover 5% of the sampling distribution of our test statistic.

As it turns out those three things uniquely solve the problem. Our critical region consists of the most extreme values, known as the **tails** of the distribution. This is illustrated in @fig-fig9-2. If we want $\alpha = .05$ then our critical regions correspond to $X \leq 40$ and $X \geq 60$.[^09-hypothesis-testing-6] That is, if the number of people saying "true" is between 41 and 59, then we should retain the null hypothesis. If the number is between $0$ to $40$, or between $60$ to $100$, then we should reject the null hypothesis. The numbers $40$ and $60$ are often referred to as the **critical values** since they define the edges of the critical region.

[^09-hypothesis-testing-6]: Strictly speaking, the test I just constructed has $\alpha = .057$, which is a bit too generous. However, if I'd chosen 39 and 61 to be the boundaries for the critical region then the critical region only covers $3.5\%$ of the distribution. I figured that it makes more sense to use $40$ and $60$ as my critical values, and be willing to tolerate a $5.7\%$ type I error rate, since that's as close as I can get to a value of $\alpha = .05$. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="fig-fig9-2" class="quarto-figure quarto-figure-left anchored">
<figure class="figure">
<p><img src="images/fig9-2.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">图&nbsp;9.2: 這張圖與 <a href="#fig-fig9-1">图&nbsp;<span>9.1</span></a> 的虛無假設 <span class="math inline">\(X\)</span> 取樣分佈一樣，進一步展示ESP研究的假設檢定的棄卻域，假設檢定的顯著水準為<span class="math inline">\(\alpha = .05\)</span> 。灰色的柱子表示我們會保留虛無假設的 <span class="math inline">\(X\)</span> 數值集合。深藍色的柱子表示棄卻域，也就是我們會拒絕虛無假設的 <span class="math inline">\(X\)</span> 值。由於對立假設的主張是雙側的（即允許 <span class="math inline">\(\theta &lt; .5\)</span> 和 <span class="math inline">\(\theta &gt; .5\)</span>），因此棄卻域涵蓋分佈的兩個尾部。為確保 <span class="math inline">\(\alpha\)</span> 水準為 <span class="math inline">\(.05\)</span>，我們需要確保左右區域各涵蓋了取樣分佈的 <span class="math inline">\(2.5%\)</span>。</figcaption>
</figure>
</div>
</div>
</div>
<p>最後，總結一下完成假設檢定的主要步驟：</p>
<ul>
<li>選擇一個顯著水準 (例如，<span class="math inline">\(\alpha = .05\)</span>)；</li>
<li>選擇一個適當的統計檢定值 (例如，<span class="math inline">\(X\)</span>)，並且設定有比較意義的<span class="math inline">\(H_0\)</span>和<span class="math inline">\(H_1\)</span>;</li>
<li>假設虛無假設是符合事實的，找出該統計檢定值的取樣分佈（在ESP案例為二項分佈）；</li>
<li>計算會產生符合 <span class="math inline">\(\alpha\)</span> 的棄卻域（0-40和60-100）。</li>
</ul>
<p>現在我們所要做的就是用實際資料計算統計檢定值（例如 <span class="math inline">\(X=62\)</span>），然後比較檢定值與臨界值做出決策。由於 <span class="math inline">\(62\)</span> 大於臨界值 <span class="math inline">\(60\)</span>，我們可以拒絕虛無假設。也可以說，我們根據檢定結果得到一個在統計<strong>顯著</strong>的結論。</p>
<!---At this point, our hypothesis test is essentially complete:

1. We choose an α level (e.g., $\alpha = .05$);
2. Come up with some test statistic (e.g., $X$) that does a good job (in some meaningful sense) of comparing $H_0$ to $H_1$;
3. Figure out the sampling distribution of the test statistic on the assumption that the null hypothesis is true (in this case, binomial); and then
4. Calculate the critical region that produces an appropriate α level (0-40 and 60-100).

All that we have to do now is calculate the value of the test statistic for the real data (e.g., X = 62) and then compare it to the critical values to make our decision. Since 62 is greater than the critical value of 60 we would reject the null hypothesis. Or, to phrase it slightly differently, we say that the test has produced a statistically **significant** result. --->
</section>
<section id="小心使用統計顯著" class="level3" data-number="9.4.2">
<h3 data-number="9.4.2" class="anchored" data-anchor-id="小心使用統計顯著"><span class="header-section-number">9.4.2</span> 小心使用統計“顯著”</h3>
<blockquote class="blockquote">
<p><em>統計學和其他占卜術一樣，擁有一套專門術語，故意設計成讓非專業人員無法從字面理解術語的意思。</em> – G. O. Ashley <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
</blockquote>
<p>在此需要講個關於 “significant”(常見中文說法“顯著”) 這個詞怎麼來的題外話。“significant” 在統計學中的概念其實很簡單，但這樣的命名並不夠好。如果實際資料能讓我們拒絕虛無假設，我們會說 “the result is statistically significant”(常見中文說法”結果有統計顯著性”)，通常簡單寫成 “the result is significant”(常見中文說法”有顯著結果”)。這個英文詞彙其實由來已久，來源可以追溯到 “significant” 的意思只是表達 “indicated”(已確認)的時代，並沒有現代英語的 “重要” 之類的含義。因此，今天許多讀者在開始學習統計學時會感到非常困惑，因為他們認為 “significant result” 必定是一個重要的結果。實際上，這並不是最早統計學家開始使用這個詞的意思。所有用”statistically significant”表達的主張， 只是表示資料允許我們拒絕一個虛無假設。至於結果是不是真的重要，則是另一個完全不同的問題，並且有其他各種因素的影響。</p>
<!--- 

> *Like other occult techniques of divination, the statistical method has a private jargon deliberately contrived to obscure its methods from non-practitioners.*\
> -- Attributed to G. O. Ashley [^09-hypothesis-testing-7]

[^09-hypothesis-testing-7]: The internet seems fairly convinced that Ashley said this, though I can't for the life of me find anyone willing to give a source for the claim.

A very brief digression is in order at this point, regarding the word "significant". The concept of statistical significance is actually a very simple one, but has a very unfortunate name. If the data allow us to reject the null hypothesis, we say that "the result is statistically significant", which is often shortened to "the result is significant". This terminology is rather old and dates back to a time when "significant" just meant something like "indicated", rather than its modern meaning which is much closer to "important". As a result, a lot of modern readers get very confused when they start learning statistics because they think that a "significant result" must be an important one. It doesn't mean that at all. All that "statistically significant" means is that the data allowed us to reject a null hypothesis. Whether or not the result is actually important in the real world is a very different question, and depends on all sorts of other things. --->
</section>
<section id="sec-The-difference-between-one-sided-and-two-sided-tests" class="level3" data-number="9.4.3">
<h3 data-number="9.4.3" class="anchored" data-anchor-id="sec-The-difference-between-one-sided-and-two-sided-tests"><span class="header-section-number">9.4.3</span> 單側與雙側檢定的不同</h3>
<p>還有一件事情要提醒各位同學，就是虛無假設與對立假設的設定方式。假如前面我所使用的統計假設是：<span class="math display">\[H_0: \theta=0.5\]</span> <span class="math display">\[H_1:\theta \neq 0.5\]</span> 我們會發現對立假設涵蓋了 <span class="math inline">\(\theta &lt; .5\)</span> 和 <span class="math inline">\(\theta &gt; .5\)</span> 這兩種可能的數值集合。這代表我認為超感官知覺可能造成優於純粹猜測的表現，也可能產生比純粹猜測還差的表現（有些人就是會這麼認為），那麼這樣的設定是有意義的。在統計學的語彙庫，這稱為<strong>雙側檢定</strong>(two-sided test)。這是因為對立假設涵蓋了 無假設兩側的數值集合，因此檢定的棄卻域覆蓋取樣分佈的兩側尾部（如果 <span class="math inline">\(\alpha = .05\)</span>，則每側尾部佔取樣分佈的2.5％），如同 <a href="#fig-fig9-2">图&nbsp;<span>9.2</span></a> 的展示。不過，這不是唯一的可能結果。如果我只在乎超感官知覺能夠產生優於純粹猜測的表現時，才願意相信這是事實，那麼對立假設就只會涵蓋 <span class="math inline">\(\theta &gt; .5\)</span> 的數值集合。因此，虛無假設和對立假設就會變成<span class="math display">\[H_0: \theta \leq 0.5\]</span> <span class="math display">\[H_1: \theta &gt; 0.5\]</span> 這種檢定條件 就是所謂的<strong>單側檢定</strong>(one-sided test)，此時檢定的棄卻域只有覆蓋取樣分佈的右側尾部，如同 <a href="#fig-fig9-3">图&nbsp;<span>9.3</span></a> 的展示。</p>
<!--- There's one more thing I want to point out about the hypothesis test that I've just constructed. If we take a moment to think about the statistical hypotheses I've been using, $$H_0: \theta=0.5$$ $$H_1:\theta \neq 0.5$$ we notice that the alternative hypothesis covers both the possibility that $\theta < .5$ and the possibility that $\theta \> .5.$ This makes sense if I really think that ESP could produce either better-than chance performance or worse-than-chance performance (and there are some people who think that). In statistical language this is an example of a **two-sided test**. It's called this because the alternative hypothesis covers the area on both "sides" of the null hypothesis, and as a consequence the critical region of the test covers both tails of the sampling distribution (2.5% on either side if α = .05), as illustrated earlier in @fig-fig9-2. However, that's not the only possibility. I might only be willing to believe in ESP if it produces better than chance performance. If so, then my alternative hypothesis would only covers the possibility that $\theta > .5$, and as a consequence the null hypothesis now becomes 
$$H_0: \theta \leq 0.5$$ 
$$H_1: \theta > 0.5$$ 
When this happens, we have what's called a **one-sided test** and the critical region only covers one tail of the sampling distribution. This is illustrated in @fig-fig9-3. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="fig-fig9-3" class="quarto-figure quarto-figure-left anchored">
<figure class="figure">
<p><img src="images/fig9-3.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">图&nbsp;9.3: 單側檢定的臨界區間。此狀況的對立假設是<span class="math inline">\(\theta \geq .5\)</span>，當<span class="math inline">\(X\)</span>的值很大，我們才能拒絕虛無假設。因此，臨界區間僅覆蓋取樣分佈的較大數值，具體來說是分佈的右側的 <span class="math inline">\(5%\)</span> 。比較一下 <a href="#fig-fig9-2">图&nbsp;<span>9.2</span></a> 的雙側檢定狀況。</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-The-p-value-of-a-test" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="sec-The-p-value-of-a-test"><span class="header-section-number">9.5</span> 統計檢定的<em>p</em>值</h2>
<p>在某種意義上，我們已經完成假設檢定程序。我們已經建立一個統計檢定值，設定好如果虛無假設符合事實的取樣分佈，並為檢定結果決策設定棄卻域。然而，其實我還省略了一個最重要的數值 – <strong><em>p</em>值</strong>。p 值有兩種不同的解釋版本，一種是由羅納德·費雪爵士(Sir Ronald Fisher)提出，另一種是由傑茲·尼曼 (Jerzy Neyman) 提出。兩種版本都是統計學家接受的解釋方法，雖然彼此反映非常不同的假設檢定思維途徑。大多數統計學教課書只會講費雪的版本，但我認為這有點可惜。我認為尼曼的版本更簡潔，更能反映虛無假設檢定的邏輯。當然，也許讀者會有不同意見，以下兩種版本都會介紹。我先從尼曼的版本開始說。</p>
<!---In one sense, our hypothesis test is complete. We've constructed a test statistic, figured out its sampling distribution if the null hypothesis is true, and then constructed the critical region for the test. Nevertheless, I've actually omitted the most important number of all, **the p value**. It is to this topic that we now turn. There are two somewhat different ways of interpreting a p value, one proposed by Sir Ronald Fisher and the other by Jerzy Neyman. Both versions are legitimate, though they reflect very different ways of thinking about hypothesis tests. Most introductory textbooks tend to give Fisher's version only, but I think that's a bit of a shame. To my mind, Neyman's version is cleaner and actually better reflects the logic of the null hypothesis test. You might disagree though, so I've included both. I'll start with Neyman's version. --->
<section id="運用p值做決策的簡單理由" class="level3" data-number="9.5.1">
<h3 data-number="9.5.1" class="anchored" data-anchor-id="運用p值做決策的簡單理由"><span class="header-section-number">9.5.1</span> 運用<em>p</em>值做決策的簡單理由</h3>
<p>前面描述的假設檢定程序有一個問題，就是並沒有區分“剛好顯著”和“非常顯著”的結果。像是在我的ESP研究案例裡，所獲得的資料只是剛好落在棄卻域的邊緣，讓我我確實得到了一個顯著結果，但這個結論其實非常微妙。若是我另外進行了一項研究，<span class="math inline">\(N=100\)</span> 參與者中有 <span class="math inline">\(X=97\)</span> 人回答正確，顯然這個結果也是顯著的，但是顯著性的程度要大得多，沒有任何模糊空間。前面描述的程序都沒有區分這兩種情況，若是我採用慣例做法，只以 <span class="math inline">\(\alpha=.05\)</span> 做為我可以接受的型一錯誤率，那麼這兩個結果都是顯著的。</p>
<p>這裡就是<em>p</em>值派上用場的地方了。為了容易理解其中的原理，讓我們想像對同一組資料做了好幾次假設檢定，但是每次設定不一樣的顯著水準 <span class="math inline">\(\alpha\)</span> 。對我所得到的 ESP 資料( <span class="math inline">\(X=62\)</span> )進行好幾次檢定後，得到的結論大致如 <a href="#tbl-tab9-4">表格&nbsp;<span>9.4</span></a> 。</p>

<!--- One problem with the hypothesis testing procedure that I've described is that it makes no distinction at all between a result that is "barely significant" and those that are "highly significant". For instance, in my ESP study the data I obtained only just fell inside the critical region, so I did get a significant effect but it was a pretty near thing. In contrast, suppose that I'd run a study in which $X = 97$ out of my $N = 100$ participants got the answer right. This would obviously be significant too but my a much larger margin, such that there's really no ambiguity about this at all. The procedure that I have already described makes no distinction between the two. If I adopt the standard convention of allowing $\alpha = .05$ as my acceptable Type I error rate, then both of these are significant results.

This is where the p value comes in handy. To understand how it works, let's suppose that we ran lots of hypothesis tests on the same data set, but with a different value of α in each case. When we do that for my original ESP data what we'd get is something like @tbl-tab9-4. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="tbl-tab9-4" class="anchored">
<table class="lightable-paper table table-sm table-striped small" data-quarto-postprocess="true">
<caption>表格&nbsp;9.4: 以不同顯著水準執行假設檢定的結果</caption>
<thead>
<tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">α值</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">X0.05</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">X0.04</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">X0.03</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">X0.02</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">X0.01</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">是否拒絕虛無假設</td>
<td style="text-align: center;">是</td>
<td style="text-align: center;">是</td>
<td style="text-align: center;">是</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">否</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>對我的ESP資料（100次觀察中有62次成功）進行幾次檢定後，以<span class="math inline">\(\alpha=.03\)</span>及以上的顯著水準決策，都是會拒絕虛無假設。以<span class="math inline">\(\alpha=.02\)</span>及以下的水準，都是是會保留虛無假設。因此，在<span class="math inline">\(.02\)</span>和<span class="math inline">\(.03\)</span>之間必定有一個最小的<span class="math inline">\(\alpha\)</span>值，讓我們可以拒絕虛無假設，這個值就是<em>p</em>值。最後我得到這筆ESP資料的<em>p</em>值為<span class="math inline">\(.021\)</span>。簡而言之，<em>p</em>值被定義為如果你想要拒絕虛無假設的話，<strong>你必須願意容忍的最小型一錯誤率</strong>(<span class="math inline">\(\alpha\)</span>)。</p>
<p>如果<em>p</em>值顯示的決策錯誤率是大到你無法接受，那麼你必須保留虛無假設。如果你對等於<em>p</em>值的決策錯誤率感到滿意，那麼你可以拒絕虛無假設並支持偏好的對立假設。</p>
<p>總而言之，<em>p</em>值是對以所有可能的顯著水準<span class="math inline">\(\alpha\)</span>，所執行的假設檢定結果總結。因此<em>p</em>值有”軟化”決策難度的效果。檢定結果的<em>p</em>值比 <span class="math inline">\(\alpha\)</span> 大的話，我們會拒絕虛無假設；而檢定結果的<em>p</em>值比 <span class="math inline">\(\alpha\)</span> 小的話，我們會保留虛無假設。由於我的 ESP 實驗結果是 <span class="math inline">\(X = 62\)</span>，因此 <em>p</em> = .021，要宣稱人類有ESP的話，我必須容忍 <span class="math inline">\(2.1%\)</span> 的型一錯誤率。另一方面，若是我的實驗結果是 <span class="math inline">\(X = 97\)</span>，那麼<em>p</em>值會是多少？這次縮小為 <span class="math inline">\(p = 1.36 \times 10^{-25}\)</span> <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>，這是一個非常、非常微小的型一錯誤率。對於第二個實驗結果，我會更有信心地拒絕虛無假設，因為我只需要 “願意” 容忍大約十分之一兆兆兆兆的型一錯誤率，我的結論會是正確的。</p>

<!--- When we test the ESP data ($X = 62$ successes out of $N = 100$ observations), using $\alpha$ levels of $.03$ and above, we'd always find ourselves rejecting the null hypothesis. For $\alpha$ levels of $.02$ and below we always end up retaining the null hypothesis. Therefore, somewhere between $.02$ and $.03$ there must be a smallest value of $\alpha$ that would allow us to reject the null hypothesis for this data. This is the $p$ value. As it turns out the ESP data has $p = .021$. In short, $p$ is defined to be the smallest Type I error rate ($\alpha$) that you have to be willing to tolerate if you want to reject the null hypothesis.

If it turns out that p describes an error rate that you find intolerable, then you must retain the null. If you're comfortable with an error rate equal to $p$, then it's okay to reject the null hypothesis in favour of your preferred alternative.

In effect, $p$ is a summary of all the possible hypothesis tests that you could have run, taken across all possible α values. And as a consequence it has the effect of "softening" our decision process. For those tests in which p ď α you would have rejected the null hypothesis, whereas for those tests in which p ą α you would have retained the null. In my ESP study I obtained $X = 62$ and as a consequence I've ended up with $p = .021$. So the error rate I have to tolerate is $2.1\%$. In contrast, suppose my experiment had yielded $X = 97$. What happens to my p value now? This time it's shrunk to $p = 1.36$ x $10^{-25}$, which is a tiny, tiny[^09-hypothesis-testing-8] Type I error rate. For this second case I would be able to reject the null hypothesis with a lot more confidence, because I only have to be "willing" to tolerate a type I error rate of about $1$ in $10$ trillion trillion in order to justify my decision to reject.

[^09-hypothesis-testing-8]: That's $p = .000000000000000000000000136$ for folks that don't like scientific notation! --->
</section>
<section id="獲得極端資料的機率" class="level3" data-number="9.5.2">
<h3 data-number="9.5.2" class="anchored" data-anchor-id="獲得極端資料的機率"><span class="header-section-number">9.5.2</span> 獲得極端資料的機率</h3>
<p>第二種<em>p</em>值的定義來自羅納德·費雪爵士，大多數入門統計學的教科書採用這個定義解釋<em>p</em>值。留意一下設定棄卻域時，是不是對應到取樣分佈的尾部，也就是分佈所涵蓋的量數之極端值？這並不是巧合，幾乎所有「好的」檢定都有這種特徵（所謂「好」是指型二錯誤率 <span class="math inline">\(\beta\)</span> 被最小化）。這是因為好的棄卻域幾乎總是對應到虛無假設成立時最不可能觀察到的統計檢定值。如果這條規則成立，那麼我們可以定義<em>p</em>值是<strong>我們會觀察到這個檢定統計值，其極端程度至少達到我們實際上得到該統計值的機率</strong>。換句話說，如果根據虛無假設解釋資料的正確性非常的低，那麼虛無假設應該是錯誤的。</p>
<!--- The second definition of the p-value comes from Sir Ronald Fisher, and it's actually this one that you tend to see in most introductory statistics textbooks. Notice how, when I constructed the critical region, it corresponded to the tails (i.e., extreme values) of the sampling distribution? That's not a coincidence, almost all "good" tests have this characteristic (good in the sense of minimising our type II error rate, $\beta$). The reason for that is that a good critical region almost always corresponds to those values of the test statistic that are least likely to be observed if the null hypothesis is true. If this rule is true, then we can define the p-value as the probability that we would have observed a test statistic that is at least as extreme as the one we actually did get. In other words, if the data are extremely implausible according to the null hypothesis, then the null hypothesis is probably wrong. --->
</section>
<section id="常見的錯誤解讀" class="level3" data-number="9.5.3">
<h3 data-number="9.5.3" class="anchored" data-anchor-id="常見的錯誤解讀"><span class="header-section-number">9.5.3</span> 常見的錯誤解讀</h3>
<p>好了，我們看到了兩種相當不同但是統計學家公認合理的解釋<em>p</em>值的定義，一種基於尼曼對假設檢定的想法，另一種基於費雪的可能性思考。不幸的是，還有第三種解釋，有些學生在初次學習統計學會遇到某些講師這樣介紹，但是<em>完全錯誤的解讀</em>。這種錯誤的定義方法是把<em>p</em>值稱為“虛無假設為真的機率”。這是一種直觀上很容易吸收的想法，但是有兩個關鍵錯誤。首先，虛無假設檢定是一種次數主義工具，而次數主義方法對機率的基本立場是，不允許研究者給虛無假設設定機率分佈。根據這種觀點，虛無假設要麼是真的，要麼不是真的，不可能存在“有<span class="math inline">\(5%\)</span>的機率是真的”這種說法。其次，即使是貝氏方法這一派，雖然會允許研究者給假設設定機率分佈，<em>p</em>值也不會對應虛無假設為真的機率，這派主張與計算<em>p</em>值的數學原理是完全不一樣的。總之，儘管這種定義方式非常直覺，但是沒有任何公認的學術方法能充分證明<em>p</em>值是某種假設為真的機率。請同學千萬要謹慎分辨。</p>
<!---- Okay, so you can see that there are two rather different but legitimate ways to interpret the $p$ value, one based on Neyman's approach to hypothesis testing and the other based on Fisher's. Unfortunately, there is a third explanation that people sometimes give, especially when they're first learning statistics, and it is *absolutely and completely wrong*. This mistaken approach is to refer to the $p$ value as "the probability that the null hypothesis is true". It's an intuitively appealing way to think, but it's wrong in two key respects. First, null hypothesis testing is a frequentist tool and the frequentist approach to probability does not allow you to assign probabilities to the null hypothesis. According to this view of probability, the null hypothesis is either true or it is not, it cannot have a "$5\%$ chance" of being true. Second, even within the Bayesian approach, which does let you assign probabilities to hypotheses, the p value would not correspond to the probability that the null is true. This interpretation is entirely inconsistent with the mathematics of how the p value is calculated. Put bluntly, despite the intuitive appeal of thinking this way, there is <u>no</u> justification for interpreting a $p$ value this way. Never do it. --->
</section>
</section>
<section id="假設檢定的報告格式" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="假設檢定的報告格式"><span class="header-section-number">9.6</span> 假設檢定的報告格式</h2>
<p>在假設檢定結果的報告，通常需要報告幾項資訊，各種檢定方法的報告格式也各有特別之處。本書的後半部將介紹如何報告各種的檢定結果（特別詳細的例子請參考 <a href="10-Categorical-data-analysis.html#sec-How-to-report-the-results-of-a-test"><span>章节&nbsp;10.1.9</span></a> ），讓同學對常用檢定方法的報告格式有所了解。不過，無論是做那一種檢定，都是要報告<em>p</em>值和結果是否有統計顯著性。</p>
<p>報告裡要說明<em>p</em>值是否表示有顯著性，這一點並不令人意外，因為這正是執行假設檢定程序的目的。會讓人意外的是，學術界對於要如何報告假設檢定結果一直存在各種爭議。先不管完全反對在報告中呈現虛無假設檢定結果的聲音，報告確切的<em>p</em>值和僅聲明<span class="math inline">\(p &lt; \alpha\)</span>（例如，<span class="math inline">\(p &lt; .05\)</span>），這兩種報告規範一直互相拉鋸。</p>
<!--- When writing up the results of a hypothesis test there's usually several pieces of information that you need to report, but it varies a fair bit from test to test. Throughout the rest of the book I'll spend a little time talking about how to report the results of different tests (see @sec-How-to-report-the-results-of-a-test for a particularly detailed example, so that you can get a feel for how it's usually done. However, regardless of what test you're doing, the one thing that you always have to do is say something about the $p$ value and whether or not the outcome was significant.

The fact that you have to do this is unsurprising, it's the whole point of doing the test. What might be surprising is the fact that there is some contention over exactly how you're supposed to do it. Leaving aside those people who completely disagree with the entire framework underpinning null hypothesis testing, there's a certain amount of tension that exists regarding whether or not to report the exact $p$ value that you obtained, or if you should state only that $p < \alpha$ for a significance level that you chose in advance (e.g., $p < .05$). --->
<section id="一些爭議" class="level3" data-number="9.6.1">
<h3 data-number="9.6.1" class="anchored" data-anchor-id="一些爭議"><span class="header-section-number">9.6.1</span> 一些爭議</h3>
<p>要了解為什麼有這些爭議，首先要認識報告<em>p</em>值的便利性。在統計實務，只要能夠計算出<em>p</em>值，即使事先沒有指定任何顯著水準 <span class="math inline">\(\alpha\)</span> ，任何人都可以進行檢定。也就是說，人人可以直接計算<em>p</em>值並直接做解釋。如果今天得到<em>p</em> = .062，這代表著研究者 必須願意容忍 <span class="math inline">\(6.2%\)</span> 的型一錯誤率，才能證實虛無假設不符合事實。如果研究者無法接受 <span class="math inline">\(6.2%\)</span> 的型一錯誤率，那麼就要接受虛無假設。因此爭議在於，為什麼不報告實際的<em>p</em>值，讓讀者自己決定什麼樣的型一錯誤率是可以接受的？這種報告方式的優勢在於 “軟化” 決策責任。若是你傾向接受尼曼定義<em>p</em>值的方法，這就是<em>p</em>值的充分意義。我們不必再依賴一個固定的顯著水準，像是 <span class="math inline">\(\alpha = .05\)</span> ， 做為 “接受” 或 “否決” 之間的明確界線，如此就消除了用 <em>p</em> = .051 和 <em>p</em> = .049等邊緣數值，做為決策依據的詭異問題。</p>
<p>這種解讀的彈性是<em>p</em>值的優勢和劣勢。許多人不喜歡報告精確的<em>p</em>值原因是，研究人員因此有太多解釋的彈性空間。特別是每次查看資料後，<em>p</em>值能讓研究者改變願意容忍多少錯誤率的想法。以我虛構的 ESP 實驗為例，若是我進行了一次實驗，得到了一個<span class="math inline">\(0.09\)</span>的<em>p</em>值。我應該要接受還是拒絕虛無假設？說實話，我甚至還沒有想到我“真正”願意接受的型一錯誤率。我對方法學的問題沒有意見，但是我對 ESP 是否存在肯定有預先立場，而且我肯定會在乎我的研究是否能夠在一個有影響力的科學期刊上發表。最匪夷所思的是，在我看了初期資料後，開始覺得 <span class="math inline">\(9%\)</span> 的錯誤率還算可以，特別是與向全世界承認我的實驗失敗的煩惱相比，似乎是幸運的。因此，為了避免看起來像是事後編造，我就在報告裡說我的 <span class="math inline">\(\alpha\)</span> 是 <span class="math inline">\(0.1\)</span>，理由是型一錯誤率 <span class="math inline">\(10%\)</span> 並不算太糟糕，而且以這個條件來說，我的實驗結果是顯著的！我贏了。</p>
<p>換句話說，這個故事情節透露，即使研究者的意圖是好的，態度也夠誠實，有時也很難抵擋在某些方面“淡化”研究難度的誘惑。任何曾經做過實驗的人都知道，這是一個漫長而且困難的過程，你常常會對你的假設情有獨鍾，很難讓人放下，並承認實驗沒有找到你想找到的結果，而這就是決策風險所在。如果我們報告“原始的”<em>p</em>值，每個人會朝他們想要相信的方向來解讀數據，而不是從數據看出事實，如果我們允許這樣做，那為什麼科學家們還要繼續進行科學研究呢？為什麼不讓每個人在任何事情上相信他們喜歡的立場，而不去管事實是什麼？好吧，這麼說有點極端了，但這就是爭議的來源。如果同學同意這樣的觀點，就必須事先指定顯著水準<span class="math inline">\(\alpha\)</span>，然後只報告檢定結果是否顯著。這是保持誠實的唯一途徑。</p>

<!--- To see why this is an issue, the key thing to recognise is that p values are terribly convenient. In practice, the fact that we can compute a p value means that we don't actually have to specify any $\alpha$ level at all in order to run the test. Instead, what you can do is calculate your p value and interpret it directly. If you get $p = .062$, then it means that you'd have to be willing to tolerate a Type I error rate of $6.2\%$ to justify rejecting the null. If you personally find $6.2\%$ intolerable then you retain the null. Therefore, the argument goes, why don't we just report the actual $p$ value and let the reader make up their own minds about what an acceptable Type I error rate is? This approach has the big advantage of "softening" the decision making process. In fact, if you accept the Neyman definition of the p value, that's the whole point of the p value. We no longer have a fixed significance level of $\alpha = .05$ as a bright line separating "accept" from "reject" decisions, and this removes the rather pathological problem of being forced to treat $p = .051$ in a fundamentally different way to $p = .049$.

This flexibility is both the advantage and the disadvantage to the $p$ value. The reason why a lot of people don't like the idea of reporting an exact $p$ value is that it gives the researcher a bit too much freedom. In particular, it lets you change your mind about what error tolerance you're willing to put up with after you look at the data. For instance, consider my ESP experiment. Suppose I ran my test and ended up with a $p$ value of $.09$. Should I accept or reject? Now, to be honest, I haven't yet bothered to think about what level of Type I error I'm "really" willing to accept. I don't have an opinion on that topic. But I *do* have an opinion about whether or not ESP exists, and I *definitely* have an opinion about whether my research should be published in a reputable scientific journal. And amazingly, now that I've looked at the data I'm starting to think that a $9\%$ error rate isn't so bad, especially when compared to how annoying it would be to have to admit to the world that my experiment has failed. So, to avoid looking like I just made it up after the fact, I now say that my $\alpha$ is .1, with the argument that a $10\%$ type I error rate isn't too bad and at that level my test is significant! I win.

In other words, the worry here is that I might have the best of intentions, and be the most honest of people, but the temptation to just "shade" things a little bit here and there is really, really strong. As anyone who has ever run an experiment can attest, it's a long and difficult process and you often get very attached to your hypotheses. It's hard to let go and admit the experiment didn't find what you wanted it to find. And that's the danger here. If we use the "raw" p-value, people will start interpreting the data in terms of what they want to believe, not what the data are actually saying and, if we allow that, why are we even bothering to do science at all? Why not let everyone believe whatever they like about anything, regardless of what the facts are? Okay, that's a bit extreme, but that's where the worry comes from. According to this view, you really must specify your $\alpha$ value in advance and then only report whether the test was significant or not. It's the only way to keep ourselves honest --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="tbl-tab9-5" class="anchored">
<table id="tab:tbl-tab9-5" class="huxtable table table-sm table-striped small" data-quarto-postprocess="true">
<caption>表格&nbsp;9.5: p值水準的一般報告方法</caption>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: bold;">Usual notation</td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: bold;">Signif. stars</td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: bold;">English translation</td>
<td data-quarto-table-cell-role="th" style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: bold;">The null is...</td>
</tr>
<tr class="even">
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: normal;">p &gt; .05</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;"></td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">The test wasn't significant</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: normal;">Retained</td>
</tr>
<tr class="odd">
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: normal;">p &lt; .05</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">*</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">The test was significant at \( \alpha \) = .05 but not at \( \alpha \) = .01 or \( \alpha \) = .001.</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: normal;">Rejected</td>
</tr>
<tr class="even">
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: normal;">p &lt; .01</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">**</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">The test was significant at \( \alpha \) = .05 and \( \alpha \) = .01 but not at \( \alpha \) = .001.</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: normal;">Rejected</td>
</tr>
<tr class="odd">
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 0pt; font-weight: normal;">p &lt; .001</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">***</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 12pt 2pt 12pt; font-weight: normal;">The test was significant at all levels</td>
<td style="text-align: center; vertical-align: top; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 2pt 0pt 2pt 12pt; font-weight: normal;">Rejected</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
</section>
<section id="兩種實務建議" class="level3" data-number="9.6.2">
<h3 data-number="9.6.2" class="anchored" data-anchor-id="兩種實務建議"><span class="header-section-number">9.6.2</span> 兩種實務建議</h3>
<p>在許多領域的統計實務，研究人員很少只指定一種顯著水準 <span class="math inline">\(\alpha\)</span> 。很多科學家會根據三種顯著水準做為決策標準：<span class="math inline">\(.05\)</span>、<span class="math inline">\(.01\)</span> 和 <span class="math inline">\(.001\)</span>。結果報告裡要明確指出根據那些顯著水準，能拒絕虛無假設。陳述檢定結果的報告範例整理在 <a href="#tbl-tab9-5">表格&nbsp;<span>9.5</span></a> 。這樣可以稍微放開決策規則，因為以符合 <span class="math inline">\(p &lt; .01\)</span> 的資料做為證據，強度明顯大過 <span class="math inline">\(p &lt; .05\)</span> 的資料。除此之外，由於這些顯著水準是事先按慣例設定的，可以避免研究人員在查看數據後，才選擇顯著水準 <span class="math inline">\(\alpha\)</span> 。</p>
<p>儘管如此，許多研究者仍然喜歡報告精確的<em>p</em>值。對許多人來說，讓讀者自行決定如何解讀<span class="math inline">\(p=0.06\)</span>的好處多過壞處。然而，在許多實務場合，即使是那些偏好報告精確<em>p</em>值的研究人員，通常也只會寫<span class="math inline">\(p&lt;0.001\)</span>，而不是報告超微小<em>p</em>值的確切數值。這部分是因為許多軟體在<em>p</em>值太小時並不會印出完整數值（例如，SPSS算出<span class="math inline">\(p&lt;0.001\)</span>的話，只會印出<span class="math inline">\(p=0.000\)</span>），另一方面，非常小的<em>p</em>值可能會誤導讀者 。人類大腦看到像<span class="math inline">\(0.0000000001\)</span>這樣的數字時，很難壓抑直覺認為支持對立假設的結果是不可動搖的鐵證。然而，在真實世界，這樣的想法通常是錯誤的。生命是複雜的，每一個被發明出來的統計檢驗方法都是根據簡化的、逼近的和假設的模型。因此，很難抗拒從任何統計分析得到的<span class="math inline">\(p&lt;0.001\)</span>強烈信心感。換句話說，<span class="math inline">\(p&lt;0.001\)</span>實際只代表“就這個檢驗方法而言，證據是壓倒性的”。</p>
<p>有鑑於此，同學可能好奇應該要怎麼做。有許多處理這個問題的建議，存在相當多相互矛盾的地方。有些人認為應該報告精確的<em>p</em>值，也有人認為檢定報告應該如同 <a href="#tbl-tab9-1">表格&nbsp;<span>9.1</span></a> ，明確寫出研究假設與統計假設。對此，我能給同學們的最好建議是，大量閱讀你的主修領域已經發表的文獻報告，看看有什麼慣例。如果看不出有什麼一致的報告模式，那麼就使用你偏好的任何方法。</p>
<!--- In practice, it's pretty rare for a researcher to specify a single α level ahead of time. Instead, the convention is that scientists rely on three standard significance levels: $.05$, $.01$ and $.001$. When reporting your results, you indicate which (if any) of these significance levels allow you to reject the null hypothesis. This is summarised in @tbl-tab9-5. This allows us to soften the decision rule a little bit, since $p < .01$ implies that the data meet a stronger evidential standard than $p < .05$ would. Nevertheless, since these levels are fixed in advance by convention, it does prevent people choosing their α level after looking at the data

Nevertheless, quite a lot of people still prefer to report exact p values. To many people, the advantage of allowing the reader to make up their own mind about how to interpret p = .06 outweighs any disadvantages. In practice, however, even among those researchers who prefer exact p values it is quite common to just write $p < .001$ instead of reporting an exact value for small p. This is in part because a lot of software doesn't actually print out the p value when it's that small (e.g., SPSS just writes $p = .000$ whenever $p < .001$), and in part because a very small p value can be kind of misleading. The human mind sees a number like .0000000001 and it's hard to suppress the gut feeling that the evidence in favour of the alternative hypothesis is a near certainty. In practice however, this is usually wrong. Life is a big, messy, complicated thing, and every statistical test ever invented relies on simplifications, approximations and assumptions. As a consequence, it's probably not reasonable to walk away from any statistical analysis with a feeling of confidence stronger than $p < .001$ implies. In other words, $p < .001$ is really code for "as far as this test is concerned, the evidence is overwhelming."

In light of all this, you might be wondering exactly what you should do. There's a fair bit of contradictory advice on the topic, with some people arguing that you should report the exact p value, and other people arguing that you should use the tiered approach illustrated in @tbl-tab9-1. As a result, the best advice I can give is to suggest that you look at papers/reports written in your field and see what the convention seems to be. If there doesn't seem to be any consistent pattern, then use whichever method you prefer. --->
</section>
</section>
<section id="假設檢定實作須知" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="假設檢定實作須知"><span class="header-section-number">9.7</span> 假設檢定實作須知</h2>
<p>介紹到這裡，可能有些同學會想知道ESP研究是一個“真正”的假設檢定，還是只為了教學而編造的虛構範例，其實我們真的可以跑檢定程序。在前面的介紹，我(原作者)根據 <a href="#sec-Hypothesis-testing-decision"><span>章节&nbsp;9.4</span></a> 介紹的決策要素設定這個檢定程序，因為我認為這是大家在現實世界裡會遇到的最簡單的研究問題。不過，統計學家早就發明對應這種問題的檢定方法，正式名稱是<strong>二項式檢定</strong>，並且能用 jamovi 的內建模組”Frequencies”執行，在”Analyses”面板開啟模組選單，選擇“2 Outcomes”就能執行。若是設定虛無假設是回答機率為一半，即 <span class="math inline">\(p = 0.5\)</span>，<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>。從示範資料庫裡開啟binomialtest.omv這個檔案，檢驗<span class="math inline">\(n=100\)</span>位參與者裡 <span class="math inline">\(x=62\)</span> 位回答正確的資料能拒絕或接受虛無假設，檢定結果如同 <a href="#fig-fig9-4">图&nbsp;<span>9.4</span></a> 。</p>
<!--- At this point some of you might be wondering if this is a "real" hypothesis test, or just a toy example that I made up. It's real. In the previous discussion I built the test from first principles, thinking that it was the simplest possible problem that you might ever encounter in real life. However, this test already exists. It's called the *binomial test*, and it's implemented by jamovi as one of the statistical analyses available when you hit the 'Frequencies' button. To test the null hypothesis that the response probability is one-half $p = .5$,[^09-hypothesis-testing-9] and using data in which $x =62$ of $n = 100$ people made the correct response, available in the binomialtest.omv data file, we get the results shown in @fig-fig9-4.

[^09-hypothesis-testing-9]: Note that the p here has nothing to do with a $p$ value. The $p$ argument in the jamovi binomial test corresponds to the probability of making a correct response, according to the null hypothesis. In other words, it's the $\theta$ value. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="fig-fig9-4" class="quarto-figure quarto-figure-left anchored">
<figure class="figure">
<p><img src="images/fig9-4.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">图&nbsp;9.4: 使用jamovi執行二項式檢定</figcaption>
</figure>
</div>
</div>
</div>
<p>報表內容對初學的同學來說可能還很陌生，但你應該可以看出一些前面談過，要在報告裡呈現的資訊。最具體的一項是<em>p</em> = 0.02 小於常用的顯著水準 <span class="math inline">\(\alpha = 0.05\)</span>，因此我們可以拒絕虛無假設。隨著後續章節的學習，同學們會逐漸了解如何閱讀報表內容，希望學過之後，大家會發現報表內容的呈現方式，在閱讀和理解報告的好處。</p>
<!--- Right now, this output looks pretty unfamiliar to you, but you can see that it's telling you more or less the right things. Specifically, the p-value of $0.02$ is less than the usual choice of $\alpha = .05$, so you can reject the null. We'll talk a lot more about how to read this sort of output as we go along, and after a while you'll hopefully find it quite easy to read and understand. --->
</section>
<section id="sec-Effect-size-sample-size-and-power" class="level2" data-number="9.8">
<h2 data-number="9.8" class="anchored" data-anchor-id="sec-Effect-size-sample-size-and-power"><span class="header-section-number">9.8</span> 效果量、樣本量、考驗力</h2>
<p>在前面的章節，我(原作者)一再強調統計假設檢定背後的主要設計原則，那就是要儘可能有效控制型一錯誤率。當我們設定 <span class="math inline">\(\alpha = .05\)</span> 時，就要嘗試確保虛無假設主張成立的話，最多只有 <span class="math inline">\(5%\)</span> 的機率被錯誤拒絕。然而，這並不是說我們不用關心型二錯誤。從研究者進行統計實務的角度來看，當虛無假設實際不成立，卻不能拒絕所造成的錯誤非常令人困擾。考慮這一點，假設檢定的次要目標就是要儘可能讓型二錯誤率 <span class="math inline">\(\beta\)</span> 維持在最低水準，儘管我們通常不會用「最小化型二錯誤」來形容這個目標。相反的，我們常用「最大化考驗力」這樣的描述。因為考驗力的定義是 <span class="math inline">\(1-\beta\)</span>，所以兩者意思是相同的。</p>
<!---In previous sections I've emphasised the fact that the major design principle behind statistical hypothesis testing is that we try to control our Type I error rate. When we fix $\alpha = .05$ we are attempting to ensure that only $5\%$ of true null hypotheses are incorrectly rejected. However, this doesn't mean that we don't care about Type II errors. In fact, from the researcher's perspective, the error of failing to reject the null when it is actually false is an extremely annoying one. With that in mind, a secondary goal of hypothesis testing is to try to minimise $\beta$, the Type II error rate, although we don't usually talk in terms of minimising Type II errors. Instead, we talk about maximising the power of the test. Since power is defined as $1 - \beta$, this is the same thing. --->
<section id="圖解考驗力" class="level3" data-number="9.8.1">
<h3 data-number="9.8.1" class="anchored" data-anchor-id="圖解考驗力"><span class="header-section-number">9.8.1</span> 圖解考驗力</h3>
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="fig-fig9-5" class="quarto-figure quarto-figure-left anchored">
<figure class="figure">
<p><img src="images/fig9-5.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">图&nbsp;9.5: 對立假設主張母群參數 <span class="math inline">\(\theta=0.55\)</span> 的取樣分佈。圖中藍色區域代表可合理拒絕虛無假設的棄卻域範圍。</figcaption>
</figure>
</div>
</div>
</div>
<p>讓我們花一點時間來好好理解什麼是型二錯誤。當對立假設成立，但我們仍然無法拒絕虛無假設時，做出的決策錯誤就是型二錯誤(再看一下 <a href="#tbl-tab9-2">表格&nbsp;<span>9.2</span></a> )。較理想的情況是我們可以設定一個代表型二錯誤率的數值 <span class="math inline">\(\beta\)</span>，就像我們可以將 <span class="math inline">\(\alpha = .05\)</span> 設定為型一錯誤率一樣。不幸的是，實際的做法非常棘手。仔細看一下ESP 研究案例的對立假設主張，其實對應許多可能的 <span class="math inline">\(\theta\)</span> 值，只要是除了 0.5 之外，每個 <span class="math inline">\(\theta\)</span> 值都可以支持對立假設。若是某位參與者 選擇正確答案的真實機率為 55%（也就是 <span class="math inline">\(\theta = .55\)</span>）。若是如此， <span class="math inline">\(X\)</span> 的取樣分佈就不是虛無假設所預測的分佈，因為 <span class="math inline">\(X\)</span> 的最有可能的數值是 <span class="math inline">\(100\)</span> 次中有 <span class="math inline">\(55\)</span> 次。不僅如此，整個取樣分佈也偏移了，如同 <a href="#fig-fig9-5">图&nbsp;<span>9.5</span></a> 的展示。當然，棄絕域並不會改變。根據定義，棄卻域是根據虛無假設的主張所設定的。從 <a href="#fig-fig9-5">图&nbsp;<span>9.5</span></a> 看到的是，當虛無假設不成立， <span class="math inline">\(\theta = .55\)</span> 的取樣分佈內有很高的比例屬於棄卻域。 的確，當虛無假設主張不成立時，拒絕虛無假設的機率相對更大！然而，<span class="math inline">\(\theta = .55\)</span> 並不是唯一符合對立假設的可能值。現在讓我們看看 <span class="math inline">\(\theta\)</span> 的真實數值是 <span class="math inline">\(0.7\)</span>，取樣分佈會變成什麼樣子？如同 <a href="#fig-fig9-6">图&nbsp;<span>9.6</span></a> 的展示，當 <span class="math inline">\(\theta = 0.7\)</span> 時，幾乎整個取樣分佈都落在棄卻域裡。因此，如果 <span class="math inline">\(\theta = 0.7\)</span>，我們正確拒絕虛無假設的機率（即檢定力）比 <span class="math inline">\(\theta = 0.55\)</span> 要大得多。簡而言之，雖然 <span class="math inline">\(\theta = .55\)</span> 和 <span class="math inline">\(\theta = .70\)</span> 都是支持對立假設的實驗結果，但型二錯誤率是不相等的。</p>
<!--- Let's take a moment to think about what a Type II error actually is. A Type II error occurs when the alternative hypothesis is true, but we are nevertheless unable to reject the null hypothesis. Ideally, we'd be able to calculate a single number $\beta$ that tells us the Type II error rate, in the same way that we can set $\alpha = .05$ for the Type I error rate. Unfortunately, this is a lot trickier to do. To see this, notice that in my ESP study the alternative hypothesis actually corresponds to lots of possible values of $\theta$. In fact, the alternative hypothesis corresponds to every value of $\theta$ except 0.5. Let's suppose that the true probability of someone choosing the correct response is 55% (i.e., $\theta = .55$). If so, then the true sampling distribution for $X$ is not the same one that the null hypothesis predicts, as the most likely value for $X$ is now $55$ out of 100. Not only that, the whole sampling distribution has now shifted, as shown in @fig-fig9-5. The critical regions, of course, do not change. By definition the critical regions are based on what the null hypothesis predicts. What we're seeing in this figure is the fact that when the null hypothesis is wrong, a much larger proportion of the sampling distribution distribution falls in the critical region. And of course that's what should happen. The probability of rejecting the null hypothesis is larger when the null hypothesis is actually false! However $\theta = .55$ is not the only possibility consistent with the alternative hypothesis. Let's instead suppose that the true value of $\theta$ is actually $0.7$. What happens to the sampling distribution when this occurs? The answer, shown in @fig-fig9-6, is that almost the entirety of the sampling distribution has now moved into the critical region. Therefore, if $\theta = 0.7$, the probability of us correctly rejecting the null hypothesis (i.e., the power of the test) is much larger than if $\theta = 0.55$. In short, while $\theta = .55$ and $\theta = .70$ are both part of the alternative hypothesis, the Type II error rate is different. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="fig-fig9-6" class="quarto-figure quarto-figure-left anchored">
<figure class="figure">
<p><img src="images/fig9-6.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">图&nbsp;9.6: 對立假設主張母群參數 <span class="math inline">\(\theta=0.70\)</span> 的取樣分佈，幾乎整個分佈都在棄絕域內。</figcaption>
</figure>
</div>
</div>
</div>
<p>這樣討論下來，我們知道假設檢定的考驗力（即<span class="math inline">\(1-\beta\)</span>）取決於 <span class="math inline">\(\theta\)</span> 的真實數值。為了清楚說明這一點，我已經算出所有 <span class="math inline">\(\theta\)</span> 值可拒絕虛無假設的預期機率，繪製出 <a href="#fig-fig9-7">图&nbsp;<span>9.7</span></a> 。圖中的曲線通常稱為假設檢定的考驗力函數。這是一個能評估檢定方法品質的好工具，因為函數列出所有可能的 <span class="math inline">\(\theta\)</span> 值可達到的考驗力（<span class="math inline">\(1-\beta\)</span>）。正如圖中顯示，當 <span class="math inline">\(\theta\)</span> 的真實值越接近 <span class="math inline">\(0.5\)</span> 時，檢定的考驗力會急劇降低，遠離 <span class="math inline">\(0.5\)</span> 的話，考驗力就越大。</p>
<!--- What all this means is that the power of a test (i.e., $1 - \beta$) depends on the true value of $\theta$. To illustrate this, I've calculated the expected probability of rejecting the null hypothesis for all values of $\theta$, and plotted it in @fig-fig9-7. This plot describes what is usually called the power function of the test. It's a nice summary of how good the test is, because it actually tells you the power $(1 - \beta$) for all possible values of $\theta$. As you can see, when the true value of $\theta$ is very close to $0.5$, the power of the test drops very sharply, but when it is further away, the power is large. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="fig-fig9-7" class="quarto-figure quarto-figure-left anchored">
<figure class="figure">
<p><img src="images/fig9-7.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">图&nbsp;9.7: 如果真正的<span class="math inline">\(\theta\)</span>值不同於虛無假設所主 張的值（<span class="math inline">\(\theta=0.5\)</span>），我們能拒絕虛無假設的機率，也就是檢定的考驗力。可以明顯看出，當<span class="math inline">\(\theta\)</span>與<span class="math inline">\(\theta=0.5\)</span>差異越大，假設檢定的考驗力更高（正確拒絕虛無假設的機率更高）。需要注意的是，當<span class="math inline">\(\theta\)</span>確實等於<span class="math inline">\(0.5\)</span>時（以黑點表示），虛無假設實際上是成立的，此時拒絕虛無假設所犯的錯誤就是型一錯誤。</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="估計考驗力的功用" class="level3" data-number="9.8.2">
<h3 data-number="9.8.2" class="anchored" data-anchor-id="估計考驗力的功用"><span class="header-section-number">9.8.2</span> 估計考驗力的功用</h3>
<blockquote class="blockquote">
<p><em>Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned with mice when there are tigers abroad</em><br>
- George Box <a href="https://www.amazon.fr/Tract-Monetary-Reform-Maynard-Keynes/dp/1607960818" target="_blank">(Box 1976, p.&nbsp;792)</a></p>
</blockquote>
<p><a href="#fig-fig9-7">图&nbsp;<span>9.7</span></a> 展示了我們能執行假設檢定的最基本條件 。如果實際狀態和虛無假設預測的狀態非常不同，那麼考驗力會非常高；但是如果實際狀態和虛無假設預測的非常相似（但不完全相同），那麼考驗力會非常低。所以，為了能讓科學家們能方便估計考驗力，統計學家發展出一些方法量化實際狀態與虛無假設之間的“相似程度”。這種統計方法就是<strong>效果量(effect size)</strong>的測量（例如 <span class="citation" data-cites="Cohen1988">Cohen (<a href="References.html#ref-Cohen1988" role="doc-biblioref">1988</a>)</span>; <span class="citation" data-cites="Ellis2010">Ellis (<a href="References.html#ref-Ellis2010" role="doc-biblioref">2010</a>)</span>）。效果量在不同的研究中的定義可能略有不同（因此，本節僅討論一般性的定義），但是各種定義嘗試捕捉的質性想法始終一致（參考 <a href="#tbl-tab9-6">表格&nbsp;<span>9.6</span></a> ）。其中一種就像本章討論的ESP案例：真實的母群參數數值與虛無假設的參數數值之間差異有多大？如果讓 <span class="math inline">\(\theta_0 = 0.5\)</span> 表示虛無假設的參數值， <span class="math inline">\(\theta\)</span> 表示母群參數的真實數值，那麼測量效果量的方式就是計算兩種數值之間的差異（即<span class="math inline">\(\theta - \theta_0\)</span>），或者數值差異的絕對值，<span class="math inline">\(abs(\theta - \theta_0)\)</span>。</p>
<!--- The plot shown in @fig-fig9-7 captures a fairly basic point about hypothesis testing. If the true state of the world is very different from what the null hypothesis predicts then your power will be very high, but if the true state of the world is similar to the null (but not identical) then the power of the test is going to be very low. Therefore, it's useful to be able to have some way of quantifying how "similar" the true state of the world is to the null hypothesis. A statistic that does this is called a measure of **effect size** (e.g., @Cohen1988; @Ellis2010). Effect size is defined slightly differently in different contexts (and so this section just talks in general terms) but the qualitative idea that it tries to capture is always the same (see e.g. @tbl-tab9-6). How big is the difference between the *true* population parameters and the parameter values that are assumed by the null hypothesis? In our ESP example, if we let $\theta_0 = 0.5$ denote the value assumed by the null hypothesis and let $\theta$ denote the true value, then a simple measure of effect size could be something like the difference between the true value and null (i.e., $\theta - \theta_0$), or possibly just the magnitude of this difference, $abs(\theta - \theta_0)$. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="tbl-tab9-6" class="anchored">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>表格&nbsp;9.6: 關於統計顯著性和效果量之間關係的簡單解讀指南。如果你沒有得到顯著的結果，基本上效果量多少就沒什麼意義，因為你沒有表明真的有效果的任何證據。另一方面，如果你得到一個顯著的效果，但是效果量很小，那麼你的研究結果（雖然是真實的）可能並不太值得注意。不過，由於這只是非常粗略的指南，結果有沒有意思主要取決於研究的具體內容。在某些情況下，即使效果量很小，仍可能具有重大的實用意義。因此，不要太過認真地看待這份指南，只是讓初學者有一個粗略的概念而已。</caption>
<thead>
<tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">X.</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">效果量大</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">效果量小</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">有顯著結果</td>
<td style="text-align: center;">確實發現差異，且有實用意義</td>
<td style="text-align: center;">確實發現差異，但未必有實用意義</td>
</tr>
<tr class="even">
<td style="text-align: center;">無顯著結果</td>
<td style="text-align: center;">未發現差異</td>
<td style="text-align: center;">未發現差異</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>為什麼要計算效果量？假設你已經進行實驗，收集完資料，進行假設檢定而得到了一個顯著性的結果。那麼你宣稱得到了一個明顯的效果，研究就結束嗎？這不就是假設檢定的功能嗎？當然不完全是。同學們現在應該會同意，進行假設檢定的目的是試圖證明虛無假設是錯誤的，但這並不是我們做研究唯一關注的事情。如果虛無假設主張<span class="math inline">\(\theta=0.5\)</span>，然後我們證實這是錯誤的，我們只是講完了一半的故事。拒絕虛無假設表示我們相信<span class="math inline">\(\theta \neq 0.5\)</span>，但是<span class="math inline">\(\theta=0.51\)</span>和<span class="math inline">\(\theta=0.8\)</span>之間存在很大的差異。如果實驗結果是<span class="math inline">\(\theta=0.8\)</span>，那麼虛無假設不僅僅是錯了，還錯得非常離譜。另一方面，若是我們成功地拒絕虛無假設，但是<span class="math inline">\(\theta\)</span>的真實數值似乎只有0.51（這只有在規模非常大的研究中才可能發生）。這個情況的虛無假設當然是錯的，但是我們並不確定這個結果是否值得注意，因為效果量非常地小。以我創造的ESP研究案例來說，我們可能仍然感到興趣，因為證實人類真的有超能力是相當酷的事<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>，但是在大多數研究的狀況，即使結果顯示有<span class="math inline">\(1%\)</span>的顯著差異，就算是真的有差異，通常也不是值得注意的發現。例如，假如我們今天研究了男女高中生的考試成績差異，結果發現女學生的平均成績比男生高<span class="math inline">\(1%\)</span>。若是我有來自成千上萬名學生的資料，那麼這種差異幾乎肯定是有統計顯著性，但是無論<em>p</em>值有多小，這種差異都沒什麼意思。沒有人敢根據如此微小的差異，宣稱一個國家出現了青少年教育危機吧？正是因為這個原因，越來越多的研究者使用某種效果量的標準尺度，與假設檢定的結果並列報告。假設檢定只有告訴我們，應不應該相信所觀察到的效果是不是真實的（即不僅僅是偶然的），而效果量則透露是不是應該關心這種效果。</p>
<!---Why calculate effect size? Let's assume that you've run your experiment, collected the data, and gotten a significant effect when you ran your hypothesis test. Isn't it enough just to say that you've gotten a significant effect? Surely that's the point of hypothesis testing? Well, sort of. Yes, the point of doing a hypothesis test is to try to demonstrate that the null hypothesis is wrong, but that's hardly the only thing we're interested in. If the null hypothesis claimed that $\theta = .5$ and we show that it's wrong, we've only really told half of the story. Rejecting the null hypothesis implies that we believe that $\theta \neq .5$, but there's a big difference between $\theta = .51$ and $\theta = .8$. If we find that $\theta = .8$, then not only have we found that the null hypothesis is wrong, it appears to be very wrong. On the other hand, suppose we've successfully rejected the null hypothesis, but it looks like the true value of $\theta$ is only .51 (this would only be possible with a very large study). Sure, the null hypothesis is wrong but it's not at all clear that we actually care because the effect size is so small. In the context of my ESP study we might still care since any demonstration of real psychic powers would actually be pretty cool[^09-hypothesis-testing-10], but in other contexts a $1\%$ difference usually isn't very interesting, even if it is a real difference. For instance, suppose we're looking at differences in high school exam scores between males and females and it turns out that the female scores are $1\%$ higher on average than the males. If I've got data from thousands of students then this difference will almost certainly be statistically significant, but regardless of how small the p value is it's just not very interesting. You'd hardly want to go around proclaiming a crisis in boys education on the basis of such a tiny difference would you? It's for this reason that it is becoming more standard (slowly, but surely) to report some kind of standard measure of effect size along with the the results of the hypothesis test. The hypothesis test itself tells you whether you should believe that the effect you have observed is real (i.e., not just due to chance), whereas the effect size tells you whether or not you should care.

[^09-hypothesis-testing-10]: Note that the p here has nothing to do with a $p$ value. The $p$ argument in the jamovi binomial test corresponds to the probability of making a correct response, according to the null hypothesis. In other words, it's the $\theta$ value. --->
</section>
<section id="增加研究考驗力的方案" class="level3" data-number="9.8.3">
<h3 data-number="9.8.3" class="anchored" data-anchor-id="增加研究考驗力的方案"><span class="header-section-number">9.8.3</span> 增加研究考驗力的方案</h3>
<p>毫不意外地，現代科學家非常關心如何最大幅度提高實驗的考驗力。我們都希望實驗能夠成功，因此期望虛無假設不成立的話，能夠最大幅度地增加拒絕的機會（當然，我們通常希望虛無假設是錯誤的！）。正如前一節討論的，影響考驗力的因素之一是效果量。因此，增加考驗力的首選方案就是增加效果量。這表示在研究實務，我們所設計的研究能使效果量放到最大。以ESP研究為例，我也許認為超感官能力在安靜、昏暗的房間裡，且要儘量減少干擾，才能得到最佳實驗效果。因此，我會嘗試在這樣的環境裡進行實驗。如果我的實驗方式確實能增強人類的ESP能力，那麼<span class="math inline">\(\theta\)</span>的真實數值就會增加<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>，就能提高效果量。簡而言之，巧妙的實驗設計是提高考驗力的一種方式，因為實驗設計可以改變效果量。</p>
<p>不幸的是，即使擁有最佳的實驗設計，大部分的研究只能得到微小效果。例如，超感官知覺也許確實存在，但是即使在最佳的設計條件測試，效果量也非常微弱。遇到這種情況，增加樣本量是增加考驗力的最佳方案。一般來說，收集越多觀察值，就越有可能區分兩種假設。比如說我找了10位參與者進行超感官知覺實驗，其中7人正確答出隱藏卡片的顏色，這樣的結果可能不會令人印象深刻。但是如果我找了10,000位參與者進行實驗，其中7,000人猜對了，這樣的結果更有可能讓人覺得是件大事。換句話說，樣本量增加，考驗力也會增加。<a href="#fig-fig9-8">图&nbsp;<span>9.8</span></a> 展示了兩者的關係，對於參數真實數值 <span class="math inline">\(\theta = 0.7\)</span> ，該圖顯示從1到100的所有樣本量<span class="math inline">\(N\)</span>的檢定力，其中虛無假設預測 <span class="math inline">\(\theta_0 = 0.5\)</span> 。</p>

<!--- Not surprisingly, scientists are fairly obsessed with maximising the power of their experiments. We want our experiments to work and so we want to maximise the chance of rejecting the null hypothesis if it is false (and of course we usually want to believe that it is false!). As we've seen, one factor that influences power is the effect size. So the first thing you can do to increase your power is to increase the effect size. In practice, what this means is that you want to design your study in such a way that the effect size gets magnified. For instance, in my ESP study I might believe that psychic powers work best in a quiet, darkened room with fewer distractions to cloud the mind. Therefore I would try to conduct my experiments in just such an environment. If I can strengthen people's ESP abilities somehow then the true value of $\theta$ will go up [^09-hypothesis-testing-11] and therefore my effect size will be larger. In short, clever experimental design is one way to boost power, because it can alter the effect size.

[^09-hypothesis-testing-11]: Notice that the true population parameter $\theta$ doesn't necessarily correspond to an immutable fact of nature. In this context $\theta$ is just the true probability that people would correctly guess the colour of the card in the other room. As such the population parameter can be influenced by all sorts of things. Of course, this is all on the assumption that ESP actually exists!

Unfortunately, it's often the case that even with the best of experimental designs you may have only a small effect. Perhaps, for example, ESP really does exist but even under the best of conditions it's very very weak. Under those circumstances your best bet for increasing power is to increase the sample size. In general, the more observations that you have available, the more likely it is that you can discriminate between two hypotheses. If I ran my ESP experiment with 10 participants and 7 of them correctly guessed the colour of the hidden card you wouldn't be terribly impressed. But if I ran it with 10,000 participants, and 7,000 of them got the answer right, you would be much more likely to think I had discovered something. In other words, power increases with the sample size. This is illustrated in @fig-fig9-8, which shows the power of the test for a true parameter of $\theta = 0.7$ for all sample sizes $N$ from $1$ to $100$, where I'm assuming that the null hypothesis predicts that $\theta_0 = 0.5$. --->
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div id="fig-fig9-8" class="quarto-figure quarto-figure-left anchored">
<figure class="figure">
<p><img src="images/fig9-8.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">图&nbsp;9.8: ESP研究的二項式檢定考驗力與樣本量 <span class="math inline">\(N\)</span> 函式關係視覺化。此圖的繪製條件還有 <span class="math inline">\(\theta\)</span> 的真實數值為0.7，但是虛無假設主張 <span class="math inline">\(\theta = 0.5\)</span> 。總體來說，樣本數 <span class="math inline">\(N\)</span> 越大，考驗力越高。(註：曲線裡的鋸齒是因為 <span class="math inline">\(\theta\)</span> ， <span class="math inline">\(\alpha\)</span> ，以及二項分佈是間斷機率分佈的本質等條件，交互運作而造成的，不過整體來說不影響我想表達的目的。)</figcaption>
</figure>
</div>
</div>
</div>
<p>因為考驗力很重要，規劃一個實驗的執行細節時，知道可能有多少考驗力會非常有用。當然，因為無法確定真正的效果量有多少，我們無法得知考驗力會有多高，但是有時候我們可以評估考驗力應該要有多大。能做到的話，我們就可以評估需要多大的樣本量！這種方案叫做<strong>考驗力分析</strong>，做得好的話，對於設計實驗會非常有用。有用的考驗力分析結果包括能成功執行實驗所需要的時間或金錢是否足夠等資訊。現在越來越多的研究者同意，考驗力分析應該成為實驗設計的必要部分，因此值得好好了解如何執行。然而，本書沒有打算介紹考驗力分析。有部分理由是講出來很無聊，還有部分是實質性的理由。無聊的理由是原作者還沒有時間去寫關於考驗力分析的介紹。實質理由是原作者對於考驗力分析的方法還有些懷疑的地方。作為一位研究者，我幾乎沒做過考驗力分析。我認為可能是因為 (a) 我的實驗經常有些非常規條件 ，不曉得如何正確地定義效果量，還有 (b) 我對研究結果的效果量實在是一無所知，不知道如何解釋分析結果。此外，我常與一位擔任統計諮詢師廣泛交流（其實就是我老婆），她實際接過的案子裡，只有要撰寫申請補助經費的計畫書的客戶才會詢問怎麼做考驗力分析。換句話說，在現實的研究場景，科學家們似乎只有被特別要求時才需要進行考驗力分析，而且考驗力分析並不是日常科研工作的一部分。簡而言之，我同意考驗力是一個重要的概念，但是考驗力分析並不像人們所說的那麼有用，除非在少數情況。像是（a）已經有方法能計算你要執行的實驗設計考驗力，（b）你對要測量的效果量可能大小有很好的想法<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>。也許其他研究者比我幸運，但我個人從未遇到過(a)和(b)都成立的情況。未來我的想法也許會改變，這本書的更新版本就會有章節介紹詳細考驗力分析，但是以目前來說，這是我編寫這個主題最心安理得的處理方式。<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>

<!--- Because power is important, whenever you're contemplating running an experiment it would be pretty useful to know how much power you're likely to have. It's never possible to know for sure since you can't possibly know what your real effect size is. However, it's often (well, sometimes) possible to guess how big it should be. If so, you can guess what sample size you need! This idea is called **power analysis**, and if it's feasible to do it then it's very helpful. It can tell you something about whether you have enough time or money to be able to run the experiment successfully. It's increasingly common to see people arguing that power analysis should be a required part of experimental design, so it's worth knowing about. I don't discuss power analysis in this book, however. This is partly for a boring reason and partly for a substantive one. The boring reason is that I haven't had time to write about power analysis yet. The substantive one is that I'm still a little suspicious of power analysis. Speaking as a researcher, I have very rarely found myself in a position to be able to do one. It's either the case that (a) my experiment is a bit non-standard and I don't know how to define effect size properly, or (b) I literally have so little idea about what the effect size will be that I wouldn't know how to interpret the answers. Not only that, after extensive conversations with someone who does stats consulting for a living (my wife, as it happens), I can't help but notice that in practice the only time anyone ever asks her for a power analysis is when she's helping someone write a grant application. In other words, the only time any scientist ever seems to want a power analysis in real life is when they're being forced to do it by bureaucratic process. It's not part of anyone's day to day work. In short, I've always been of the view that whilst power is an important concept, power analysis is not as useful as people make it sound, except in the rare cases where (a) someone has figured out how to calculate power for your actual experimental design and (b) you have a pretty good idea what the effect size is likely to be.[^09-hypothesis-testing-12] Maybe other people have had better experiences than me, but I've personally never been in a situation where both (a) and (b) were true. Maybe I'll be convinced otherwise in the future, and probably a future version of this book would include a more detailed discussion of power analysis, but for now this is about as much as I'm comfortable saying about the topic.

[^09-hypothesis-testing-12]: One possible exception to this is when researchers study the effectiveness of a new medical treatment and they specify in advance what an important effect size would be to detect, for example over and above any existing treatment. In this way some information about the potential value of a new treatment can be obtained. --->
</section>
</section>
<section id="值得繼續學習的主題" class="level2" data-number="9.9">
<h2 data-number="9.9" class="anchored" data-anchor-id="值得繼續學習的主題"><span class="header-section-number">9.9</span> 值得繼續學習的主題</h2>
<blockquote class="blockquote">
<p><strong>譯者註</strong> 20230418初步以ChatGPT-4完成翻譯，內容待編修。</p>
</blockquote>
<p>在本章中，我向您描述的是虛無假設顯著性檢驗（NHST）的正統框架。理解NHST如何運作是絕對必要的，因為自20世紀初成為主流以來，它一直是主要的推論統計方法。這是絕大多數在職科學家依賴的數據分析方法，因此即使您討厭它，也需要了解它。然而，這種方法並非沒有問題。框架中存在一些怪異之處，其產生的歷史奇觀，關於框架是否正確的理論爭議，以及對不慎的人來說有很多實際陷阱。我不打算詳細討論這個主題，但我認為簡要討論一下這些問題是值得的。</p>
<!--- What I've described to you in this chapter is the orthodox framework for null hypothesis significance testing (NHST). Understanding how NHST works is an absolute necessity because it has been the dominant approach to inferential statistics ever since it came to prominence in the early 20th century. It's what the vast majority of working scientists rely on for their data analysis, so even if you hate it you need to know it. However, the approach is not without problems. There are a number of quirks in the framework, historical oddities in how it came to be, theoretical disputes over whether or not the framework is right, and a lot of practical traps for the unwary. I'm not going to go into a lot of detail on this topic, but I think it's worth briefly discussing a few of these issues. --->
<section id="尼曼與費雪" class="level3" data-number="9.9.1">
<h3 data-number="9.9.1" class="anchored" data-anchor-id="尼曼與費雪"><span class="header-section-number">9.9.1</span> 尼曼與費雪</h3>
<p>您首先應該知道的是，正統虛無假設檢定實際上是將羅納德·費雪爵士和傑茲·尼曼提出的兩種相當不同的假設檢定方法混合在一起（有關歷史概要，請參見 <span class="citation" data-cites="Lehmann2011">Lehmann (<a href="References.html#ref-Lehmann2011" role="doc-biblioref">2011</a>)</span> ）。歷史很混亂，因為費雪和尼曼是現實生活中的人，他們的觀點會隨著時間而改變，而且他們都沒有提供“如何解釋幾十年後他們的工作的明確說法”。也就是說，這是我對這兩種方法的快速總結。</p>
<p>首先，讓我們談論費雪的方法。據我所知，費雪假設您只有一個假設（虛無假設），您想做的是找出虛無假設是否與數據不一致。從他的角度來看，您應該做的是檢查數據是否根據虛無假設是“足夠不可能”。實際上，如果您回想一下我們之前的討論，這就是費雪如何定義p值的。根據費雪的說法，如果虛無假設對數據的解釋非常差，那麼您可以放心地拒絕它。但是，由於您無法將其與其他假設進行比較，因此無法“接受對立假設”，因為您不一定有一個明確陳述的對立假設。這就是所有的內容。</p>
<p>相比之下，尼曼認為假設檢定的目的是作為行動指南，他的方法比費雪的更正式。他認為，您可以做很多事情（接受虛無假設或接受對立假設），檢驗的目的是告訴您數據支持哪一個。從這個角度來看，確定對立假設至關重要。如果您不知道對立假設是什麼，那麼您就不知道測試的有效性，甚至不知道哪個動作是有意義的。他的框架確實需要不同假設之間的競爭。對於尼曼來說，<span class="math inline">\(p\)</span>值並未直接衡量在虛無假設下的數據（或更極端的數據）的機率，而更像是一個抽象描述，關於哪些“可能的測試”告訴您接受虛無假設，以及哪些“可能的測試”告訴您接受對立假設。</p>
<p>如您所見，今天的虛無假設檢定是兩者之間的奇怪混合物。我們談論擁有虛無假設和對立假設（尼曼），但通常[^09-hypothesis-testing-13]根據極端數據來定義<span class="math inline">\(p\)</span>值（費雪），但我們仍然有α值（尼曼）。部分統計檢驗具有明確指定的對立假設（尼曼），但其他則相對含糊（費雪）。至少根據某些人的看法，我們不允許談論接受對立假設（費雪）。假設檢定是至今還是一團混亂的統計學歷史遺產，但我希望這至少能解釋為什麼會這樣。</p>
<p>[^09-hypothesis-testing-13]：儘管這本書描述了尼曼和費雪對<span class="math inline">\(p\)</span>值的定義，但大多數不會。大多數入門教材只會給你費雪版本。</p>
<!--- The first thing you should be aware of is that orthodox NHST is actually a mash-up of two rather different approaches to hypothesis testing, one proposed by Sir Ronald Fisher and the other proposed by Jerzy Neyman (see @Lehmann2011 for a historical summary). The history is messy because Fisher and Neyman were real people whose opinions changed over time, and at no point did either of them offer "the definitive statement" of how we should interpret their work many decades later. That said, here's a quick summary of what I take these two approaches to be.

First, let's talk about Fisher's approach. As far as I can tell, Fisher assumed that you only had the one hypothesis (the null) and that what you want to do is find out if the null hypothesis is inconsistent with the data. From his perspective, what you should do is check to see if the data are "sufficiently unlikely" according to the null. In fact, if you remember back to our earlier discussion, that's how Fisher defines the p-value. According to Fisher, if the null hypothesis provided a very poor account of the data then you could safely reject it. But, since you don't have any other hypotheses to compare it to, there's no way of "accepting the alternative" because you don't necessarily have an explicitly stated alternative. That's more or less all there is to it.

In contrast, Neyman thought that the point of hypothesis testing was as a guide to action and his approach was somewhat more formal than Fisher's. His view was that there are multiple things that you could do (accept the null or accept the alternative) and the point of the test was to tell you which one the data support. From this perspective, it is critical to specify your alternative hypothesis properly. If you don't know what the alternative hypothesis is, then you don't know how powerful the test is, or even which action makes sense. His framework genuinely requires a competition between different hypotheses. For Neyman, the $p$ value didn't directly measure the probability of the data (or data more extreme) under the null, it was more of an abstract description about which "possible tests" were telling you to accept the null, and which "possible tests" were telling you to accept the alternative.

As you can see, what we have today is an odd mishmash of the two. We talk about having both a null hypothesis and an alternative (Neyman), but usually[^09-hypothesis-testing-13] define the $p$ value in terms of exreme data (Fisher), but we still have $\alpha$ values (Neyman). Some of the statistical tests have explicitly specified alternatives (Neyman) but others are quite vague about it (Fisher). And, according to some people at least, we're not allowed to talk about accepting the alternative (Fisher). It's a mess, but I hope this at least explains why it's a mess.

[^09-hypothesis-testing-13]: Although this book describes both Neyman's and Fisher's definition of the $p$ value, most don't. Most introductory textbooks will only give you the Fisher version. --->
</section>
<section id="貝氏統計與次數主義統計" class="level3" data-number="9.9.2">
<h3 data-number="9.9.2" class="anchored" data-anchor-id="貝氏統計與次數主義統計"><span class="header-section-number">9.9.2</span> 貝氏統計與次數主義統計</h3>
<p>在<a href="09-Hypothesis-testing.html#sec-The-p-value-of-a-test">統計檢定的<em>p</em>值</a>這一節，我強調不能將<em>p</em>值解釋為虛無假設為真的機率。NHST基本上是一個頻率主義工具（參見@sec-Introduction-to-probability），因此它不允許您為假設分配機率。虛無假設要么是對的，要么是錯的。貝氏統計方法將機率解釋為信念程度，因此完全可以說虛無假設為真的機率是<span class="math inline">\(10\%\)</span>。這只是反映了您對這個假設的信心程度。在頻率主義方法中，您不能這樣做。請記住，如果您是頻率主義者，機率只能根據大量獨立重複實驗（即長期頻率）來定義。如果這是您對機率的解釋，那麼談論“虛無假設的機率”就是完全無意義的：虛無假設要么是對的，要么是錯的。您無法將這個陳述的長期頻率表達出來。談論“虛無假設的機率”就像談論“自由的顏色”一樣無意義。它沒有顏色！</p>
<p>最重要的是，這不僅僅是一個純粹的意識形態問題。如果您決定成為貝氏學派，並且您可以對假設做出機率陳述，那麼您必須遵循貝氏規則來計算這些機率。在 <a href="16-Bayesian-statistics.html"><span>章节&nbsp;16</span></a> 中我將進一步談論這個問題，但目前我想指出的是，p值對於<span class="math inline">\(H_0\)</span>為真的機率是一個糟糕的近似。如果您想知道虛無假設的機率，那麼p值並非您要尋找的東西！</p>
<!--- Earlier on in this chapter I was quite emphatic about the fact that you *cannot* interpret the p value as the probability that the null hypothesis is true. NHST is fundamentally a frequentist tool (see @sec-Introduction-to-probability) and as such it does not allow you to assign probabilities to hypotheses. The null hypothesis is either true or it is not. The Bayesian approach to statistics interprets probability as a degree of belief, so it's totally okay to say that there is a $10\%$ chance that the null hypothesis is true. That's just a reflection of the degree of confidence that you have in this hypothesis. You aren't allowed to do this within the frequentist approach. Remember, if you're a frequentist, a probability can only be defined in terms of what happens after a large number of independent replications (i.e., a long run frequency). If this is your interpretation of probability, talking about the "probability" that the null hypothesis is true is complete gibberish: a null hypothesis is either true or it is false. There's no way you can talk about a long run frequency for this statement. To talk about "the probability of the null hypothesis" is as meaningless as "the colour of freedom". It doesn't have one!

Most importantly, this isn't a purely ideological matter. If you decide that you are a Bayesian and that you're okay with making probability statements about hypotheses, you have to follow the Bayesian rules for calculating those probabilities. I'll talk more about this in @sec-Bayesian-statistics, but for now what I want to point out to you is the p value is a terrible approximation to the probability that $H_0$ is true. If what you want to know is the probability of the null, then the p value is not what you're looking for! --->
</section>
<section id="決策陷阱" class="level3" data-number="9.9.3">
<h3 data-number="9.9.3" class="anchored" data-anchor-id="決策陷阱"><span class="header-section-number">9.9.3</span> 決策陷阱</h3>
<p>如您所見，假設檢定背後的理論是一團糟，甚至到現在統計學家們還在爭論它“應該”如何運作。然而，統計學家之間的分歧不是我們真正關心的問題。我們真正關心的是實用數據分析。儘管“正統”的虛無假設顯著性檢驗存在許多缺陷，但即使是像我這樣毫不猶豫的貝氏學者也會同意，如果使用得當，它們是有用的。大多數時候，它們會給出合理的答案，並且您可以用它們來學習有趣的事物。撇開我們已經討論過的各種意識形態和歷史混亂，事實仍然是統計中最大的危險在於<em>不加思考</em>。我不是指愚蠢，而是字面意思上的不加思考。在沒有花時間考慮每個檢驗實際上對數據說了什麼，以及檢查這是否與您的解釋一致的情況下，匆忙地解釋結果。這就是最大的陷阱所在。</p>
<p>舉個例子，考慮以下例子（參見 <span class="citation" data-cites="Gelman2006">Gelman &amp; Stern (<a href="References.html#ref-Gelman2006" role="doc-biblioref">2006</a>)</span> ）。假設我正在進行ESP研究，並且我已經決定分別為男性參與者和女性參與者分析數據。在男性參與者中，有<span class="math inline">\(33\)</span>人中的<span class="math inline">\(50\)</span>人猜對了卡片的顏色。這是一個顯著效應（<span class="math inline">\(p=.03\)</span>）。在女性參與者中，有<span class="math inline">\(29\)</span>人中的<span class="math inline">\(50\)</span>人猜對了。這不是一個顯著效應（<span class="math inline">\(p=.32\)</span>）。看到這一點，人們極其想知道為什麼男性和女性在通靈能力方面存在差異。然而，這是錯誤的。如果你仔細想想，我們實際上並沒有運行一個明確比較男性和女性的測試。我們所做的一切就是將男性與機會進行比較（二項檢驗顯著）和將女性與機會進行比較（二項檢驗不顯著）。如果我們想要認為男性和女性之間存在實際差異，我們可能應該運行一個虛無假設沒有差異的檢驗！我們可以使用另一種假設檢定<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>，但是當我們這樣做時，事實證明，我們並沒有證據表明男性和女性之間存在顯著差異（<span class="math inline">\(p=.54\)</span>）。現在，您是否認為兩組之間存在根本差異？當然不是。這裡發生的情況是，兩組數據（男性和女性）都非常接近邊界。純粹憑機運，其中一組恰好落在<span class="math inline">\(p=.05\)</span>這條神奇的線上，而另一組則沒有。這並不意味著男性和女性之間存在差異。這個錯誤非常普遍，您應該時刻警惕。顯著與不顯著之間的差異並不能證明存在實際差異。如果您想說兩組之間存在差異，那麼您必須測試該差異！</p>
<p>上面的例子僅僅是一個例子。我將其單獨拿出來，因為它非常常見，但更大的畫面是數據分析可能很難做對。思考您要測試什麼，<u>為什麼</u>要測試它，以及您的測試結果是否可能在現實世界中有意義。</p>
<!--- As you can see, the theory behind hypothesis testing is a mess, and even now there are arguments in statistics about how it "should" work. However, disagreements among statisticians are not our real concern here. Our real concern is practical data analysis. And while the "orthodox" approach to null hypothesis significance testing has many drawbacks, even an unrepentant Bayesian like myself would agree that they can be useful if used responsibly. Most of the time they give sensible answers and you can use them to learn interesting things. Setting aside the various ideologies and historical confusions that we've discussed, the fact remains that the biggest danger in all of statistics is *thoughtlessness*. I don't mean stupidity, I literally mean thoughtlessness. The rush to interpret a result without spending time thinking through what each test actually says about the data, and checking whether that's consistent with how you've interpreted it. That's where the biggest trap lies.

To give an example of this, consider the following example (see @Gelman2006). Suppose I'm running my ESP study and I've decided to analyse the data separately for the male participants and the female participants. Of the male participants, $33$ out of $50$ guessed the colour of the card correctly. This is a significant effect ($p = .03$). Of the female participants, $29$ out of $50$ guessed correctly. This is not a significant effect ($p = .32$). Upon observing this, it is extremely tempting for people to start wondering why there is a difference between males and females in terms of their psychic abilities. However, this is wrong. If you think about it, we haven't actually run a test that explicitly compares males to females. All we have done is compare males to chance (binomial test was significant) and compared females to chance (binomial test was non significant). If we want to argue that there is a real difference between the males and the females, we should probably run a test of the null hypothesis that there is no difference! We can do that using a different hypothesis test,[^09-hypothesis-testing-14] but when we do that it turns out that we have no evidence that males and females are significantly different ($p = .54$). Now do you think that there's anything fundamentally different between the two groups? Of course not. What's happened here is that the data from both groups (male and female) are pretty borderline. By pure chance one of them happened to end up on the magic side of the $p = .05$ line, and the other one didn't. That doesn't actually imply that males and females are different. This mistake is so common that you should always be wary of it. The difference between significant and not-significant is not evidence of a real difference. If you want to say that there's a difference between two groups, then you have to test for that difference!

[^09-hypothesis-testing-14]: In this case, the Pearson chi-square test of independence (see @sec-Categorical-data-analysis)

The example above is just that, an example. I've singled it out because it's such a common one, but the bigger picture is that data analysis can be tricky to get right. Think about what it is you want to test, <u>why</u> you want to test it, and whether or not the answers that your test gives could possibly make any sense in the real world. --->
</section>
</section>
<section id="本章小結" class="level2" data-number="9.10">
<h2 data-number="9.10" class="anchored" data-anchor-id="本章小結"><span class="header-section-number">9.10</span> 本章小結</h2>
<p>虛無假設檢定是統計理論最普遍的一種應用，科學研究報告結果都會呈現某種假設的檢定。現代科學家幾乎都多少要了解<em>p</em>值的意義，否則不能被認為是合格的科學研究者，所以這一章是本書最重要的部分。以下幫助讀者及學生快速回顧本章重點：</p>
<ul>
<li><a href="09-Hypothesis-testing.html#假設大觀園">假設的層次</a> 研究假設與統計假設。虛無假設與對立假設。</li>
<li><a href="09-Hypothesis-testing.html#兩種決策失誤">兩種決策失誤</a> 型一與型二錯誤<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></li>
<li><a href="09-Hypothesis-testing.html#運用樣本分佈檢測統計值">運用取樣分佈檢測統計值</a>.</li>
<li>統計推論的<a href="09-Hypothesis-testing.html#統計推論的決策要素">決策要素</a><a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a></li>
<li><a href="http://localhost:7933/09-Hypothesis-testing.html#sec-The-p-value-of-a-test">統計檢定的<em>p</em>值</a> 為何用<em>p</em>值做決策是”模擬兩可”。</li>
<li><a href="09-Hypothesis-testing.html#假設檢定的報告格式">假設檢定的報告格式</a></li>
<li><a href="09-Hypothesis-testing.html#假設檢定實作須知">假設檢定實作須知</a><a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a></li>
<li><a href="09-Hypothesis-testing.html#sec-Effect-size-sample-size-and-power">效果量、樣本量、考驗力</a><a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></li>
<li>一些<a href="09-Hypothesis-testing.html#值得繼續學習的主題">值得繼續學習的主題</a></li>
</ul>
<p>到了本書最後一章 <a href="16-Bayesian-statistics.html"><span>章节&nbsp;16</span></a> ，我們會從貝氏統計觀點回顧統計理論與虛無假設檢定，還有介紹幾套非次數主義取向的統計工具。不過我們先暫別抽象的統計理論，接下來的第五部分將學習實用的統計分析方法。</p>
<!---Null hypothesis testing is one of the most ubiquitous elements to statistical theory. The vast majority of scientific papers report the results of some hypothesis test or another. As a consequence it is almost impossible to get by in science without having at least a cursory understanding of what a p-value means, making this one of the most important chapters in the book. As usual, I'll end the chapter with a quick recap of the key ideas that we've talked about:

- [A menagerie of hypotheses]. Research hypotheses and statistical hypotheses. Null and alternative hypotheses.
- [Two types of errors]. Type I and Type II.
- [Test statistics and sampling distributions].
- Hypothesis testing for [Making decisions]
- [The p value of a test]. p-values as "soft" decisions
- [Reporting the results of a hypothesis test]
- [Running the hypothesis test in practice] 
- [Effect size, sample size and power]
- [Some issues to consider] regarding hypothesis testing  

Later in the book, in @sec-Bayesian-statistics, I'll revisit the theory of null hypothesis tests from a Bayesian perspective and introduce a number of new tools that you can use if you aren't particularly fond of the orthodox approach. But for now, though, we're done with the abstract statistical theory, and we can start discussing specific data analysis tools.--->


<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list" style="display: none">
<div id="ref-Cohen1988" class="csl-entry" role="listitem">
Cohen, J. (1988). <em>Statistical Power Analysis for the Behavioral Sciences</em> (2nd 本). Lawrence Erlbaum.
</div>
<div id="ref-Ellis2010" class="csl-entry" role="listitem">
Ellis, P. D. (2010). <em>The Essential Guide to Effect Sizes: Statistical Power, Meta-Analysis, and the Interpretation of Research Results</em>. Cambridge University Press.
</div>
<div id="ref-Gelman2006" class="csl-entry" role="listitem">
Gelman, A., &amp; Stern, H. (2006). The difference between <span>《significant》</span> and <span>《not significant》</span> is not itself statistically significant. <em>The American Statistician</em>, <em>60</em>, 328–331.
</div>
<div id="ref-Lehmann2011" class="csl-entry" role="listitem">
Lehmann, E. L. (2011). <em>Fisher, <span>N</span>eyman, and the Creation of Classical Statistics</em>. Springer.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>這段話引自維根斯坦於1922年出版的專書<em>邏輯哲學論</em>。<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>技術性註記。這一章的敘述與許多入門教材的常見說明有些微不同。經典的虛無假設檢定理論是20世紀初期，由羅納德·費雪和傑茲·尼曼 兩位統計學者<em>分別</em>發展出來的，但是費雪和尼曼對於理論的運作有非常不同的看法。現今大多數教材所採用的檢定理論是兩種觀點的混合。本書的解說方式較接近尼曼的風格，特別在解釋<em>p</em>值意義的部分。<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>在此對真心相信超感官知覺（ESP）存在的朋友說聲抱歉，根據我（原作者）所知道的ESP相關文獻，我認為這種研究是不切實際的。雖然說其中一些研究的設計是嚴謹的，從心理學研究設計的角度來看，這是一個有趣的研究領域。當然，在一個自由國家，只要你願意，你可以花費時間和精力來證實我錯了，但我認為這真的不是一個發揮個人智慧的實在主題。<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>這種比喻只適用像英國、美國或澳洲等採用訴訟辯護制度的國家。據原作者所知，法國的審判制度是完全不同的。<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>關於描述假設檢定結果會使用的詞彙，有一些需要注意的地方。首先，建議要避免使用「證明」(prove)這個詞。統計檢定不能證明一個假設是真的或假的，因為「證明」暗示絕對的確定性，但是統計學中永遠沒有絕對的確定性。這點幾乎所有懂統計的人都會同意(<strong>譯註</strong>:本書中文版一律用「證實」)。然而，還有一些讓人混淆的用語。有些人認為，我們只可以說「拒絕虛無假設」、「未能拒絕虛無假設」或「保留虛無假設」。按照這種思路，我們不可以說「接受對立假設」或「接受虛無假設」。對我而言，這樣說法太過嚴格了。我認為這混淆了虛無假設檢定和卡爾·波普認為科學研究是證偽過程的觀點。儘管證偽主義和虛無假設檢定兩者思路有相似之處，但是不完全一樣。雖然就我個人而言，我認為可以談論接受一個假設（「接受」一個假設並不意味著它一定要是真的，特別是虛無假設所主張的情況），不過許多人會持不同意見。更重要的是，同學們應該曉得這些詞彙的特殊使用方式，這樣在寫自己的報告時就不會手足無措了。<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>嚴格來說，這裡設定的顯著水準其實是 <span class="math inline">\(\alpha = .057\)</span>，這有點太寬鬆了。不過，如果是選擇 <span class="math inline">\(39\)</span> 和 <span class="math inline">\(61\)</span> 做為臨界值，那麼棄卻域只會涵蓋分佈的 <span class="math inline">\(3.5%\)</span>。原作者覺得使用 <span class="math inline">\(40\)</span> 和 <span class="math inline">\(60\)</span> 作為臨界值更好討論，並願意容忍 <span class="math inline">\(5.7%\)</span> 的型一錯誤率，因為這是最接近 <span class="math inline">\(\alpha = .05\)</span> 的整數了。<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>原作者在網路找到的資訊都是說這是Ashley說的，但是無法找到可靠的消息來源。<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><span class="math inline">\(p = .000000000000000000000000136\)</span> 在一般人看來並不是科學的表達方式！<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>注意，<code>Test value</code>要填入的 p 與<em>p</em>值是兩回事。用 jamovi 進行二項式檢定，要先設定 <span class="math inline">\(p\)</span> 參數代表根據虛無假設猜測正確答案的機率，也就是 <span class="math inline">\(\theta\)</span> 值。換句話說，這個 <span class="math inline">\(p\)</span> 是指根據虛無假設，參與者能答對的機率。<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>請注意，ESP案例的回答正確率我習慣會用p代表，但是這個p與<em>p</em>值無關。在 jamovi 的二項檢定中， 參數<span class="math inline">\(p\)</span>對應到根據虛無假設所作出的正確反應的機率。換句話說，它是 <span class="math inline">\(\theta\)</span> 的值。<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>請注意，母群參數的真實數值 <span class="math inline">\(\theta\)</span> 不一定對應自然界中不可改變的事實。在ESP實驗的狀況， <span class="math inline">\(\theta\)</span> 只是代表參與者正確猜對隔壁房間的卡片顏色機率。所以，各種因素都可以影響母群參數。當然，我們能這樣設計實驗的前提是超感官力量確實存在！<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>一個可能的例外是，研究目標是測試一種新式醫療方法的有效性，研究人員能事先指定需要檢測的重要效果量，例如在任何優於現有治療方法的額外效果量。如此做考驗力分析可以獲得一些有關新療法潛在價值的信息。<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>譯註~ 譯者認為原作者應該還有另一層考量。由於本書定位是入門教科書，考驗力分析需要進一步學習各種研究方法(也就是 ＠sec-A-brief-introduction-to-research-design 的完整版)，才能充分了解其用途。如果教師想為學生介紹預先註冊(preregisteration)的觀念及做法，可考慮在統計課程介紹考驗力分析的必要性。<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>在這種情況下，皮爾森卡方獨立性檢驗（參見 <a href="10-Categorical-data-analysis.html"><span>章节&nbsp;10</span></a> ）<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>讀完原作者虛構的ESP研究案例，打開示範檔案庫的”Binomial Test”，找一找虛無假設與對立假設、型一與型二錯誤有沒有呈現在jamovi介面的任何地方？有的話是如何呈現？<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>如果在 <a href="07-Introduction-to-probability.html"><span>章节&nbsp;7</span></a> 有用過distrACTION這個模組認識機率分佈，再次使用這個模組繪製雙側檢定與單側檢定的棄卻域。<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>分別以雙側檢定與單側檢定的結果，使用distrACTION模組確認表格內量數之外的累積機率，確認是否與表格裡的p值一致？<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>首先定義一個你期望為真的成功率或失敗率，使用distrACTION模組製作一個代表這項機率的二項分佈機率，繪製出雙側與單側考驗力的區域。<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "已复制");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "已复制");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("https:\/\/scgeeker\.github\.io\/lsj-book-zh_tw\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./08-Estimating-unknown-quantities-from-a-sample.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">運用樣本估計未知量數</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Prelude-Part-V.html" class="pagination-link">
        <span class="nav-page-text">線性模型的學習取向</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left"><a href="https://learnstatswithjamovi.com">用jamovi上手統計學</a></div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">電子書使用 <a href="https://quarto.org/">Quarto套件</a>創建</div>
  </div>
</footer>



</body></html>