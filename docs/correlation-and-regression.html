<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 2 Correlation and regression | learning statistics with jamovi</title>
<meta name="author" content="Danielle J. Navarro &amp; David R. Foxcroft">
<meta name="description" content="The goal in this chapter is to introduce correlation and linear regression. These are the standard tools that statisticians rely on when analysing the relationship between continuous predictors...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Chapter 2 Correlation and regression | learning statistics with jamovi">
<meta property="og:type" content="book">
<meta property="og:image" content="/images/bookcover_logo.png">
<meta property="og:description" content="The goal in this chapter is to introduce correlation and linear regression. These are the standard tools that statisticians rely on when analysing the relationship between continuous predictors...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 2 Correlation and regression | learning statistics with jamovi">
<meta name="twitter:description" content="The goal in this chapter is to introduce correlation and linear regression. These are the standard tools that statisticians rely on when analysing the relationship between continuous predictors...">
<meta name="twitter:image" content="/images/bookcover_logo.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><style>
    .enlarge-image {
        transition: transform .2s ease-out;
        cursor: pointer;
    }

    .enlarge-image:hover {
        transform: scale(2.0);
        display: block;
        background: black;
        position:relative;
        float:left;
        z-index:999;
    }
    </style>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script type="text/x-mathjax-config"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title=""><span style="font-family:Garamond;font-weight:700;">learning statistics with jamovi</span></a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"></a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="why-do-we-learn-statistics.html"><span class="header-section-number">1</span> Why do we learn statistics</a></li>
<li><a class="active" href="correlation-and-regression.html"><span class="header-section-number">2</span> Correlation and regression</a></li>
<li><a class="" href="drawing-graphs.html"><span class="header-section-number">3</span> Drawing graphs</a></li>
<li><a class="" href="pragmatic-matters.html"><span class="header-section-number">4</span> Pragmatic matters</a></li>
<li><a class="" href="prelude-to-part-iv.html">Prelude to Part IV</a></li>
<li><a class="" href="introduction-to-probability.html"><span class="header-section-number">5</span> Introduction to probability</a></li>
<li><a class="" href="estimating-unkown-quantities-from-a-sample.html"><span class="header-section-number">6</span> Estimating unkown quantities from a sample</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">7</span> Hypothesis testing</a></li>
<li><a class="" href="categorical-data-analysis.html"><span class="header-section-number">8</span> Categorical data analysis</a></li>
<li><a class="" href="comparing-two-means.html"><span class="header-section-number">9</span> Comparing two means</a></li>
<li><a class="" href="comparing-several-means-one-way-anova.html"><span class="header-section-number">10</span> Comparing several means (one-way ANOVA)</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="correlation-and-regression" class="section level1" number="2">
<h1>
<span class="header-section-number">2</span> Correlation and regression<a class="anchor" aria-label="anchor" href="#correlation-and-regression"><i class="fas fa-link"></i></a>
</h1>
<p>The goal in this chapter is to introduce <strong>correlation</strong> and <strong>linear regression</strong>. These are the standard tools that statisticians rely on when analysing the relationship between continuous predictors and continuous outcomes.</p>
<div id="correlations" class="section level2" number="2.1">
<h2>
<span class="header-section-number">2.1</span> Correlations<a class="anchor" aria-label="anchor" href="#correlations"><i class="fas fa-link"></i></a>
</h2>
<p>In this section we’ll talk about how to describe the relationships between variables in the data. To do that, we want to talk mostly about the <strong>correlation</strong> between variables. But first, we need some data (Table <a href="correlation-and-regression.html#tab:tab12-1">2.1</a>).</p>
<div id="the-data" class="section level3" number="2.1.1">
<h3>
<span class="header-section-number">2.1.1</span> The data<a class="anchor" aria-label="anchor" href="#the-data"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-table"><table class="huxtable" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  " id="tab:tab12-1">
<caption style="caption-side: bottom; text-align: left;">
<span id="tab:tab12-1">Table 2.1: </span> Data for correlation analysis: descriptive statistics for the parenthood data</caption>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
<tr>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: bold;">variable</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">min</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">max</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">mean</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">median</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">std. dev</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">IQR</th>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 0pt; font-weight: normal;">Dani's grumpiness</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">41</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">91</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">63.71</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">62</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">10.05</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 0pt 6pt 6pt; font-weight: normal;">14</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">Dani's hours slept</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">4.84</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">9.00</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">6.97</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">7.03</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">1.02</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">1.45</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; font-weight: normal;">Dani's son's hours slept</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">3.25</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">12.07</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">8.05</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">7.95</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">2.07</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; font-weight: normal;">3.21</td>
</tr>
</table></div>
<p>Let’s turn to a topic close to every parent’s heart: sleep. The data set we’ll use is fictitious, but based on real events. Suppose I’m curious to find out how much my infant son’s sleeping habits affect my mood. Let’s say that I can rate my grumpiness very precisely, on a scale from 0 (not at all grumpy) to <span class="math inline">\(100\)</span> (grumpy as a very, very grumpy old man or woman). And lets also assume that I’ve been measuring my grumpiness, my sleeping patterns and my son’s sleeping patterns for quite some time now. Let’s say, for <span class="math inline">\(100\)</span> days. And, being a nerd, I’ve saved the data as a file called parenthood.csv. If we load the data we can see that the file contains four variables dani.sleep, baby.sleep, dani.grump and day. Note that when you first load this data set jamovi may not have guessed the data type for each variable correctly, in which case you should fix it: dani.sleep, baby.sleep, dani.grump and day can be specified as continuous variables, and ID is a nominal(integer) variable.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;I’ve noticed that in some versions of jamovi you can also specify an ‘ID’ variable type, but for our purposes it does not matter how we specify the ID variable as we won’t be including it in any analyses.&lt;/p&gt;"><sup>6</sup></a></p>
<p>Next, I’ll take a look at some basic descriptive statistics and, to give a graphical depiction of what each of the three interesting variables looks like, Figure <a href="correlation-and-regression.html#fig:fig12-1">2.1</a> plots histograms. One thing to note: just because jamovi can calculate dozens of different statistics doesn’t mean you should report all of them. If I were writing this up for a report, I’d probably pick out those statistics that are of most interest to me (and to my readership), and then put them into a nice, simple table like the one in Table 12.1.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Actually, even that table is more than I’d bother with. In practice most people pick one measure of central tendency, and one measure of variability only.&lt;/p&gt;"><sup>7</sup></a> Notice that when I put it into a table, I gave everything “human readable” names. This is always good practice. Notice also that I’m not getting enough sleep. This isn’t good practice, but other parents tell me that it’s pretty standard.</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-1"></span>
<img src="images/Figure105.PNG" alt="Histograms for the three interesting variables in the parenthood data set" width="90%"><p class="caption">
Figure 2.1: Histograms for the three interesting variables in the parenthood data set
</p>
</div>
</div>
<div id="the-strength-and-direction-of-a-relationship" class="section level3" number="2.1.2">
<h3>
<span class="header-section-number">2.1.2</span> The strength and direction of a relationship<a class="anchor" aria-label="anchor" href="#the-strength-and-direction-of-a-relationship"><i class="fas fa-link"></i></a>
</h3>
<p>We can draw scatterplots to give us a general sense of how closely related two variables are. Ideally though, we might want to say a bit more about it than that. For instance, let’s compare the relationship between dani.sleep and dani.grump (Figure <a href="correlation-and-regression.html#fig:fig12-1">2.1</a>, left) with that between baby.sleep and dani.grump (Figure <a href="correlation-and-regression.html#fig:fig12-2">2.2</a>, right). When looking at these two plots side by side, it’s clear that the relationship is qualitatively the same in both cases: more sleep equals less grump! However, it’s also pretty obvious that the relationship between dani.sleep and dani.grump is stronger than the relationship between baby.sleep and dani.grump. The plot on the left is “neater” than the one on the right. What it feels like is that if you want to predict what my mood is, it’d help you a little bit to know how many hours my son slept, but it’d be more helpful to know how many hours I slept.</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-2"></span>
<img src="images/Figure106.PNG" alt="Scatterplots showing the relationship between dani.sleep and dani.grump (left) and the relationship between baby.sleep and dani.grump (right)" width="90%"><p class="caption">
Figure 2.2: Scatterplots showing the relationship between dani.sleep and dani.grump (left) and the relationship between baby.sleep and dani.grump (right)
</p>
</div>
<p>In contrast, let’s consider the two scatterplots shown in Figure <a href="correlation-and-regression.html#fig:fig12-3">2.3</a>. If we compare the scatterplot of “baby.sleep v dani.grump” (left) to the scatterplot of “’baby.sleep v dani.sleep” (right), the overall strength of the relationship is the same, but the direction is different. That is, if my son sleeps more, I get more sleep (positive relationship, right hand side), but if he sleeps more then I get less grumpy (negative relationship, left hand side).</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-3"></span>
<img src="images/Figure107.PNG" alt="Scatterplots showing the relationship between baby.sleep and dani.grump (left), as compared to the relationship between baby.sleep and dani.sleep (right)" width="90%"><p class="caption">
Figure 2.3: Scatterplots showing the relationship between baby.sleep and dani.grump (left), as compared to the relationship between baby.sleep and dani.sleep (right)
</p>
</div>
</div>
<div id="the-correlation-coefficient" class="section level3" number="2.1.3">
<h3>
<span class="header-section-number">2.1.3</span> The correlation coefficient<a class="anchor" aria-label="anchor" href="#the-correlation-coefficient"><i class="fas fa-link"></i></a>
</h3>
<p>We can make these ideas a bit more explicit by introducing the idea of a <strong>correlation coefficient</strong> (or, more specifically, Pearson’s correlation coefficient <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The formula for the Pearson’s correlation coefficient can be written in several different ways. I think the simplest way to write down the formula is to break it into two steps. Firstly, let’s introduce the idea of a &lt;strong&gt;covariance&lt;/strong&gt;. The covariance between two variables &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(Y\)&lt;/span&gt; is a generalisation of the notion of the variance and is a mathematically simple way of describing the relationship between two variables that isn’t terribly informative to humans &lt;span class="math display"&gt;\[Cov(X,Y)=\frac{1}{N-1}\sum_{i=1}^N(X_i-\bar{X})(Y_i-\bar{Y})\]&lt;/span&gt; Because we’re multiplying (i.e., taking the “product” of) a quantity that depends on X by a quantity that depends on Y and then averaging&lt;span class="math inline"&gt;\(^a\)&lt;/span&gt;, you can think of the formula for the covariance as an “average cross product” between &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(Y\)&lt;/span&gt;. The covariance has the nice property that, if &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(Y\)&lt;/span&gt; are entirely unrelated, then the covariance is exactly zero. If the relationship between them is positive (in the sense shown in Figure &lt;a href="correlation-and-regression.html#fig:fig12-4"&gt;2.4&lt;/a&gt; then the covariance is also positive, and if the relationship is negative then the covariance is also negative. In other words, the covariance captures the basic qualitative idea of correlation. Unfortunately, the raw magnitude of the covariance isn’t easy to interpret as it depends on the units in which &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(Y\)&lt;/span&gt; are expressed and, worse yet, the actual units that the covariance itself is expressed in are really weird. For instance, if &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; refers to the dani.sleep variable (units: hours) and &lt;span class="math inline"&gt;\(Y\)&lt;/span&gt; refers to the dani.grump variable (units: grumps), then the units for their covariance are &lt;span class="math inline"&gt;\(hours \times grumps\)&lt;/span&gt;. And I have no freaking idea what that would even mean. The Pearson correlation coefficient r fixes this interpretation problem by standardising the covariance, in pretty much the exact same way that the z-score standardises a raw score, by dividing by the standard deviation. However, because we have two variables that contribute to the covariance, the standardisation only works if we divide by both standard deviations.&lt;span class="math inline"&gt;\(^b\)&lt;/span&gt; In other words, the correlation between &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(Y\)&lt;/span&gt; can be written as follows: &lt;span class="math display"&gt;\[r_{XY}=\frac{Cov(X,Y)}{\hat{\sigma}_X\hat{\sigma}_Y}\]&lt;/span&gt;&lt;br&gt;
+++&lt;br&gt;&lt;span class="math inline"&gt;\(^a\)&lt;/span&gt; Just like we saw with the variance and the standard deviation, in practice we divide by &lt;span class="math inline"&gt;\(N - 1\)&lt;/span&gt; rather than &lt;span class="math inline"&gt;\(N\)&lt;/span&gt;. &lt;span class="math inline"&gt;\(^b\)&lt;/span&gt; This is an oversimplification, but it’ll do for our purposes.&lt;/p&gt;'><sup>8</sup></a>), which is traditionally denoted as r. The correlation coefficient between two variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (sometimes denoted <span class="math inline">\(r_{XY}\)</span> ), which we’ll define more precisely in the next section, is a measure that varies from -1 to 1. When <span class="math inline">\(r = -1\)</span> it means that we have a perfect negative relationship, and when <span class="math inline">\(r = 1\)</span> it means we have a perfect positive relationship. When <span class="math inline">\(r = 0\)</span>, there’s no relationship at all. If you look at Figure <a href="correlation-and-regression.html#fig:fig12-4">2.4</a>, you can see several plots showing what different correlations look like.</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-4"></span>
<img src="images/Figure108.PNG" alt="Illustration of the effect of varying the strength and direction of a correlation. In the left hand column, the correlations are $0, .33, .66$ and $1$. In the right hand column, the correlations are $0, -.33, -.66$ and $-1$" width="90%"><p class="caption">
Figure 2.4: Illustration of the effect of varying the strength and direction of a correlation. In the left hand column, the correlations are <span class="math inline">\(0, .33, .66\)</span> and <span class="math inline">\(1\)</span>. In the right hand column, the correlations are <span class="math inline">\(0, -.33, -.66\)</span> and <span class="math inline">\(-1\)</span>
</p>
</div>
<p>By standardising the covariance, not only do we keep all of the nice properties of the covariance discussed earlier, but the actual values of r are on a meaningful scale: r = 1 implies a perfect positive relationship and <span class="math inline">\(r = -1\)</span> implies a perfect negative relationship. I’ll expand a little more on this point later, in Section 12.1.5. But before I do, let’s look at how to calculate correlations in jamovi.</p>
</div>
<div id="calculating-correlations-in-jamovi" class="section level3" number="2.1.4">
<h3>
<span class="header-section-number">2.1.4</span> Calculating correlations in jamovi<a class="anchor" aria-label="anchor" href="#calculating-correlations-in-jamovi"><i class="fas fa-link"></i></a>
</h3>
<p>Calculating correlations in jamovi can be done by clicking on the ‘Regression’ - ‘Correlation Matrix’ button. Transfer all four continuous variables across into the box on the right to get the output in Figure <a href="correlation-and-regression.html#fig:fig12-5">2.5</a>.</p>
</div>
<div id="interpreting-a-correlation" class="section level3" number="2.1.5">
<h3>
<span class="header-section-number">2.1.5</span> Interpreting a correlation<a class="anchor" aria-label="anchor" href="#interpreting-a-correlation"><i class="fas fa-link"></i></a>
</h3>
<p>Naturally, in real life you don’t see many correlations of <span class="math inline">\(1\)</span>. So how should you interpret a correlation of, say, r = <span class="math inline">\(.4\)</span>? The honest answer is that it really depends on what you want to use the data for, and on how strong the correlations in your field tend to be. A friend of mine in engineering once argued that any correlation less than <span class="math inline">\(.95\)</span> is completely useless (I think he was exaggerating, even for engineering). On the other hand, there are real cases, even in psychology, where you should really expect correlations that strong. For instance, one of the benchmark data sets used to test theories of how people judge similarities is so clean that any theory that can’t achieve a correlation of at least <span class="math inline">\(.9\)</span> really isn’t deemed to be successful. However, when looking for (say) elementary correlates of intelligence (e.g., inspection time, response time), if you get a correlation above <span class="math inline">\(.3\)</span> you’re doing very very well. In short, the interpretation of a correlation depends a lot on the context. That said, the rough guide in Table <a href="correlation-and-regression.html#tab:tab12-3">2.3</a> is pretty typical.</p>
<p>However, something that can never be stressed enough is that you should always look at the scatterplot before attaching any interpretation to the data. A correlation might not mean what you think it means. The classic illustration of this is “Anscombe’s Quartet” <span class="citation">(<a href="references.html#ref-Anscombe1973" role="doc-biblioref">Anscombe 1973</a>)</span>, a collection of four data sets. Each data set has two variables, an X and a $Y $. For all four data sets the mean value for <span class="math inline">\(X\)</span> is <span class="math inline">\(9\)</span> and the mean for <span class="math inline">\(Y\)</span> is <span class="math inline">\(7.5\)</span>. The standard deviations for all <span class="math inline">\(X\)</span> variables are almost identical, as are those for the Y variables. And in each case the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is <span class="math inline">\(r = 0.816\)</span>. You can verify this yourself, since I happen to have saved it in a file called anscombe.csv.</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-5"></span>
<img src="images/Figure109.PNG" alt="A jamovi screenshot showing correlations between variables in the parenthood.csv file" width="90%"><p class="caption">
Figure 2.5: A jamovi screenshot showing correlations between variables in the parenthood.csv file
</p>
</div>
<p>You’d think that these four data sets would look pretty similar to one another. They do not. If we draw scatterplots of <span class="math inline">\(X\)</span> against <span class="math inline">\(Y\)</span> for all four variables, as shown in Figure <a href="correlation-and-regression.html#fig:fig12-6">2.6</a>, we see that all four of these are spectacularly different to each other. The lesson here, which so very many people seem to forget in real life, is “always graph your raw data” (Chapter <strong>5</strong>).</p>
</div>
<div id="spearmans-rank-correlations" class="section level3" number="2.1.6">
<h3>
<span class="header-section-number">2.1.6</span> Spearman’s rank correlations<a class="anchor" aria-label="anchor" href="#spearmans-rank-correlations"><i class="fas fa-link"></i></a>
</h3>
<p>The Pearson correlation coefficient is useful for a lot of things, but it does have shortcomings. One issue in particular stands out: what it actually measures is the strength of the linear relationship between two variables. In other words, what it gives you is a measure of the extent to which the data all tend to fall on a single, perfectly straight line. Often, this is a pretty good approximation to what we mean when we say “relationship”, and so the Pearson correlation is a good thing to calculate. Sometimes though, it isn’t.</p>
<p>One very common situation where the Pearson correlation isn’t quite the right thing to use arises when an increase in one variable <span class="math inline">\(X\)</span> really is reflected in an increase in another variable Y , but the nature of the relationship isn’t necessarily linear. An example of this might be the relationship between effort and reward when studying for an exam. If you put zero effort (<span class="math inline">\(X\)</span>) into learning a subject then you should expect a grade of <span class="math inline">\(0\%\)</span> (<span class="math inline">\(Y\)</span>). However, a little bit of effort will cause a massive improvement. Just turning up to lectures means that you learn a fair bit, and if you just turn up to classes and scribble a few things down your grade might rise to 35%, all without a lot of effort. However, you just don’t get the same effect at the other end of the scale. As everyone knows, it takes a lot more effort to get a grade of <span class="math inline">\(90\%\)</span> than it takes to get a grade of <span class="math inline">\(55\%\)</span>. What this means is that, if I’ve got data looking at study effort and grades, there’s a pretty good chance that Pearson correlations will be misleading.</p>
<div class="inline-table"><table class="huxtable" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  " id="tab:tab12-2">
<caption style="caption-side: bottom; text-align: left;">
<span id="tab:tab12-2">Table 2.2: </span> A rough guide to interpreting correlations. Note that I say a rough guide. There aren't hard and fast rules for what counts as strong or weak relationships. It depends on the context.</caption>
<col>
<col>
<col>
<tr>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: bold;">Correlation</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">Strength</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">Direction</th>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 0pt; font-weight: normal;">-1.0 to -0.9</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">Very strong</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 0pt 6pt 6pt; font-weight: normal;">Negative</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">-0.9 to -0.7</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Strong</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Negative</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;">-0.7 to -0.4</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">Moderate</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">Negative</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">-0.4 to -0.2</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Weak</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Negative</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;">-0.2 to 0</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">Negligible</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">Negative</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">0 to 0.2</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Negligible</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Positive</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;">0.2 to 0.4</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">Weak</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">Positive</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">0.4 to 0.7</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Moderate</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Positive</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;">0.7 to 0.9</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">Strong</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">Positive</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">0.9 to 1.0</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Very strong</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">Positive</td>
</tr>
</table></div>
<p>To illustrate, consider the data plotted in Figure <a href="correlation-and-regression.html#fig:fig12-7">2.7</a>, showing the relationship between hours worked and grade received for 10 students taking some class. The curious thing about this (highly fictitious) data set is that increasing your effort always increases your grade. It might be by a lot or it might be by a little, but increasing effort will never decrease your grade. If we run a standard Pearson correlation, it shows a strong relationship between hours worked and grade received, with a correlation coefficient of <span class="math inline">\(0.91\)</span>. However, this doesn’t actually capture the observation that increasing hours worked always increases the grade. There’s a sense here in which we want to be able to say that the correlation is perfect but for a somewhat different notion of what a “relationship” is. What we’re looking for is something that captures the fact that there is a perfect <strong>ordinal relationship</strong> here. That is, if student 1 works more hours than student 2, then we can guarantee that student 1 will get the better grade. That’s not what a correlation of <span class="math inline">\(r = .91\)</span> says at all.</p>
<p>How should we address this? Actually, it’s really easy. If we’re looking for ordinal relationships all we have to do is treat the data as if it were ordinal scale! So, instead of measuring effort in terms of “hours worked”, lets rank all <span class="math inline">\(10\)</span> of our students in order of hours worked. That is, student <span class="math inline">\(1\)</span> did the least work out of anyone (<span class="math inline">\(2\)</span> hours) so they get the lowest rank (rank = <span class="math inline">\(1\)</span>). Student <span class="math inline">\(4\)</span> was the next laziest, putting in only <span class="math inline">\(6\)</span> hours of work over the whole semester, so they get the next lowest rank (rank = <span class="math inline">\(2\)</span>). Notice that I’m using “rank =1” to mean “low rank”. Sometimes in everyday language we talk about “rank = <span class="math inline">\(1\)</span>” to mean “top rank” rather than “bottom rank”. So be careful, you can rank “from smallest value to largest value” (i.e., small equals rank <span class="math inline">\(1\)</span>) or you can rank “from largest value to smallest value” (i.e., large equals rank 1). In this case, I’m ranking from smallest to largest, but as it’s really easy to forget which way you set things up you have to put a bit of effort into remembering!</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-6"></span>
<img src="images/Figure110.PNG" alt="Anscombe's quartet. All four of these data sets have a Pearson correlation of r = .816, but they are qualitatively different from one another" width="90%"><p class="caption">
Figure 2.6: Anscombe’s quartet. All four of these data sets have a Pearson correlation of r = .816, but they are qualitatively different from one another
</p>
</div>
<p>Okay, so let’s have a look at our students when we rank them from worst to best in terms of effort and reward:</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-7"></span>
<img src="images/Figure111.PNG" alt="The relationship between hours worked and grade received for a toy data set consisting of only 10 students (each circle corresponds to one student). The dashed line through the middle shows the linear relationship between the two variables. This produces a strong Pearson correlation of $r = .91$. However, the interesting thing to note here is that there's actually a perfect monotonic relationship between the two variables. In this toy example, increasing the hours worked always increases the grade received, as illustrated by the solid line. This is reflected in a Spearman correlation of $\rho = 1$. With such a small data set, however, it's an open question as to which version better describes the actual relationship involved" width="90%"><p class="caption">
Figure 2.7: The relationship between hours worked and grade received for a toy data set consisting of only 10 students (each circle corresponds to one student). The dashed line through the middle shows the linear relationship between the two variables. This produces a strong Pearson correlation of <span class="math inline">\(r = .91\)</span>. However, the interesting thing to note here is that there’s actually a perfect monotonic relationship between the two variables. In this toy example, increasing the hours worked always increases the grade received, as illustrated by the solid line. This is reflected in a Spearman correlation of <span class="math inline">\(\rho = 1\)</span>. With such a small data set, however, it’s an open question as to which version better describes the actual relationship involved
</p>
</div>
<div class="inline-table"><table class="huxtable" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  " id="tab:tab12-3">
<caption style="caption-side: bottom; text-align: left;">
<span id="tab:tab12-3">Table 2.3: </span> Students ranked in terms of effort and reward</caption>
<col>
<col>
<col>
<tr>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: bold;"></th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">rank (hours worked)</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">rank (grade received)</th>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 0pt; font-weight: normal;">student 1</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">1</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 0pt 6pt 6pt; font-weight: normal;">1</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">student 2</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">10</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">10</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;">student 3</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">6</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">6</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">student 4</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">2</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">2</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;">student 5</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">3</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">3</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">student 6</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">5</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">5</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;">student 7</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">4</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">4</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">student 8</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">8</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">8</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;">student 9</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">7</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">7</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">student 10</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">9</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">9</td>
</tr>
</table></div>
<p>Hmm. These are identical. The student who put in the most effort got the best grade, the student with the least effort got the worst grade, etc. As the table above shows, these two rankings are identical, so if we now correlate them we get a perfect relationship, with a correlation of 1.0.</p>
<p>What we’ve just re-invented is <strong>Spearman’s rank order correlation</strong>, usually denoted <span class="math inline">\(\rho\)</span> to distinguish it from the Pearson correlation r. We can calculate Spearman’s <span class="math inline">\(\rho\)</span> using jamovi simply by clicking the ‘Spearman’ check box in the ‘Correlation Matrix’ screen.</p>
</div>
</div>
<div id="scatterplots" class="section level2" number="2.2">
<h2>
<span class="header-section-number">2.2</span> Scatterplots<a class="anchor" aria-label="anchor" href="#scatterplots"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Scatterplots</strong> are a simple but effective tool for visualising the relationship between two variables, like we saw with the figures in the section on correlation (Section <strong>12.1</strong>). It’s this latter application that we usually have in mind when we use the term “scatterplot”. In this kind of plot each observation corresponds to one dot. The horizontal location of the dot plots the value of the observation on one variable, and the vertical location displays its value on the other variable. In many situations you don’t really have a clear opinions about what the causal relationship is (e.g., does A cause B, or does B cause A, or does some other variable C control both A and B). If that’s the case, it doesn’t really matter which variable you plot on the x-axis and which one you plot on the y-axis. However, in many situations you do have a pretty strong idea which variable you think is most likely to be causal, or at least you have some suspicions in that direction. If so, then it’s conventional to plot the cause variable on the x-axis, and the effect variable on the y-axis. With that in mind, let’s look at how to draw scatterplots in jamovi, using the same parenthood data set (i.e. parenthood.csv) that I used when introducing correlations.</p>
<p>Suppose my goal is to draw a scatterplot displaying the relationship between the amount of sleep that I get (dani.sleep) and how grumpy I am the next day (dani.grump). There are two different ways in which we can use jamovi to get the plot that we’re after. The first way is to use the ‘Plot’ option under the ‘Regression’ - ‘Correlation Matrix’ button, giving us the output shown in Figure @ref(fig:fig12.8). Note that jamovi draws a line through the points, we’ll come onto this a bit later in Section (<strong>12.3</strong>). Plotting a scatterplot in this way also allow you to specify ‘Densities for variables’ and this option adds a density curve showing how the data in each variable is distributed.</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-8"></span>
<img src="images/Figure111.PNG" alt="Scatterplot via the 'Correlation Matrix' command in jamovi]" width="90%"><p class="caption">
Figure 2.8: Scatterplot via the ‘Correlation Matrix’ command in jamovi]
</p>
</div>
<p>The second way do to it is to use one of the jamovi add-on modules. This module is called ‘scatr’ and you can install it by clicking on the large ‘<span class="math inline">\(+\)</span>’ icon in the top right of the jamovi screen, opening the jamovi library, scrolling down until you find ‘scatr’ and clicking ‘install’. When you have done this, you will find a new ‘Scatterplot’ command available under the ‘Exploration’ button. This plot is a bit different than the first way, see Figure <a href="correlation-and-regression.html#fig:fig12-9">2.9</a>, but the important information is the same.</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-9"></span>
<img src="images/Figure113.PNG" alt="Scatterplot via the 'scatr' add-on module in - jamovi]" width="90%"><p class="caption">
Figure 2.9: Scatterplot via the ‘scatr’ add-on module in - jamovi]
</p>
</div>
<div id="more-elaborate-options" class="section level3" number="2.2.1">
<h3>
<span class="header-section-number">2.2.1</span> More elaborate options<a class="anchor" aria-label="anchor" href="#more-elaborate-options"><i class="fas fa-link"></i></a>
</h3>
<p>Often you will want to look at the relationships between several variables at once, using a <strong>scatterplot matrix</strong> (in jamovi via the ‘Correlation Matrix’ - ‘Plot’ command). Just add another variable, for example baby.sleep to the list of variables to be correlated, and jamovi will create a scatterplot matrix for you, just like the one in Figure <a href="correlation-and-regression.html#fig:fig12-10">2.10</a>.</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-10"></span>
<img src="images/Figure114.PNG" alt="A matrix of scatterplots produced using jamovi" width="90%"><p class="caption">
Figure 2.10: A matrix of scatterplots produced using jamovi
</p>
</div>
</div>
</div>
<div id="what-is-a-linear-regression-model" class="section level2" number="2.3">
<h2>
<span class="header-section-number">2.3</span> What is a linear regression model?<a class="anchor" aria-label="anchor" href="#what-is-a-linear-regression-model"><i class="fas fa-link"></i></a>
</h2>
<p>Stripped to its bare essentials, linear regression models are basically a slightly fancier version of the Pearson correlation (Section <strong>12.1</strong>), though as we’ll see regression models are much more powerful tools.</p>
<p>Since the basic ideas in regression are closely tied to correlation, we’ll return to the parenthood.csv file that we were using to illustrate how correlations work. Recall that, in this data set we were trying to find out why Dani is so very grumpy all the time and our working hypothesis was that I’m not getting enough sleep. We drew some scatterplots to help us examine the relationship between the amount of sleep I get and my grumpiness the following day, as in Figure <a href="correlation-and-regression.html#fig:fig12-9">2.9</a>, and as we saw previously this corresponds to a correlation of <span class="math inline">\(r = -.90\)</span>, but what we find ourselves secretly imagining is something that looks closer to Figure <a href="correlation-and-regression.html#fig:fig12-11">2.11</a>a. That is, we mentally draw a straight line through the middle of the data. In statistics, this line that we’re drawing is called a <strong>regression line</strong>. Notice that, since we’re not idiots, the regression line goes through the middle of the data. We don’t find ourselves imagining anything like the rather silly plot shown in Figure <a href="correlation-and-regression.html#fig:fig12-11">2.11</a>b.</p>
<p>This is not highly surprising. The line that I’ve drawn in Figure <a href="correlation-and-regression.html#fig:fig12-11">2.11</a>b doesn’t “fit” the data very well, so it doesn’t make a lot of sense to propose it as a way of summarising the data, right? This is a very simple observation to make, but it turns out to be very powerful when we start trying to wrap just a little bit of maths around it. To do so, let’s start with a refresher of some high school maths. The formula for a straight line is usually written like this</p>
<p><span class="math display">\[y=a+bx\]</span></p>
<div class="figure">
<span style="display:block;" id="fig:fig12-11"></span>
<img src="images/Figure115.PNG" alt="Panel a shows the sleep-grumpiness scatterplot from Figure \@ref(fig:fig12-9) with the best fitting regression line drawn over the top. Not surprisingly, the line goes through the middle of the data. In contrast, panel b shows the same data, but with a very poor choice of regression line drawn over the top" width="90%"><p class="caption">
Figure 2.11: Panel a shows the sleep-grumpiness scatterplot from Figure <a href="correlation-and-regression.html#fig:fig12-9">2.9</a> with the best fitting regression line drawn over the top. Not surprisingly, the line goes through the middle of the data. In contrast, panel b shows the same data, but with a very poor choice of regression line drawn over the top
</p>
</div>
<p>Or, at least, that’s what it was when I went to high school all those years ago. The two variables are <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, and we have two coefficients, <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Also sometimes written as &lt;span class="math inline"&gt;\(y = mx + c\)&lt;/span&gt; where m is the slope coefficient and &lt;span class="math inline"&gt;\(c\)&lt;/span&gt; is the intercept (constant) coefficient.&lt;/p&gt;'><sup>9</sup></a> The coefficient a represents the y-intercept of the line, and coefficient b represents the slope of the line. Digging further back into our decaying memories of high school (sorry, for some of us high school was a long time ago), we remember that the intercept is interpreted as “the value of y that you get when <span class="math inline">\(x = 0\)</span>”. Similarly, a slope of b means that if you increase the x-value by 1 unit, then the y-value goes up by b units, and a negative slope means that the y-value would go down rather than up. Ah yes, it’s all coming back to me now. Now that we’ve remembered that it should come as no surprise to discover that we use the exact same formula for a regression line. If <span class="math inline">\(Y\)</span> is the outcome variable (the DV) and X is the predictor variable (the <span class="math inline">\(IV\)</span>), then the formula that describes our regression is written like this</p>
<p><span class="math display">\[\hat{Y}_i=b_0+b_1X_i\]</span></p>
<p>Hmm. Looks like the same formula, but there’s some extra frilly bits in this version. Let’s make sure we understand them. Firstly, notice that I’ve written <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i\)</span> rather than just plain old <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> . This is because we want to remember that we’re dealing with actual data. In this equation, <span class="math inline">\(X_i\)</span> is the value of predictor variable for the ith observation (i.e., the number of hours of sleep that I got on day i of my little study), and <span class="math inline">\(Y_i\)</span> is the corresponding value of the outcome variable (i.e., my grumpiness on that day). And although I haven’t said so explicitly in the equation, what we’re assuming is that this formula works for all observations in the data set (i.e., for all i). Secondly, notice that I wrote <span class="math inline">\(\hat{Y}_i\)</span> and not <span class="math inline">\(Y_i\)</span> . This is because we want to make the distinction between the actual data <span class="math inline">\(Y_i\)</span>, and the estimate <span class="math inline">\(\hat{Y}_i\)</span> (i.e., the prediction that our regression line is making). Thirdly, I changed the letters used to describe the coefficients from a and <span class="math inline">\(b\)</span> to <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>. That’s just the way that statisticians like to refer to the coefficients in a regression model. I’ve no idea why they chose b, but that’s what they did. In any case <span class="math inline">\(b_0\)</span> always refers to the intercept term, and <span class="math inline">\(b_1\)</span> refers to the slope.</p>
<p>Excellent, excellent. Next, I can’t help but notice that, regardless of whether we’re talking about the good regression line or the bad one, the data don’t fall perfectly on the line. Or, to say it another way, the data <span class="math inline">\(Y_i\)</span> are not identical to the predictions of the regression model <span class="math inline">\(\hat{Y}_i\)</span>. Since statisticians love to attach letters, names and numbers to everything, let’s refer to the difference between the model prediction and that actual data point as a residual, and we’ll refer to it as <span class="math inline">\(\epsilon_i\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The &lt;span class="math inline"&gt;\(\epsilon\)&lt;/span&gt; symbol is the Greek letter epsilon. It’s traditional to use &lt;span class="math inline"&gt;\(\epsilon_i\)&lt;/span&gt; or &lt;span class="math inline"&gt;\(e_i\)&lt;/span&gt; to denote a residual.&lt;/p&gt;'><sup>10</sup></a> Written using mathematics, the residuals are defined as</p>
<p><span class="math display">\[\epsilon_i=Y_i-\hat{Y}_i\]</span></p>
<p>which in turn means that we can write down the complete linear regression model as</p>
<p><span class="math display">\[Y_i=b_0+b_1X_i+\epsilon_i\]</span></p>
</div>
<div id="estimating-a-linear-regression-model" class="section level2" number="2.4">
<h2>
<span class="header-section-number">2.4</span> Estimating a linear regression model<a class="anchor" aria-label="anchor" href="#estimating-a-linear-regression-model"><i class="fas fa-link"></i></a>
</h2>
<div class="figure">
<span style="display:block;" id="fig:fig12-12"></span>
<img src="images/Figure116.PNG" alt="A depiction of the residuals associated with the best fitting regression line (panel a), and the residuals associated with a poor regression line (panel b). The residuals are much smaller for the good regression line. Again, this is no surprise given that the good line is the one that goes right through the middle of the data" width="90%"><p class="caption">
Figure 2.12: A depiction of the residuals associated with the best fitting regression line (panel a), and the residuals associated with a poor regression line (panel b). The residuals are much smaller for the good regression line. Again, this is no surprise given that the good line is the one that goes right through the middle of the data
</p>
</div>
<p>Okay, now let’s redraw our pictures but this time I’ll add some lines to show the size of the residual for all observations. When the regression line is good, our residuals (the lengths of the solid black lines) all look pretty small, as shown in Figure <a href="correlation-and-regression.html#fig:fig12-12">2.12</a>a, but when the regression line is a bad one the residuals are a lot larger, as you can see from looking at Figure <a href="correlation-and-regression.html#fig:fig12-12">2.12</a>b. Hmm. Maybe what we “want” in a regression model is <em>small</em> residuals. Yes, that does seem to make sense. In fact, I think I’ll go so far as to say that the “best fitting” regression line is the one that has the smallest residuals. Or, better yet, since statisticians seem to like to take squares of everything why not say that:</p>
<blockquote>
<p>The estimated regression coefficients, <span class="math inline">\(\hat{b}_0\)</span> and <span class="math inline">\(\hat{b}_1\)</span>, are those that minimise the sum of the squared residuals, which we could either write as <span class="math inline">\(\sum_i (Y_i - \hat{Y}_i)^2\)</span> or as <span class="math inline">\(\sum_i \epsilon_i^2\)</span> .</p>
</blockquote>
<p>Yes, yes that sounds even better. And since I’ve indented it like that, it probably means that this is the right answer. And since this is the right answer, it’s probably worth making a note of the fact that our regression coefficients are estimates (we’re trying to guess the parameters that describe a population!), which is why I’ve added the little hats, so that we get <span class="math inline">\(\hat{b}_0\)</span> and <span class="math inline">\(\hat{b}_1\)</span> rather than <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>. Finally, I should also note that, since there’s actually more than one way to estimate a regression model, the more technical name for this estimation process is <strong>ordinary least squares (OLS) regression</strong>.</p>
<p>At this point, we now have a concrete definition for what counts as our “best” choice of regression coefficients, <span class="math inline">\(\hat{b}_0\)</span> and <span class="math inline">\(\hat{b}_1\)</span>. The natural question to ask next is, if our optimal regression coefficients are those that minimise the sum squared residuals, how do we find these wonderful numbers? The actual answer to this question is complicated and doesn’t help you understand the logic of regression.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Or at least, I’m assuming that it doesn’t help most people. But on the off chance that someone reading this is a proper kung fu master of linear algebra (and to be fair, I always have a few of these people in my intro stats class), it will help you to know that the solution to the estimation problem turns out to be &lt;span class=&quot;math inline&quot;&gt;\(\hat{b} = (X^{'}X)^{-1}X^{'}y\)&lt;/span&gt;, where &lt;span class=&quot;math inline&quot;&gt;\(\hat{b}\)&lt;/span&gt; is a vector containing the estimated regression coefficients, &lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt; is the “design matrix” that contains the predictor variables (plus an additional column containing all ones; strictly &lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt; is a matrix of the regressors, but I haven’t discussed the distinction yet), and y is a vector containing the outcome variable. For everyone else, this isn’t exactly helpful and can be downright scary. However, since quite a few things in linear regression can be written in linear algebra terms, you’ll see a bunch of footnotes like this one in this chapter. If you can follow the maths in them, great. If not, ignore it.&lt;/p&gt;"><sup>11</sup></a> This time I’m going to let you off the hook. Instead of showing you the long and tedious way first and then “revealing” the wonderful shortcut that jamovi provides, let’s cut straight to the chase and just use jamovi to do all the heavy lifting.</p>
<div id="linear-regression-in-jamovi" class="section level3" number="2.4.1">
<h3>
<span class="header-section-number">2.4.1</span> Linear regression in jamovi<a class="anchor" aria-label="anchor" href="#linear-regression-in-jamovi"><i class="fas fa-link"></i></a>
</h3>
<p>To run my linear regression, open up the ‘Regression’ - ‘Linear Regression’ analysis in jamovi, using the parenthood.csv data file. Then specify dani.grump as the ‘Dependent Variable’ and dani.sleep as the variable entered in the ‘Covariates’ box. This gives the results shown in Figure <a href="correlation-and-regression.html#fig:fig12-13">2.13</a>, showing an intercept <span class="math inline">\(\hat{b}_0 = 125.96\)</span> and the slope <span class="math inline">\(\hat{b}_1 = -8.94\)</span>. In other words, the best fitting regression line that I plotted in Figure <a href="correlation-and-regression.html#fig:fig12-11">2.11</a> has this formula:</p>
<p><span class="math display">\[\hat{Y}_i=125.96+(-8.94 X_i)\]</span></p>
</div>
<div id="interpreting-the-estimated-model" class="section level3" number="2.4.2">
<h3>
<span class="header-section-number">2.4.2</span> Interpreting the estimated model<a class="anchor" aria-label="anchor" href="#interpreting-the-estimated-model"><i class="fas fa-link"></i></a>
</h3>
<p>The most important thing to be able to understand is how to interpret these coefficients. Let’s start with <span class="math inline">\(\hat{b}_1\)</span>, the slope. If we remember the definition of the slope, a regression coefficient of <span class="math inline">\(\hat{b}_1 = -8.94\)</span> means that if I increase Xi by 1, then I’m decreasing Yi by 8.94. That is, each additional hour of sleep that I gain will improve my mood, reducing my grumpiness by 8.94 grumpiness points. What about the intercept? Well, since <span class="math inline">\(\hat{b}_0\)</span> corresponds to “the expected value of <span class="math inline">\(Y_i\)</span> when <span class="math inline">\(X_i\)</span> equals 0”, it’s pretty straightforward. It implies that if I get zero hours of sleep (<span class="math inline">\(X_i = 0\)</span>) then my grumpiness will go off the scale, to an insane value of (<span class="math inline">\(Y_i = 125.96\)</span>). Best to be avoided, I think.</p>
<div class="figure">
<span style="display:block;" id="fig:fig12-13"></span>
<img src="images/Figure117.PNG" alt="A jamovi screenshot showing a simple linear regression analysis" width="90%"><p class="caption">
Figure 2.13: A jamovi screenshot showing a simple linear regression analysis
</p>
</div>
</div>
</div>
<div id="multiple-linear-regression" class="section level2" number="2.5">
<h2>
<span class="header-section-number">2.5</span> Multiple linear regression<a class="anchor" aria-label="anchor" href="#multiple-linear-regression"><i class="fas fa-link"></i></a>
</h2>
<p>The simple linear regression model that we’ve discussed up to this point assumes that there’s a single predictor variable that you’re interested in, in this case dani.sleep. In fact, up to this point every statistical tool that we’ve talked about has assumed that your analysis uses one predictor variable and one outcome variable. However, in many (perhaps most) research projects you actually have multiple predictors that you want to examine. If so, it would be nice to be able to extend the linear regression framework to be able to include multiple predictors. Perhaps some kind of <strong>multiple regression</strong> model would be in order?</p>
<p>Multiple regression is conceptually very simple. All we do is add more terms to our regression equation. Let’s suppose that we’ve got two variables that we’re interested in; perhaps we want to use both dani.sleep and baby.sleep to predict the dani.grump variable. As before, we let <span class="math inline">\(Y_{i}\)</span> refer to my grumpiness on the i-th day. But now we have two $ X $ variables: the first corresponding to the amount of sleep I got and the second corresponding to the amount of sleep my son got. So we’ll let <span class="math inline">\(X_{i1}\)</span> refer to the hours I slept on the i-th day and <span class="math inline">\(X_{i2}\)</span> refers to the hours that the baby slept on that day. If so, then we can write our regression model like this:</p>
<p><span class="math display">\[Y_i=b_0+b_1X_{i1}+b_2X_{i2}+\epsilon_i\]</span></p>
<p>As before, <span class="math inline">\(\epsilon_i\)</span> is the residual associated with the i-th observation, <span class="math inline">\(\epsilon_i = Y_i - \hat{Y}_i\)</span>. In this model, we now have three coefficients that need to be estimated: b0 is the intercept, b1 is the coefficient associated with my sleep, and b2 is the coefficient associated with my son’s sleep. However, although the number of coefficients that need to be estimated has changed, the basic idea of how the estimation works is unchanged: our estimated coefficients <span class="math inline">\(\hat{b}_0\)</span>, <span class="math inline">\(\hat{b}_1\)</span> and <span class="math inline">\(\hat{b}_2\)</span> are those that minimise the sum squared residuals.</p>
<div id="doing-it-in-jamovi" class="section level3" number="2.5.1">
<h3>
<span class="header-section-number">2.5.1</span> Doing it in jamovi<a class="anchor" aria-label="anchor" href="#doing-it-in-jamovi"><i class="fas fa-link"></i></a>
</h3>
<p>Multiple regression in jamovi is no different to simple regression. All we have to do is add additional variables to the ‘Covariates’ box in jamovi. For example, if we want to use both dani.sleep and baby.sleep as predictors in our attempt to explain why I’m so grumpy, then move baby.sleep across into the ‘Covariates’ box alongside dani.sleep. By default, jamovi assumes that the model should include an intercept. The coefficients we get this time are shown in Table <a href="correlation-and-regression.html#tab:tab12-4">2.4</a>.</p>
<div class="inline-table"><table class="huxtable" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  " id="tab:tab12-4">
<caption style="caption-side: bottom; text-align: left;">
<span id="tab:tab12-4">Table 2.4: </span> Adding multiple variables as predictors in a regression</caption>
<col>
<col>
<col>
<tr>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: bold;">(Intercept)</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">dani.sleep</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">baby.sleep</th>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; font-weight: normal;">125.97</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">-8.95</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; font-weight: normal;">0.01</td>
</tr>
</table></div>
<p>The coefficient associated with dani.sleep is quite large, suggesting that every hour of sleep I lose makes me a lot grumpier. However, the coefficient for baby.sleep is very small, suggesting that it doesn’t really matter how much sleep my son gets. What matters as far as my grumpiness goes is how much sleep I get. To get a sense of what this multiple regression model looks like, Figure @ref(fig:fig12.14) shows a 3D plot that plots all three variables, along with the regression model itself.</p>
<p>Statistical notation <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The formula for the general case: The equation that I gave in the main text shows you what a multiple regression model looks like when you include two predictors. Not surprisingly then, if you want more than two predictors all you have to do is add more X terms and more b coefficients. In other words, if you have K predictor variables in the model then the regression equation look like this &lt;span class="math display"&gt;\[Y_i=b_0+(\sum_{k=1}^{K}b_k X_{ik})+\epsilon_i\]&lt;/span&gt;&lt;/p&gt;'><sup>12</sup></a></p>
<div class="figure">
<span style="display:block;" id="fig:fig12-14"></span>
<img src="images/Figure118.PNG" alt="A 3D visualisation of a multiple regression model. There are two predictors in the model, dani.sleep and baby.sleep and the outcome variable is dani.grump. Together, these three variables form a 3D space. Each observation (dot) is a point in this space. In much the same way that a simple linear regression model forms a line in 2D space, this multiple regression model forms a plane in 3D space. When we estimate the regression coefficients what we're trying to do is find a plane that is as close to all the blue dots as possible" width="90%"><p class="caption">
Figure 2.14: A 3D visualisation of a multiple regression model. There are two predictors in the model, dani.sleep and baby.sleep and the outcome variable is dani.grump. Together, these three variables form a 3D space. Each observation (dot) is a point in this space. In much the same way that a simple linear regression model forms a line in 2D space, this multiple regression model forms a plane in 3D space. When we estimate the regression coefficients what we’re trying to do is find a plane that is as close to all the blue dots as possible
</p>
</div>
</div>
</div>
<div id="quantifying-the-fit-of-the-regression-model" class="section level2" number="2.6">
<h2>
<span class="header-section-number">2.6</span> Quantifying the fit of the regression model<a class="anchor" aria-label="anchor" href="#quantifying-the-fit-of-the-regression-model"><i class="fas fa-link"></i></a>
</h2>
<p>So we now know how to estimate the coefficients of a linear regression model. The problem is, we don’t yet know if this regression model is any good. For example, the regression.1 model claims that every hour of sleep will improve my mood by quite a lot, but it might just be rubbish. Remember, the regression model only produces a prediction <span class="math inline">\(\hat{Y}_i\)</span> about what my mood is like, but my actual mood is <span class="math inline">\(Y_i\)</span> . If these two are very close, then the regression model has done a good job. If they are very different, then it has done a bad job.</p>
<div id="the-r2-value" class="section level3" number="2.6.1">
<h3>
<span class="header-section-number">2.6.1</span> The <span class="math inline">\(R^2\)</span> value<a class="anchor" aria-label="anchor" href="#the-r2-value"><i class="fas fa-link"></i></a>
</h3>
<p>Once again, let’s wrap a little bit of mathematics around this. Firstly, we’ve got the sum of the squared residuals</p>
<p><span class="math display">\[SS_{res}=\sum_i (Y_i-\hat{Y_i})^2\]</span></p>
<p>which we would hope to be pretty small. Specifically, what we’d like is for it to be very small in comparison to the total variability in the outcome variable</p>
<p><span class="math display">\[SS_{tot}=\sum_i(Y_i-\bar{Y})^2\]</span></p>
<p>While we’re here, let’s calculate these values ourselves, not by hand though. Let’s use something like Excel or another standard spreadsheet programme. I have done this by opening up the parenthood.csv file in Excel and saving it as parenthood rsquared.xls so that I can work on it. The first thing to do is calculate the values, and for the simple model that uses only a single predictor we would do the following:</p>
<ol style="list-style-type: decimal">
<li>create a new column called ‘Y.pred’ using the formula ‘= 125.97 + (-8.94 <span class="math inline">\(\times\)</span> dani.sleep)’</li>
<li>calculate the SS(resid) by creating a new column called ‘(Y-Y.pred)^2’ using the formula ’ = (dani.grump - Y.pred)^2 ’.</li>
<li>Then, at the bottom of this column calculate the sum of these values, i.e. ’ sum( ( Y-Y.pred)^2 ) .</li>
<li>At the bottom of the dani.grump column, calculate the mean value for dani.grump (NB Excel uses the word ’ AVERAGE ’ rather than ‘mean’ in its function).</li>
<li>Then create a new column, called ’ (Y - mean(Y))^2 )’ using the formula ’ = (dani.grump - AVERAGE(dani.grump))^2 ’.</li>
<li>Then, at the bottom of this column calculate the sum of these values, i.e. ‘sum( (Y - mean(Y))^2 )’.</li>
<li>Calculate R.squared by typing into a blank cell the following: ‘= 1 - (SS(resid) / SS(tot) )’.</li>
</ol>
<p>This gives a value for <span class="math inline">\(R^2\)</span> of ‘0.8161018’. The <span class="math inline">\(R^2\)</span> value, sometimes called the <strong>coefficient of determination</strong><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;And by “sometimes” I mean “almost never”. In practice everyone just calls it “R-squared”.&lt;/p&gt;"><sup>13</sup></a> has a simple interpretation: it is the proportion of the variance in the outcome variable that can be accounted for by the predictor. So, in this case the fact that we have obtained <span class="math inline">\(R^2 = .816\)</span> means that the predictor (my.sleep) explains <span class="math inline">\(81.6\%\)</span> of the variance in the outcome (my.grump).</p>
<p>Naturally, you don’t actually need to type all these commands into Excel yourself if you want to obtain the <span class="math inline">\(R^2\)</span> value for your regression model. As we’ll see later on in Section 12.7.3, all you need to do is specify this as an option in jamovi. However, let’s put that to one side for the moment. There’s another property of <span class="math inline">\(R^2\)</span> that I want to point out.</p>
</div>
<div id="the-relationship-between-regression-and-correlation" class="section level3" number="2.6.2">
<h3>
<span class="header-section-number">2.6.2</span> The relationship between regression and correlation<a class="anchor" aria-label="anchor" href="#the-relationship-between-regression-and-correlation"><i class="fas fa-link"></i></a>
</h3>
<p>At this point we can revisit my earlier claim that regression, in this very simple form that I’ve discussed so far, is basically the same thing as a correlation. Previously, we used the symbol <span class="math inline">\(r\)</span> to denote a Pearson correlation. Might there be some relationship between the value of the correlation coefficient <span class="math inline">\(r\)</span> and the <span class="math inline">\(R^2\)</span> value from linear regression? Of course there is: the squared correlation <span class="math inline">\(r^2\)</span> is identical to the <span class="math inline">\(R^2\)</span> value for a linear regression with only a single predictor. In other words, running a Pearson correlation is more or less equivalent to running a linear regression model that uses only one predictor variable.</p>
</div>
<div id="the-adjusted-r2-value" class="section level3" number="2.6.3">
<h3>
<span class="header-section-number">2.6.3</span> The adjusted <span class="math inline">\(R^2\)</span> value<a class="anchor" aria-label="anchor" href="#the-adjusted-r2-value"><i class="fas fa-link"></i></a>
</h3>
<p>One final thing to point out before moving on. It’s quite common for people to report a slightly different measure of model performance, known as “adjusted <span class="math inline">\(R^2\)</span>”. The motivation behind calculating the adjusted <span class="math inline">\(R^2\)</span> value is the observation that adding more predictors into the model will always cause the <span class="math inline">\(R^2\)</span> value to increase (or at least not decrease).</p>
<p>Statistical notation <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The adjusted &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; value introduces a slight change to the calculation, as follows. For a regression model with &lt;span class="math inline"&gt;\(K\)&lt;/span&gt; predictors, fit to a data set containing &lt;span class="math inline"&gt;\(N\)&lt;/span&gt; observations, the adjusted &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; is: &lt;span class="math display"&gt;\[\text{adj.}R^2=1-(\frac{SS_{res}}{SS_{tot}} \times \frac{N-1}{N-K-1})\]&lt;/span&gt;&lt;/p&gt;'><sup>14</sup></a></p>
<p>This adjustment is an attempt to take the degrees of freedom into account. The big advantage of the adjusted <span class="math inline">\(R^2\)</span> value is that when you add more predictors to the model, the adjusted <span class="math inline">\(R^2\)</span> value will only increase if the new variables improve the model performance more than you’d expect by chance. The big disadvantage is that the adjusted <span class="math inline">\(R^2\)</span> value can’t be interpreted in the elegant way that <span class="math inline">\(R^2\)</span> can. <span class="math inline">\(R^2\)</span> has a simple interpretation as the proportion of variance in the outcome variable that is explained by the regression model. To my knowledge, no equivalent interpretation exists for adjusted <span class="math inline">\(R^2\)</span>.</p>
<p>An obvious question then is whether you should report <span class="math inline">\(R^2\)</span> or adjusted <span class="math inline">\(R^2\)</span> . This is probably a matter of personal preference. If you care more about interpretability, then <span class="math inline">\(R^2\)</span> is better. If you care more about correcting for bias, then adjusted <span class="math inline">\(R^2\)</span> is probably better. Speaking just for myself, I prefer <span class="math inline">\(R^2\)</span>. My feeling is that it’s more important to be able to interpret your measure of model performance. Besides, as we’ll see in Section 12.7, if you’re worried that the improvement in <span class="math inline">\(R^2\)</span> that you get by adding a predictor is just due to chance and not because it’s a better model, well we’ve got hypothesis tests for that.</p>
</div>
</div>
<div id="hypothesis-tests-for-regression-models" class="section level2" number="2.7">
<h2>
<span class="header-section-number">2.7</span> Hypothesis tests for regression models<a class="anchor" aria-label="anchor" href="#hypothesis-tests-for-regression-models"><i class="fas fa-link"></i></a>
</h2>
<p>So far we’ve talked about what a regression model is, how the coefficients of a regression model are estimated, and how we quantify the performance of the model (the last of these, incidentally, is basically our measure of effect size). The next thing we need to talk about is hypothesis tests. There are two different (but related) kinds of hypothesis tests that we need to talk about: those in which we test whether the regression model as a whole is performing significantly better than a null model, and those in which we test whether a particular regression coefficient is significantly different from zero.</p>
<div id="testing-the-model-as-a-whole" class="section level3" number="2.7.1">
<h3>
<span class="header-section-number">2.7.1</span> Testing the model as a whole<a class="anchor" aria-label="anchor" href="#testing-the-model-as-a-whole"><i class="fas fa-link"></i></a>
</h3>
<p>Okay, suppose you’ve estimated your regression model. The first hypothesis test you might try is the null hypothesis that there is no relationship between the predictors and the outcome, and the alternative hypothesis that the data are distributed in exactly the way that the regression model predicts.</p>
<p>Statistical notation <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Formally, our “null model” corresponds to the fairly trivial “regression” model in which we include 0 predictors and only include the intercept term &lt;span class="math inline"&gt;\(b_0\)&lt;/span&gt;: &lt;span class="math inline"&gt;\(H_0:Y_0=b_0+\epsilon_i\)&lt;/span&gt; If our regression model has &lt;span class="math inline"&gt;\(K\)&lt;/span&gt; predictors, the “alternative model” is described using the usual formula for a multiple regression model: &lt;span class="math inline"&gt;\(H_1:Y_i=b_0+(\sum_{k=1}^K b_k X_{ik})+\epsilon_i\)&lt;/span&gt; How can we test these two hypotheses against each other? The trick is to understand that it’s possible to divide up the total variance SStot into the sum of the residual variance SSres and the regression model variance SSmod. I’ll skip over the technicalities, since we’ll get to that later when we look at ANOVA in Chapter &lt;strong&gt;13&lt;/strong&gt;. But just note that &lt;span class="math inline"&gt;\(SS_{mod}=SS_{tot}-SS_{res}\)&lt;/span&gt; And we can convert the sums of squares into mean squares by dividing by the degrees of freedom. &lt;span class="math inline"&gt;\(MS_{mod}=\frac{SS_{mod}}{df_{mod}}\)&lt;/span&gt; &lt;span class="math inline"&gt;\(MS_{res}=\frac{SS_{res}}{df_{res}}\)&lt;/span&gt; So, how many degrees of freedom do we have? As you might expect the df associated with the model is closely tied to the number of predictors that we’ve included. In fact, it turns out that &lt;span class="math inline"&gt;\(df_mod = K\)&lt;/span&gt;. For the residuals the total degrees of freedom is &lt;span class="math inline"&gt;\(df_res = N - K - 1\)&lt;/span&gt;. Now that we’ve got our mean square values we can calculate an F-statistic like this &lt;span class="math inline"&gt;\(F=\frac{MS_{mod}}{MS_{res}}\)&lt;/span&gt; and the degrees of freedom associated with this are K and &lt;span class="math inline"&gt;\(N - K - 1\)&lt;/span&gt;.&lt;/p&gt;'><sup>15</sup></a></p>
<p>We’ll see much more of the F statistic in the chapter on <span style="background-color:Gainsboro;font-style:italic;">Comparing several means (one-waty ANOVA), but for now just know that we can interpret large F values as indicating that the null hypothesis is performing poorly in comparison to the alternative hypothesis. In a moment I’ll show you how to do the test in jamovi the easy way, but first let’s have a look at the tests for the individual regression coefficients.</span></p>
<p>Now that we’ve got the basic idea, let’s have a look at a concrete example. Once again, let’s use the first five AFL games as our data. If we follow the same approach that we took last time, we end up with the information shown in Table <a href="correlation-and-regression.html#tab:tab4-3">2.5</a>.</p>
<div class="inline-table"><table class="huxtable" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  " id="tab:tab4-3">
<caption style="caption-side: bottom; text-align: left;">
<span id="tab:tab4-3">Table 2.5: </span> Measures  of variability for the first five AFL games</caption>
<col>
<col>
<col>
<col>
<col>
<tr>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: bold;">English</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">maths:</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">value</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">deviation from mean</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">absolute deviation</th>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 0pt; font-weight: normal;">notation:</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">\(i\)</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">\(X_i\)</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">\(X_i - \bar{X} \)</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 0pt 6pt 6pt; font-weight: normal;">\( ( X_i - \bar{X} )^2 \)</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;"></td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">1</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">56</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">19.4</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">376.36</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;"></td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">2</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">31</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">-5.6</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">31.36</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;"></td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">3</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">56</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">19.4</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">376.36</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; font-weight: normal;"></td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">4</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">8</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; font-weight: normal;">-28.6</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; font-weight: normal;">817.96</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;"></td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">5</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">32</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">-4.6</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">21.16</td>
</tr>
</table></div>
<p>That last column contains all of our squared deviations, so all we have to do is average them. If we do that by hand, i.e. using a calculator, we end up with a variance of <span class="math inline">\(324.64\)</span>. Exciting, isn’t it? For the moment, let’s ignore the burning question that you’re all probably thinking (i.e., what the heck does a variance of <span class="math inline">\(324.64\)</span> actually mean?) and instead talk a bit more about how to do the calculations in jamovi, because this will reveal something very weird. Start a new jamovi session by clicking on the main menu button (three horizontal lines in the top left corner and selecting ‘New’. Now type in the first five values from the afl.margins data set in column A (<span class="math inline">\(56\)</span>, <span class="math inline">\(31\)</span>, <span class="math inline">\(56\)</span>, <span class="math inline">\(8\)</span>, <span class="math inline">\(32\)</span>. Change the variable type to ‘Continuous’ and under ‘Descriptives’ click the ‘Variance’ check box, and you get the same values for variance as the one we calculated by hand (<span class="math inline">\(324.64\)</span>). No, wait, you get a completely different answer (<span class="math inline">\(405.80\)</span>) - see Figure <a href="correlation-and-regression.html#fig:fig4-9">2.15</a>. That’s just weird. Is jamovi broken? Is this a typo? Am I an idiot?</p>
<div class="figure">
<span style="display:block;" id="fig:fig4-9"></span>
<img src="images/Figure16.PNG" alt="A screenshot of jamovi showing the Variance for the first 5 values of the afl.margins variable" width="90%"><p class="caption">
Figure 2.15: A screenshot of jamovi showing the Variance for the first 5 values of the afl.margins variable
</p>
</div>
<p>As it happens, the answer is no.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;With the possible exception of the third question.&lt;/p&gt;"><sup>16</sup></a> It’s not a typo, and jamovi is not making a mistake. In fact, it’s very simple to explain what jamovi is doing here, but slightly trickier to explain why jamovi is doing it. So let’s start with the “what”. What jamovi is doing is evaluating a slightly different formula to the one I showed you above. Instead of averaging the squared deviations, which requires you to divide by the number of data points N, jamovi has chosen to divide by <span class="math inline">\(N - 1\)</span>.</p>
<p><span style="background-color:Gainsboro;font-style:italic;">[Option: statistical formulae]</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span style="background-color:Gainsboro;font-style:italic;"&gt;In other words, the formula that jamovi is using is this one: &lt;span class="math display"&gt;\[\frac{1}{N-1} \sum_{i=1}^{N} ( X_i - \bar{X} )^2\]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;'><sup>17</sup></a></p>
<p>So that’s the <em>what</em>. The real question is why jamovi is dividing by <span class="math inline">\(N - 1\)</span> and not by <span class="math inline">\(N\)</span>. After all, the variance is supposed to be the mean squared deviation, right? So shouldn’t we be dividing by N, the actual number of observations in the sample? Well, yes, we should. However, as we’ll discuss in the chapter on [Estimating unknown quantities from a sample], there’s a subtle distinction between “describing a sample” and “making guesses about the population from which the sample came”. Up to this point, it’s been a distinction without a difference. Regardless of whether you’re describing a sample or drawing inferences about the population, the mean is calculated exactly the same way. Not so for the variance, or the standard deviation, or for many other measures besides. What I outlined to you initially (i.e., take the actual average, and thus divide by <span class="math inline">\(N\)</span>) assumes that you literally intend to calculate the variance of the sample. Most of the time, however, you’re not terribly interested in the sample in and of itself. Rather, the sample exists to tell you something about the world. If so, you’re actually starting to move away from calculating a “sample statistic” and towards the idea of estimating a “population parameter”. However, I’m getting ahead of myself. For now, let’s just take it on faith that jamovi knows what it’s doing, and we’ll revisit the question later on when we talk about estimation in the chapter on [Estimating unknown quantities from a sample].</p>
<p>Okay, one last thing. This section so far has read a bit like a mystery novel. I’ve shown you how to calculate the variance, described the weird “<span class="math inline">\(N - 1\)</span>” thing that jamovi does and hinted at the reason why it’s there, but I haven’t mentioned the single most important thing. How do you interpret the variance? Descriptive statistics are supposed to describe things, after all, and right now the variance is really just a gibberish number. Unfortunately, the reason why I haven’t given you the human-friendly interpretation of the variance is that there really isn’t one. This is the most serious problem with the variance. Although it has some elegant mathematical properties that suggest that it really is a fundamental quantity for expressing variation, it’s completely useless if you want to communicate with an actual human. Variances are completely uninterpretable in terms of the original variable! All the numbers have been squared and they don’t mean anything anymore. This is a huge issue. For instance, according to Table <a href="correlation-and-regression.html#tab:tab4-3">2.5</a>, the margin in game 1 was “376.36 points-squared higher than the average margin”. This is <em>exactly</em> as stupid as it sounds, and so when we calculate a variance of <span class="math inline">\(324.64\)</span> we’re in the same situation. I’ve watched a lot of footy games, and at no time has anyone ever referred to “points squared”. It’s not a real unit of measurement, and since the variance is expressed in terms of this gibberish unit, it is totally meaningless to a human.</p>
</div>
<div id="standard-deviation" class="section level3" number="2.7.2">
<h3>
<span class="header-section-number">2.7.2</span> Standard deviation<a class="anchor" aria-label="anchor" href="#standard-deviation"><i class="fas fa-link"></i></a>
</h3>
<p>Okay, suppose that you like the idea of using the variance because of those nice mathematical properties that I haven’t talked about, but since you’re a human and not a robot you’d like to have a measure that is expressed in the same units as the data itself (i.e., points, not points squared). What should you do? The solution to the problem is obvious! Take the square root of the variance, known as the <strong>standard deviation</strong>, also called the “root mean squared deviation”, or RMSD. This solves our problem fairly neatly. Whilst nobody has a clue what “a variance of 324.68 points-squared” really means, it’s much easier to understand “a standard deviation of 18.01 points” since it’s expressed in the original units. It is traditional to refer to the standard deviation of a sample of data as s, though “sd” and “std dev.” are also used at times.</p>
<p><span style="background-color:Gainsboro;font-style:italic;">[Option: statistical formulae]</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span style="background-color:Gainsboro;font-style:italic;"&gt;Because the standard deviation is equal to the square root of the variance, you probably won’t be surprised to see that the formula is: &lt;span class="math display"&gt;\[s=\sqrt{\frac{1}{N} \sum_{i=1}^{N} ( X_i - \bar{X} )^2 }\]&lt;/span&gt; and in jamovi there is a check box for ‘Std. deviation’ right above the check box for ‘Variance’. Selecting this gives a value of &lt;span class="math inline"&gt;\(26.07\)&lt;/span&gt; for the standard deviation.&lt;/span&gt;&lt;/p&gt;'><sup>18</sup></a></p>
<p>However, as you might have guessed from our discussion of the variance, what jamovi actually calculates is slightly different to the formula given above. Just like the we saw with the variance, what jamovi calculates is a version that divides by <span class="math inline">\(N - 1\)</span> rather than <span class="math inline">\(N\)</span>.</p>
<p><span style="background-color:Gainsboro;font-style:italic;">[Option: statistical formulae]</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span style="background-color:Gainsboro;font-style:italic;"&gt;For reasons that will make sense when we return to this topic in the chapter on [Estimating unknown quantities from a sample] I’ll refer to this new quantity as &lt;span class="math inline"&gt;\(\hat{\sigma}\)&lt;/span&gt; (read as: “sigma hat”), and the formula for this is: &lt;span class="math display"&gt;\[\hat{\sigma}=\sqrt{\frac{1}{N-1} \sum_{i=1}^{N} ( X_i - \bar{X} )^2}\]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;'><sup>19</sup></a></p>
<p>Interpreting standard deviations is slightly more complex. Because the standard deviation is derived from the variance, and the variance is a quantity that has little to no meaning that makes sense to us humans, the standard deviation doesn’t have a simple interpretation. As a consequence, most of us just rely on a simple rule of thumb. In general, you should expect 68% of the data to fall within 1 standard deviation of the mean, 95% of the data to fall within 2 standard deviation of the mean, and 99.7% of the data to fall within 3 standard deviations of the mean. This rule tends to work pretty well most of the time, but it’s not exact. It’s actually calculated based on an assumption that the histogram is symmetric and “bell shaped”.[^04.5] As you can tell from looking at the AFL winning margins histogram in Figure <a href="#fig:fig4-2"><strong>??</strong></a>, this isn’t exactly true of our data! Even so, the rule is approximately correct. As it turns out, 65.3% of the AFL margins data fall within one standard deviation of the mean. This is shown visually in <a href="correlation-and-regression.html#fig:fig4-10">2.16</a>.</p>
</div>
<div id="which-measure-to-use" class="section level3" number="2.7.3">
<h3>
<span class="header-section-number">2.7.3</span> Which measure to use?<a class="anchor" aria-label="anchor" href="#which-measure-to-use"><i class="fas fa-link"></i></a>
</h3>
<p>We’ve discussed quite a few measures of spread: range, IQR, mean absolute deviation, variance and standard deviation; and hinted at their strengths and weaknesses. Here’s a quick summary:</p>
<ul>
<li>
<em>Range</em>. Gives you the full spread of the data. It’s very vulnerable to outliers and as a consequence it isn’t often used unless you have good reasons to care about the extremes in the data.</li>
<li>
<em>Interquartile range</em>. Tells you where the “middle half” of the data sits. It’s pretty robust and complements the median nicely. This is used a lot.</li>
<li>
<em>Mean absolute deviation</em>. Tells you how far “on average” the observations are from the mean. It’s very interpretable but has a few minor issues (not discussed here) that make it less attractive to statisticians than the standard deviation. Used sometimes, but not often.</li>
<li>
<em>Variance</em>. Tells you the average squared deviation from the mean. It’s mathematically elegant and is probably the “right” way to describe variation around the mean, but it’s completely uninterpretable because it doesn’t use the same units as the data. Almost never used except as a mathematical tool, but it’s buried “under the hood” of a very large number of statistical tools.</li>
<li>
<em>Standard deviation</em>. This is the square root of the variance. It’s fairly elegant mathematically and it’s expressed in the same units as the data so it can be interpreted pretty well. In situations where the mean is the measure of central tendency, this is the default. This is by far the most popular measure of variation.</li>
</ul>
<p>In short, the IQR and the standard deviation are easily the two most common measures used to report the variability of the data. But there are situations in which the others are used. I’ve described all of them in this book because there’s a fair chance you’ll run into most of these somewhere.</p>
<div class="figure">
<span style="display:block;" id="fig:fig4-10"></span>
<img src="images/Figure17.PNG" alt="An illustration of the standard deviation from the AFL winning margins data. The shaded bars in the histogram show how much of the data fall within one standard deviation of the mean. In this case, 65.3% of the data set lies within this range, which is pretty consistent with the 'approximately 68% rule' discussed in the main text" width="90%"><p class="caption">
Figure 2.16: An illustration of the standard deviation from the AFL winning margins data. The shaded bars in the histogram show how much of the data fall within one standard deviation of the mean. In this case, 65.3% of the data set lies within this range, which is pretty consistent with the ‘approximately 68% rule’ discussed in the main text
</p>
</div>
</div>
</div>
<div id="skew-and-kurtosis" class="section level2" number="2.8">
<h2>
<span class="header-section-number">2.8</span> Skew and kurtosis<a class="anchor" aria-label="anchor" href="#skew-and-kurtosis"><i class="fas fa-link"></i></a>
</h2>
<p>There are two more descriptive statistics that you will sometimes see reported in the psychological literature: skew and kurtosis. In practice, neither one is used anywhere near as frequently as the measures of central tendency and variability that we’ve been talking about. Skew is pretty important, so you do see it mentioned a fair bit, but I’ve actually never seen kurtosis reported in a scientific article to date.</p>
<div class="figure">
<span style="display:block;" id="fig:fig4-11"></span>
<img src="images/Figure18.PNG" alt="An illustration of skewness. On the left we have a negatively skewed data set ($skewness = -.93$), in the middle we have a data set with no skew (well, hardly any: $skewness = -.006$), and on the right we have a positively skewed data set ($skewness = .93$)" width="90%"><p class="caption">
Figure 2.17: An illustration of skewness. On the left we have a negatively skewed data set (<span class="math inline">\(skewness = -.93\)</span>), in the middle we have a data set with no skew (well, hardly any: <span class="math inline">\(skewness = -.006\)</span>), and on the right we have a positively skewed data set (<span class="math inline">\(skewness = .93\)</span>)
</p>
</div>
<p>Since it’s the more interesting of the two, let’s start by talking about the <strong>skewness</strong>. Skewness is basically a measure of asymmetry and the easiest way to explain it is by drawing some pictures. As Figure <a href="correlation-and-regression.html#fig:fig4-11">2.17</a> illustrates, if the data tend to have a lot of extreme small values (i.e., the lower tail is “longer” than the upper tail) and not so many extremely large values (left panel) then we say that the data are <em>negatively skewed</em>. On the other hand, if there are more extremely large values than extremely small ones (right panel) we say that the data are positively skewed. That’s the qualitative idea behind skewness. If there are relatively more values that are far greater than the mean, the distribution is positively skewed or right skewed, with a tail stretching to the right. Negative or left skew is the opposite. A symmetric distribution has a skewness of 0. The skewness value for a positively skewed distribution is positive, and a negative value for a negatively skewed distribution.</p>
<p><span style="background-color:Gainsboro;font-style:italic;">[Option: statistical formulae]</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span style="background-color:Gainsboro;font-style:italic;"&gt;One formula for the skewness of a data set is as follows &lt;span class="math display"&gt;\[    skewness(X)=\frac{1}{N \hat{\sigma}^3} \sum_{i=1}^{N} ( X_i - \bar{X})^3\]&lt;/span&gt; where N is the number of observations, &lt;span class="math inline"&gt;\(\bar{X}\)&lt;/span&gt; is the sample mean, and &lt;span class="math inline"&gt;\(\hat{\sigma}\)&lt;/span&gt; is the standard deviation (the “divide by &lt;span class="math inline"&gt;\(N - 1\)&lt;/span&gt;” version, that is).&lt;/span&gt;&lt;/p&gt;'><sup>20</sup></a></p>
<p>Perhaps more helpfully, you can use jamovi to calculate skewness: it’s a check box in the ‘Statistics’ options under ‘Exploration’ - ‘Descriptives’. For the afl.margins variable, the skewness figure is <span class="math inline">\(0.780\)</span>. If you divide the skewness estimate by the Std. error for skewness you have an indication of how skewed the data is. Especially in small samples (N <span class="math inline">\(&lt;\)</span> 50), one rule of thumb suggests that a value of 2 or less can mean that the data is not very skewed, and a value of over 2 that there is sufficient skew in the data to possibly limit its use in some statistical analyses. Though there is no clear agreement on this interpretation. That said, this does indicate that the AFL winning margins data is somewhat skewed (<span class="math inline">\(\frac{0.780}{0.183} = 4.262\)</span>).</p>
<p>The final measure that is sometimes referred to, though very rarely in practice, is the kurtosis of a data set. Put simply, kurtosis is a measure of how thin or fat the tails of a distribution are, as illustrated in Figure @ref(fig:fig4.12). By convention, we say that the “normal curve” (black lines) has zero kurtosis, so the degree of kurtosis is assessed relative to this curve.</p>
<div class="figure">
<span style="display:block;" id="fig:fig4-12"></span>
<img src="images/Figure19.PNG" alt="An illustration of kurtosis. On the left, we have a 'platykurtic' distribution (kurtosis = -.95) meaning that the distribution has 'thin' or flat tails. In the middle we have a 'mesokurtic' distribution (kurtosis is almost exactly 0) which means that the tails are neither thin or fat. Finally, on the right, we have a 'leptokurtic' distribution (kurtosis = 2.12) indicating that the distribution has 'fat' tails. Note that kurtosis is measured with respect to a normal curve (black line)" width="90%"><p class="caption">
Figure 2.18: An illustration of kurtosis. On the left, we have a ‘platykurtic’ distribution (kurtosis = -.95) meaning that the distribution has ‘thin’ or flat tails. In the middle we have a ‘mesokurtic’ distribution (kurtosis is almost exactly 0) which means that the tails are neither thin or fat. Finally, on the right, we have a ‘leptokurtic’ distribution (kurtosis = 2.12) indicating that the distribution has ‘fat’ tails. Note that kurtosis is measured with respect to a normal curve (black line)
</p>
</div>
<p>In this Figure, the data on the left have a pretty flat distribution, with thin tails, so the kurtosis is negative and we call the data platykurtic. The data on the right have a distribution with fat tails, so the kurtosis is positive and we say that the data is leptokurtic. But the data in the middle have neither think or fat tails, so we say that it is mesokurtic and has kurtosis zero. This is summarised in the table below:</p>
<div class="inline-table"><table class="huxtable" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  " id="tab:tab4-4">
<caption style="caption-side: bottom; text-align: left;">
<span id="tab:tab4-4">Table 2.6: </span> Thin to fat tails to illustrate kurtosis</caption>
<col>
<col>
<col>
<tr>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: bold;">English</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">informal term</th>
<th style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: bold;">kurtosis value</th>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 0pt; font-weight: normal;">"tails too thinâ</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">platykurtic</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 6pt 0pt 6pt 6pt; font-weight: normal;">negative</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 0pt; background-color: rgb(242, 242, 242); font-weight: normal;">"tails neither thin or fat"</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 6pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">mesokurtic</td>
<td style="vertical-align: top; text-align: center; white-space: normal; padding: 6pt 0pt 6pt 6pt; background-color: rgb(242, 242, 242); font-weight: normal;">zero</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 0pt; font-weight: normal;">"tails too fatâ</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">leptokurtic</td>
<td style="vertical-align: top; text-align: center; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 6pt 0pt 6pt 6pt; font-weight: normal;">positive</td>
</tr>
</table></div>
<p><span style="background-color:Gainsboro;font-style:italic;">[Option: statistical formulae]</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span style="background-color:Gainsboro;font-style:italic;"&gt;The equation for kurtosis is pretty similar in spirit to the formulas we’ve seen already for the variance and the skewness. Except that where the variance involved squared deviations and the skewness involved cubed deviations, the kurtosis involves raising the deviations to the fourth power:&lt;span class="math inline"&gt;\(^b\)&lt;/span&gt; &lt;span class="math display"&gt;\[kurtosis(X)=\frac{1}{N \hat{\sigma}^4} \sum_{i=1}^{N} ( X_i - \bar{X} )^4 - 3\]&lt;/span&gt; I know, it’s not terribly interesting to me either. &lt;br&gt;—&lt;br&gt;&lt;span class="math inline"&gt;\(^b\)&lt;/span&gt; The “-3” part is something that statisticians tack on to ensure that the normal curve has kurtosis zero. It looks a bit stupid, just sticking a “-3” at the end of the formula, but there are good mathematical reasons for doing this.&lt;/span&gt;&lt;/p&gt;'><sup>21</sup></a></p>
<p>More to the point, jamovi has a check box for kurtosis just below the check box for skewness, and this gives a value for kurtosis of <span class="math inline">\(0.101\)</span> with a standard error of <span class="math inline">\(0.364\)</span>. This means that the AFL winning margins data has only a small kurtosis, which is ok.</p>
</div>
<div id="descriptive-statistics-separately-for-each-group" class="section level2" number="2.9">
<h2>
<span class="header-section-number">2.9</span> Descriptive statistics separately for each group<a class="anchor" aria-label="anchor" href="#descriptive-statistics-separately-for-each-group"><i class="fas fa-link"></i></a>
</h2>
<p>It is very commonly the case that you find yourself needing to look at descriptive statistics broken down by some grouping variable. This is pretty easy to do in jamovi. For instance, let’s say I want to look at the descriptive statistics for some clinical trial data, broken down separately by therapy type. This is a new data set, one that you’ve never seen before. The data is stored in the clinicaltrial.csv file and we’ll use it a lot later on in the chapter on <a href="comparing-several-means-one-way-anova.html#comparing-several-means-one-way-anova">Comparing several means (one-way ANOVA)</a> (you can find a complete description of the data at the start of that chapter). Let’s load it and see what we’ve got:</p>
<p>Evidently there were three drugs: a placebo, something called “anxifree” and something called “joyzepam”, and there were 6 people administered each drug. There were 9 people treated using cognitive behavioural therapy (CBT) and 9 people who received no psychological treatment. And we can see from looking at the ‘Descriptives’ of the mood.gain variable that most people did show a mood gain (<span class="math inline">\(mean = 0.88\)</span>), though without knowing what the scale is here it’s hard to say much more than that. Still, that’s not too bad. Overall I feel that I learned something from that.</p>
<p>We can also go ahead and look at some other descriptive statistics, and this time separately for each type of therapy. In jamovi, check Std. deviation, Skewness and Kurtosis in the ‘Statistics’ options. At the same time, transfer the therapy variable into the ‘Split by’ box, and you should get something like Figure <a href="correlation-and-regression.html#fig:fig4-14">2.20</a></p>
<div class="figure">
<span style="display:block;" id="fig:fig4-13"></span>
<img src="images/Figure20.PNG" alt="A screenshot of jamovi showing the variables stored in the clinicaltrial.csv file" width="90%"><p class="caption">
Figure 2.19: A screenshot of jamovi showing the variables stored in the clinicaltrial.csv file
</p>
</div>
<p>What if you have multiple grouping variables? Suppose you want to look at the average mood gain separately for all possible combinations of drug and therapy. It is possible to do this by adding another variable, drug, into the ‘Split by’ box. Easy peasy, though sometimes if you split too much there isn’t enough data in each breakdown combination to make meaningful calculations. In this case jamovi tells you this by stating something like NaN or Inf. <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Sometimes jamovi will also present numbers in an unusual way. If a number is very small, or very large, then jamovi switches to an exponential form for numbers. For example 6.51e-4 is the same as saying that the decimal point is moved 4 places to the left, so the actual number is 0.000651. If there is a plus sign (i.e. 6.51e+4 then the decimal point is moved to the right, i.e. 65,100.00. Usually only very small or very large numbers are expressed in this way, for example 6.51e-16, which would be quite unwieldy to write out in the normal way.&lt;/p&gt;"><sup>22</sup></a></p>
<div class="figure">
<span style="display:block;" id="fig:fig4-14"></span>
<img src="images/Figure21.PNG" alt="A screenshot of jamovi showing Descriptives split by therapy type" width="90%"><p class="caption">
Figure 2.20: A screenshot of jamovi showing Descriptives split by therapy type
</p>
</div>
</div>
<div id="standard-scores" class="section level2" number="2.10">
<h2>
<span class="header-section-number">2.10</span> Standard scores<a class="anchor" aria-label="anchor" href="#standard-scores"><i class="fas fa-link"></i></a>
</h2>
<p>Suppose my friend is putting together a new questionnaire intended to measure “grumpiness”. The survey has <span class="math inline">\(50\)</span> questions which you can answer in a grumpy way or not. Across a big sample (hypothetically, let’s imagine a million people or so!) the data are fairly normally distributed, with the mean grumpiness score being <span class="math inline">\(17\)</span> out of <span class="math inline">\(50\)</span> questions answered in a grumpy way, and the standard deviation is <span class="math inline">\(5\)</span>. In contrast, when I take the questionnaire I answer <span class="math inline">\(35\)</span> out of <span class="math inline">\(50\)</span> questions in a grumpy way. So, how grumpy am I? One way to think about it would be to say that I have grumpiness of <span class="math inline">\(\frac{35}{50}\)</span>, so you might say that I’m 70% grumpy. But that’s a bit weird, when you think about it. If my friend had phrased her questions a bit differently people might have answered them in a different way, so the overall distribution of answers could easily move up or down depending on the precise way in which the questions were asked. So, I’m only 70% grumpy <em>with respect to this set of survey questions</em>. Even if it’s a very good questionnaire this isn’t very a informative statement.</p>
<p>A simpler way around this is to describe my grumpiness by comparing me to other people. Shockingly, out of my friend’s sample of <span class="math inline">\(1,000,000\)</span> people, only <span class="math inline">\(159\)</span> people were as grumpy as me (that’s not at all unrealistic, frankly) suggesting that I’m in the top 0.016% of people for grumpiness. This makes much more sense than trying to interpret the raw data. This idea, that we should describe my grumpiness in terms of the overall distribution of the grumpiness of humans, is the qualitative idea that standardisation attempts to get at. One way to do this is to do exactly what I just did and describe everything in terms of percentiles. However, the problem with doing this is that “it’s lonely at the top”. Suppose that my friend had only collected a sample of <span class="math inline">\(1000\)</span> people (still a pretty big sample for the purposes of testing a new questionnaire, I’d like to add), and this time gotten, let’s say, a mean of <span class="math inline">\(16\)</span> out of <span class="math inline">\(50\)</span> with a standard deviation of <span class="math inline">\(5\)</span>. The problem is that almost certainly not a single person in that sample would be as grumpy as me.</p>
<p>However, all is not lost. A different approach is to convert my grumpiness score into a <strong>standard score</strong>, also referred to as a z-score. The standard score is defined as the number of standard deviations above the mean that my grumpiness score lies. To phrase it in “pseudomaths” the standard score is calculated like this:</p>
<p><span class="math display">\[
\text{standard score} = \frac{\text{raw score} - mean}{\text{standard deviation}}
\]</span></p>
<p><span style="background-color:Gainsboro;font-style:italic;">[Option: statistical formulae]</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span style="background-color:Gainsboro;font-style:italic;"&gt;In actual maths, the equation for the z-score is &lt;span class="math display"&gt;\[z_i =\frac{X_i - \bar{X}}{\hat{\sigma}}\]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;'><sup>23</sup></a></p>
<p>So, going back to the grumpiness data, we can now transform Dani’s raw grumpiness into a standardised grumpiness score.</p>
<p><span class="math display">\[ z =\frac{35 - 17}{5} = 3.6 \]</span> To interpret this value, recall the rough heuristic that I provided in the section on <a href="correlation-and-regression.html#standard-deviation">Standard deviation</a> in which I noted that 99.7% of values are expected to lie within 3 standard deviations of the mean. So the fact that my grumpiness corresponds to a z score of 3.6 indicates that I’m very grumpy indeed. In fact this suggests that I’m grumpier than 99.98% of people. Sounds about right.</p>
<p>In addition to allowing you to interpret a raw score in relation to a larger population (and thereby allowing you to make sense of variables that lie on arbitrary scales), standard scores serve a second useful function. Standard scores can be compared to one another in situations where the raw scores can’t. Suppose, for instance, my friend also had another questionnaire that measured extraversion using a <span class="math inline">\(24\)</span> item questionnaire. The overall mean for this measure turns out to be 13 with standard deviation <span class="math inline">\(4\)</span>, and I scored a <span class="math inline">\(2\)</span>. As you can imagine, it doesn’t make a lot of sense to try to compare my raw score of <span class="math inline">\(2\)</span> on the extraversion questionnaire to my raw score of 35 on the grumpiness questionnaire. The raw scores for the two variables are “about” fundamentally different things, so this would be like comparing apples to oranges.</p>
<p>What about the standard scores? Well, this is a little different. If we calculate the standard scores we get <span class="math inline">\((z = \frac{(35-17)}{5}=3.6)\)</span> for grumpiness and <span class="math inline">\((z = \frac{(2-13)}{4}=-2.75)\)</span> for extraversion. These two numbers can be compared to each other.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Though some caution is usually warranted. It’s not always the case that one standard deviation on variable A corresponds to the same “kind” of thing as one standard deviation on variable B. Use common sense when trying to determine whether or not the z scores of two variables can be meaningfully compared&lt;/p&gt;"><sup>24</sup></a> I’m much less extraverted than most people (<span class="math inline">\(z = -2.75\)</span>) and much grumpier than most people (<span class="math inline">\(z=3.6\)</span>). But the extent of my unusualness is much more extreme for grumpiness, since <span class="math inline">\(3.6\)</span> is a bigger number than <span class="math inline">\(2.75\)</span>. Because each standardised score is a statement about where an observation falls relative to its own population, it is possible to compare standardised scores across completely different variables.</p>
</div>
<div id="summary" class="section level2" number="2.11">
<h2>
<span class="header-section-number">2.11</span> Summary<a class="anchor" aria-label="anchor" href="#summary"><i class="fas fa-link"></i></a>
</h2>
<p>Calculating some basic descriptive statistics is one of the very first things you do when analysing real data, and descriptive statistics are much simpler to understand than inferential statistics, so like every other statistics textbook I’ve started with descriptives. In this chapter, we talked about the following topics:</p>
<ul>
<li>[Measures of central tendency]. Broadly speaking, central tendency measures tell you where the data are. There’s three measures that are typically reported in the literature: the mean, median and mode.</li>
<li>[Measures of variability]. In contrast, measures of variability tell you about how “spread out” the data are. The key measures are: range, standard deviation, and interquartile range.</li>
<li>
<a href="correlation-and-regression.html#skew-and-kurtosis">Skew and kurtosis</a>. We also looked at assymetry in a variable’s distribution (skew) and thin or fat tailed distributions (kurtosis).</li>
<li>
<a href="correlation-and-regression.html#descriptive-statistics-separately-for-each-group">Descriptive statistics separately for each group</a>. Since this book focuses on doing data analysis in jamovi, we spent a bit of time talking about how descriptive statistics are computed for different subgroups.</li>
<li>
<a href="correlation-and-regression.html#standard-scores">Standard scores</a>. The z-score is a slightly unusual beast. It’s not quite a descriptive statistic, and not quite an inference. Make sure you understand this section. It’ll come up again later.</li>
</ul>
<p>In the next Chapter we’ll move on to a discussion of how to draw pictures! Everyone loves a pretty picture, right? But before we do, I want to end on an important point. A traditional first course in statistics spends only a small proportion of the class on descriptive statistics, maybe one or two lectures at most. The vast majority of the lecturer’s time is spent on inferential statistics because that’s where all the hard stuff is. That makes sense, but it hides the practical everyday importance of choosing good descriptives. With that in mind…</p>
<hr>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="why-do-we-learn-statistics.html"><span class="header-section-number">1</span> Why do we learn statistics</a></div>
<div class="next"><a href="drawing-graphs.html"><span class="header-section-number">3</span> Drawing graphs</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#correlation-and-regression"><span class="header-section-number">2</span> Correlation and regression</a></li>
<li>
<a class="nav-link" href="#correlations"><span class="header-section-number">2.1</span> Correlations</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-data"><span class="header-section-number">2.1.1</span> The data</a></li>
<li><a class="nav-link" href="#the-strength-and-direction-of-a-relationship"><span class="header-section-number">2.1.2</span> The strength and direction of a relationship</a></li>
<li><a class="nav-link" href="#the-correlation-coefficient"><span class="header-section-number">2.1.3</span> The correlation coefficient</a></li>
<li><a class="nav-link" href="#calculating-correlations-in-jamovi"><span class="header-section-number">2.1.4</span> Calculating correlations in jamovi</a></li>
<li><a class="nav-link" href="#interpreting-a-correlation"><span class="header-section-number">2.1.5</span> Interpreting a correlation</a></li>
<li><a class="nav-link" href="#spearmans-rank-correlations"><span class="header-section-number">2.1.6</span> Spearman’s rank correlations</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#scatterplots"><span class="header-section-number">2.2</span> Scatterplots</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#more-elaborate-options"><span class="header-section-number">2.2.1</span> More elaborate options</a></li></ul>
</li>
<li><a class="nav-link" href="#what-is-a-linear-regression-model"><span class="header-section-number">2.3</span> What is a linear regression model?</a></li>
<li>
<a class="nav-link" href="#estimating-a-linear-regression-model"><span class="header-section-number">2.4</span> Estimating a linear regression model</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-regression-in-jamovi"><span class="header-section-number">2.4.1</span> Linear regression in jamovi</a></li>
<li><a class="nav-link" href="#interpreting-the-estimated-model"><span class="header-section-number">2.4.2</span> Interpreting the estimated model</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#multiple-linear-regression"><span class="header-section-number">2.5</span> Multiple linear regression</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#doing-it-in-jamovi"><span class="header-section-number">2.5.1</span> Doing it in jamovi</a></li></ul>
</li>
<li>
<a class="nav-link" href="#quantifying-the-fit-of-the-regression-model"><span class="header-section-number">2.6</span> Quantifying the fit of the regression model</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-r2-value"><span class="header-section-number">2.6.1</span> The \(R^2\) value</a></li>
<li><a class="nav-link" href="#the-relationship-between-regression-and-correlation"><span class="header-section-number">2.6.2</span> The relationship between regression and correlation</a></li>
<li><a class="nav-link" href="#the-adjusted-r2-value"><span class="header-section-number">2.6.3</span> The adjusted \(R^2\) value</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#hypothesis-tests-for-regression-models"><span class="header-section-number">2.7</span> Hypothesis tests for regression models</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#testing-the-model-as-a-whole"><span class="header-section-number">2.7.1</span> Testing the model as a whole</a></li>
<li><a class="nav-link" href="#standard-deviation"><span class="header-section-number">2.7.2</span> Standard deviation</a></li>
<li><a class="nav-link" href="#which-measure-to-use"><span class="header-section-number">2.7.3</span> Which measure to use?</a></li>
</ul>
</li>
<li><a class="nav-link" href="#skew-and-kurtosis"><span class="header-section-number">2.8</span> Skew and kurtosis</a></li>
<li><a class="nav-link" href="#descriptive-statistics-separately-for-each-group"><span class="header-section-number">2.9</span> Descriptive statistics separately for each group</a></li>
<li><a class="nav-link" href="#standard-scores"><span class="header-section-number">2.10</span> Standard scores</a></li>
<li><a class="nav-link" href="#summary"><span class="header-section-number">2.11</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong><span style="font-family:Garamond;font-weight:700;">learning statistics with jamovi</span></strong>" was written by Danielle J. Navarro &amp; David R. Foxcroft. It was last built on 17 June 2022 (version 0.75).</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
